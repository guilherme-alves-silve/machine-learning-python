{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym[atari]\n",
    "!wget http://www.atarimania.com/roms/Atari-2600-VCS-ROM-Collection.zip\n",
    "!unzip -q Atari-2600-VCS-ROM-Collection.zip\n",
    "!python -m atari_py.import_roms ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faae2910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.7.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from gym.utils import play\n",
    "from rl.core import Processor\n",
    "from rl.memory import SequentialMemory\n",
    "from collections import deque\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac538017",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8867737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to play\n",
    "# play.play(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41435804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the ball show exactly the same as the tutorial\n",
    "WINDOW_LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374a7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "env.reset()\n",
    "\n",
    "# [[0, 1, 2], [1, 2, 3], [2, 3, 4]]\n",
    "sequential_frame_buffer = []\n",
    "temp_sequential_frames = deque(maxlen=WINDOW_LENGTH)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    if i == 1:\n",
    "        action = 1 # INITIATE BALL\n",
    "    else:\n",
    "        action = 3 # LEFT\n",
    "    \n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    if len(temp_sequential_frames) == WINDOW_LENGTH:\n",
    "        sequential_frame_buffer.append(list(temp_sequential_frames))\n",
    "    temp_sequential_frames.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e91c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequential_frame_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969123d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sequential_frame_buffer)):\n",
    "    print(len(sequential_frame_buffer[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2bd6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i][j].imshow(sequential_frame_buffer[i][j])\n",
    "        ax[i][j].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804b8bf",
   "metadata": {},
   "source": [
    "## Example of the made by the author of the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52748bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1200 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis = plt.subplots(4, WINDOW_LENGTH, figsize=(12, 12))\n",
    "for global_index, timestep in enumerate(sequential_frame_buffer[:4]):\n",
    "    for frame_index, frame in enumerate(timestep):\n",
    "        axis[global_index][frame_index].imshow(frame)\n",
    "        \n",
    "fig.subplots_adjust(wspace=0, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd056c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1000, window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4714eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_frame_buffer[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf92134",
   "metadata": {},
   "source": [
    "## To reduce the processing time, we reduce the shape, in this case, 84x84 won't be hard to the model learn to play the game, it can recognize the game in this shape, but, if reduce to much, it would be hard for the model to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d5d705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a5b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreakOutProcessor(Processor):\n",
    "    \n",
    "    def process_observation(self, obs):\n",
    "        # array -> Image with PIL\n",
    "        img = Image.fromarray(obs)\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        img = img.convert(\"L\")\n",
    "        return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6c66981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = []\n",
    "breakout_processor = BreakOutProcessor()\n",
    "\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    proc_obs = breakout_processor.process_observation(obs)\n",
    "    sample_images.append(proc_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99012ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sample_images[-1].shape)\n",
    "plt.imshow(sample_images[-1], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adac598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beae1879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutDeterministic-v4\")\n",
    "nb_actions = env.action_space.n\n",
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf891ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67921cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    \n",
    "    def process_observation(self, obs):\n",
    "        img = Image.fromarray(obs)\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        img = img.convert(\"L\")\n",
    "        img = np.array(img)\n",
    "        return img.astype(\"uint8\")\n",
    "    \n",
    "    def process_state_batch(self, batch):\n",
    "        processed_batch = batch.astype(\"float32\")/255.0\n",
    "        return processed_batch\n",
    "    \n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a16f896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0192ef",
   "metadata": {},
   "source": [
    "To work with the Convolution2D (or Conv2D) we need have the shape (Batch, 84, 84, 4), but the input_shape has shape (4, 84, 84), we can use [**Permute**](https://keras.io/api/layers/reshaping_layers/permute/) to change the index positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f166634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programas\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 84, 84, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 375,460\n",
      "Trainable params: 375,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# (Batch, 84, 84, 4)\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(32, (8, 8), strides=(4, 4), kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), strides=(4, 4), kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation(\"linear\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c690af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1_000_000, window_length=WINDOW_LENGTH)\n",
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "355d6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                              attr=\"eps\",\n",
    "                              value_max=1.0,\n",
    "                              value_min=0.1,\n",
    "                              value_test=0.05,\n",
    "                              nb_steps=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4b8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_actions,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50_000,\n",
    "               gamma=0.99,\n",
    "               target_model_update=10_000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d8a354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=0.00025), metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename = \"dqn_bo.h5f\"\n",
    "checkpoint_filename = \"dqn_checkpoint.h5f\"\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_filename, interval=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1484d8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - ale.lives: 3.130\n",
      "\n",
      "Interval 2 (500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - ale.lives: 2.750\n",
      "\n",
      "Interval 3 (1000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - ale.lives: 3.532\n",
      "\n",
      "Interval 4 (1500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - ale.lives: 3.150\n",
      "\n",
      "Interval 5 (2000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 3.008\n",
      "\n",
      "Interval 6 (2500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.876\n",
      "\n",
      "Interval 7 (3000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 0.750 [0.000, 2.000] - ale.lives: 3.168\n",
      "\n",
      "Interval 8 (3500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - ale.lives: 2.886\n",
      "\n",
      "Interval 9 (4000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - ale.lives: 3.102\n",
      "\n",
      "Interval 10 (4500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - ale.lives: 2.614\n",
      "\n",
      "Interval 11 (5000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - ale.lives: 2.698\n",
      "\n",
      "Interval 12 (5500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.884\n",
      "\n",
      "Interval 13 (6000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - ale.lives: 3.058\n",
      "\n",
      "Interval 14 (6500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - ale.lives: 3.080\n",
      "\n",
      "Interval 15 (7000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - ale.lives: 3.038\n",
      "\n",
      "Interval 16 (7500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.250 [0.000, 1.000] - ale.lives: 3.100\n",
      "\n",
      "Interval 17 (8000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - ale.lives: 2.378\n",
      "\n",
      "Interval 18 (8500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - ale.lives: 3.202\n",
      "\n",
      "Interval 19 (9000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - ale.lives: 2.398\n",
      "\n",
      "Interval 20 (9500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.854\n",
      "\n",
      "Interval 21 (10000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - ale.lives: 3.036\n",
      "\n",
      "Interval 22 (10500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - ale.lives: 2.964\n",
      "\n",
      "Interval 23 (11000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 3.158\n",
      "\n",
      "Interval 24 (11500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - ale.lives: 3.274\n",
      "\n",
      "Interval 25 (12000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - ale.lives: 2.822\n",
      "\n",
      "Interval 26 (12500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 2.922\n",
      "\n",
      "Interval 27 (13000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - ale.lives: 2.770\n",
      "\n",
      "Interval 28 (13500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.910\n",
      "\n",
      "Interval 29 (14000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - ale.lives: 2.978\n",
      "\n",
      "Interval 30 (14500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - ale.lives: 2.674\n",
      "\n",
      "Interval 31 (15000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 3.186\n",
      "\n",
      "Interval 32 (15500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - ale.lives: 3.040\n",
      "\n",
      "Interval 33 (16000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - ale.lives: 2.938\n",
      "\n",
      "Interval 34 (16500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - ale.lives: 3.112\n",
      "\n",
      "Interval 35 (17000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - ale.lives: 2.600\n",
      "\n",
      "Interval 36 (17500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.870\n",
      "\n",
      "Interval 37 (18000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 3.002\n",
      "\n",
      "Interval 38 (18500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 3.014\n",
      "\n",
      "Interval 39 (19000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - ale.lives: 2.730\n",
      "\n",
      "Interval 40 (19500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 2.782\n",
      "\n",
      "Interval 41 (20000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - ale.lives: 2.488\n",
      "\n",
      "Interval 42 (20500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - ale.lives: 3.254\n",
      "\n",
      "Interval 43 (21000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 3.306\n",
      "\n",
      "Interval 44 (21500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 2.950\n",
      "\n",
      "Interval 45 (22000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - ale.lives: 3.016\n",
      "\n",
      "Interval 46 (22500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - ale.lives: 2.760\n",
      "\n",
      "Interval 47 (23000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - ale.lives: 3.030\n",
      "\n",
      "Interval 48 (23500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.890\n",
      "\n",
      "Interval 49 (24000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - ale.lives: 2.846\n",
      "\n",
      "Interval 50 (24500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - ale.lives: 2.726\n",
      "\n",
      "Interval 51 (25000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 3.206\n",
      "\n",
      "Interval 52 (25500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - ale.lives: 2.926\n",
      "\n",
      "Interval 53 (26000 steps performed)\n",
      "500/500 [==============================] - 5s 11ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 3.072\n",
      "\n",
      "Interval 54 (26500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 3.002\n",
      "\n",
      "Interval 55 (27000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.916\n",
      "\n",
      "Interval 56 (27500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 1.000 [0.000, 3.000] - ale.lives: 2.872\n",
      "\n",
      "Interval 57 (28000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.870\n",
      "\n",
      "Interval 58 (28500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - ale.lives: 3.138\n",
      "\n",
      "Interval 59 (29000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - ale.lives: 2.826\n",
      "\n",
      "Interval 60 (29500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.850\n",
      "\n",
      "Interval 61 (30000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 1.000 [0.000, 3.000] - ale.lives: 2.754\n",
      "\n",
      "Interval 62 (30500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - ale.lives: 3.414\n",
      "\n",
      "Interval 63 (31000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - ale.lives: 2.514\n",
      "\n",
      "Interval 64 (31500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - ale.lives: 2.812\n",
      "\n",
      "Interval 65 (32000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - ale.lives: 3.290\n",
      "\n",
      "Interval 66 (32500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - ale.lives: 3.160\n",
      "\n",
      "Interval 67 (33000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 3.018\n",
      "\n",
      "Interval 68 (33500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.632\n",
      "\n",
      "Interval 69 (34000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.774\n",
      "\n",
      "Interval 70 (34500 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - ale.lives: 2.952\n",
      "\n",
      "Interval 71 (35000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - ale.lives: 2.904\n",
      "\n",
      "Interval 72 (35500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - ale.lives: 2.752\n",
      "\n",
      "Interval 73 (36000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - ale.lives: 3.222\n",
      "\n",
      "Interval 74 (36500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - ale.lives: 2.988\n",
      "\n",
      "Interval 75 (37000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - ale.lives: 2.520\n",
      "\n",
      "Interval 76 (37500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 0.750 [0.000, 1.000] - ale.lives: 2.832\n",
      "\n",
      "Interval 77 (38000 steps performed)\n",
      "500/500 [==============================] - 5s 9ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.754\n",
      "\n",
      "Interval 78 (38500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.840\n",
      "\n",
      "Interval 79 (39000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [0.000, 7.000] - ale.lives: 3.352\n",
      "\n",
      "Interval 80 (39500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - ale.lives: 2.578\n",
      "\n",
      "Interval 81 (40000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - ale.lives: 2.670\n",
      "\n",
      "Interval 82 (40500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - ale.lives: 2.920\n",
      "\n",
      "Interval 83 (41000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - ale.lives: 2.944\n",
      "\n",
      "Interval 84 (41500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - ale.lives: 3.138\n",
      "\n",
      "Interval 85 (42000 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - ale.lives: 3.082\n",
      "\n",
      "Interval 86 (42500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - ale.lives: 3.090\n",
      "\n",
      "Interval 87 (43000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - ale.lives: 2.572\n",
      "\n",
      "Interval 88 (43500 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - ale.lives: 2.750\n",
      "\n",
      "Interval 89 (44000 steps performed)\n",
      "500/500 [==============================] - 5s 10ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - ale.lives: 3.052\n",
      "\n",
      "Interval 90 (44500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - ale.lives: 2.794\n",
      "\n",
      "Interval 91 (45000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - ale.lives: 2.686\n",
      "\n",
      "Interval 92 (45500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 3.070\n",
      "\n",
      "Interval 93 (46000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 2.840\n",
      "\n",
      "Interval 94 (46500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - ale.lives: 2.664\n",
      "\n",
      "Interval 95 (47000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.992\n",
      "\n",
      "Interval 96 (47500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - ale.lives: 3.216\n",
      "\n",
      "Interval 97 (48000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - ale.lives: 2.956\n",
      "\n",
      "Interval 98 (48500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - ale.lives: 2.666\n",
      "\n",
      "Interval 99 (49000 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - ale.lives: 3.204\n",
      "\n",
      "Interval 100 (49500 steps performed)\n",
      "500/500 [==============================] - 4s 9ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - ale.lives: 2.698\n",
      "\n",
      "Interval 101 (50000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.005 - mae: 0.090 - mean_q: 0.145 - mean_eps: 0.955 - ale.lives: 2.950\n",
      "\n",
      "Interval 102 (50500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.006 - mae: 0.089 - mean_q: 0.137 - mean_eps: 0.954 - ale.lives: 2.692\n",
      "\n",
      "Interval 103 (51000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 0.083 - mean_q: 0.121 - mean_eps: 0.954 - ale.lives: 3.154\n",
      "\n",
      "Interval 104 (51500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.004 - mae: 0.084 - mean_q: 0.127 - mean_eps: 0.953 - ale.lives: 3.072\n",
      "\n",
      "Interval 105 (52000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.005 - mae: 0.086 - mean_q: 0.126 - mean_eps: 0.953 - ale.lives: 2.968\n",
      "\n",
      "Interval 106 (52500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.004 - mae: 0.086 - mean_q: 0.121 - mean_eps: 0.953 - ale.lives: 2.730\n",
      "\n",
      "Interval 107 (53000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.004 - mae: 0.085 - mean_q: 0.123 - mean_eps: 0.952 - ale.lives: 2.958\n",
      "\n",
      "Interval 108 (53500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.004 - mae: 0.084 - mean_q: 0.119 - mean_eps: 0.952 - ale.lives: 3.204\n",
      "\n",
      "Interval 109 (54000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0000e+00\n",
      "4 episodes - episode_reward: 1.000 [0.000, 4.000] - loss: 0.003 - mae: 0.085 - mean_q: 0.121 - mean_eps: 0.951 - ale.lives: 3.074\n",
      "\n",
      "Interval 110 (54500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.004 - mae: 0.086 - mean_q: 0.122 - mean_eps: 0.951 - ale.lives: 3.042\n",
      "\n",
      "Interval 111 (55000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.004 - mae: 0.088 - mean_q: 0.126 - mean_eps: 0.950 - ale.lives: 2.668\n",
      "\n",
      "Interval 112 (55500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.003 - mae: 0.084 - mean_q: 0.119 - mean_eps: 0.950 - ale.lives: 3.014\n",
      "\n",
      "Interval 113 (56000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.002 - mae: 0.082 - mean_q: 0.117 - mean_eps: 0.949 - ale.lives: 2.886\n",
      "\n",
      "Interval 114 (56500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 0.082 - mean_q: 0.112 - mean_eps: 0.949 - ale.lives: 3.080\n",
      "\n",
      "Interval 115 (57000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0000e+00\n",
      "4 episodes - episode_reward: 0.750 [0.000, 3.000] - loss: 0.003 - mae: 0.087 - mean_q: 0.120 - mean_eps: 0.948 - ale.lives: 2.954\n",
      "\n",
      "Interval 116 (57500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 0.084 - mean_q: 0.116 - mean_eps: 0.948 - ale.lives: 2.848\n",
      "\n",
      "Interval 117 (58000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.250 [0.000, 1.000] - loss: 0.001 - mae: 0.080 - mean_q: 0.112 - mean_eps: 0.948 - ale.lives: 3.050\n",
      "\n",
      "Interval 118 (58500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.081 - mean_q: 0.111 - mean_eps: 0.947 - ale.lives: 2.694\n",
      "\n",
      "Interval 119 (59000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.082 - mean_q: 0.113 - mean_eps: 0.947 - ale.lives: 3.014\n",
      "\n",
      "Interval 120 (59500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.001 - mae: 0.079 - mean_q: 0.109 - mean_eps: 0.946 - ale.lives: 3.280\n",
      "\n",
      "Interval 121 (60000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.003 - mae: 0.088 - mean_q: 0.120 - mean_eps: 0.946 - ale.lives: 2.532\n",
      "\n",
      "Interval 122 (60500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.003 - mae: 0.087 - mean_q: 0.119 - mean_eps: 0.945 - ale.lives: 3.132\n",
      "\n",
      "Interval 123 (61000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 0.085 - mean_q: 0.116 - mean_eps: 0.945 - ale.lives: 3.000\n",
      "\n",
      "Interval 124 (61500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.087 - mean_q: 0.121 - mean_eps: 0.944 - ale.lives: 3.130\n",
      "\n",
      "Interval 125 (62000 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.084 - mean_q: 0.116 - mean_eps: 0.944 - ale.lives: 2.424\n",
      "\n",
      "Interval 126 (62500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0000e+00\n",
      "4 episodes - episode_reward: 0.750 [0.000, 3.000] - loss: 0.001 - mae: 0.085 - mean_q: 0.116 - mean_eps: 0.944 - ale.lives: 3.106\n",
      "\n",
      "Interval 127 (63000 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.083 - mean_q: 0.112 - mean_eps: 0.943 - ale.lives: 2.694\n",
      "\n",
      "Interval 128 (63500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.001 - mae: 0.084 - mean_q: 0.116 - mean_eps: 0.943 - ale.lives: 2.824\n",
      "\n",
      "Interval 129 (64000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.085 - mean_q: 0.115 - mean_eps: 0.942 - ale.lives: 2.952\n",
      "\n",
      "Interval 130 (64500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.001 - mae: 0.082 - mean_q: 0.111 - mean_eps: 0.942 - ale.lives: 3.172\n",
      "\n",
      "Interval 131 (65000 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.086 - mean_q: 0.119 - mean_eps: 0.941 - ale.lives: 2.908\n",
      "\n",
      "Interval 132 (65500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 0.086 - mean_q: 0.116 - mean_eps: 0.941 - ale.lives: 2.782\n",
      "\n",
      "Interval 133 (66000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.083 - mean_q: 0.114 - mean_eps: 0.940 - ale.lives: 2.448\n",
      "\n",
      "Interval 134 (66500 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [1.000, 3.000] - loss: 0.001 - mae: 0.084 - mean_q: 0.114 - mean_eps: 0.940 - ale.lives: 2.988\n",
      "\n",
      "Interval 135 (67000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.085 - mean_q: 0.115 - mean_eps: 0.939 - ale.lives: 2.772\n",
      "\n",
      "Interval 136 (67500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.084 - mean_q: 0.114 - mean_eps: 0.939 - ale.lives: 2.914\n",
      "\n",
      "Interval 137 (68000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.001 - mae: 0.085 - mean_q: 0.116 - mean_eps: 0.939 - ale.lives: 3.198\n",
      "\n",
      "Interval 138 (68500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.082 - mean_q: 0.112 - mean_eps: 0.938 - ale.lives: 3.016\n",
      "\n",
      "Interval 139 (69000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.086 - mean_q: 0.119 - mean_eps: 0.938 - ale.lives: 3.126\n",
      "\n",
      "Interval 140 (69500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 2.000] - loss: 0.001 - mae: 0.084 - mean_q: 0.115 - mean_eps: 0.937 - ale.lives: 3.170\n",
      "\n",
      "Interval 141 (70000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.093 - mean_q: 0.125 - mean_eps: 0.937 - ale.lives: 2.884\n",
      "\n",
      "Interval 142 (70500 steps performed)\n",
      "500/500 [==============================] - 21s 42ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 0.093 - mean_q: 0.125 - mean_eps: 0.936 - ale.lives: 3.118\n",
      "\n",
      "Interval 143 (71000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.093 - mean_q: 0.127 - mean_eps: 0.936 - ale.lives: 3.294\n",
      "\n",
      "Interval 144 (71500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.091 - mean_q: 0.124 - mean_eps: 0.935 - ale.lives: 2.740\n",
      "\n",
      "Interval 145 (72000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.092 - mean_q: 0.125 - mean_eps: 0.935 - ale.lives: 3.264\n",
      "\n",
      "Interval 146 (72500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.001 - mae: 0.092 - mean_q: 0.123 - mean_eps: 0.935 - ale.lives: 3.184\n",
      "\n",
      "Interval 147 (73000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.091 - mean_q: 0.124 - mean_eps: 0.934 - ale.lives: 3.008\n",
      "\n",
      "Interval 148 (73500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.750 [0.000, 2.000] - loss: 0.001 - mae: 0.092 - mean_q: 0.125 - mean_eps: 0.934 - ale.lives: 2.812\n",
      "\n",
      "Interval 149 (74000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.090 - mean_q: 0.121 - mean_eps: 0.933 - ale.lives: 2.996\n",
      "\n",
      "Interval 150 (74500 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.090 - mean_q: 0.122 - mean_eps: 0.933 - ale.lives: 3.246\n",
      "\n",
      "Interval 151 (75000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.091 - mean_q: 0.123 - mean_eps: 0.932 - ale.lives: 3.008\n",
      "\n",
      "Interval 152 (75500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.001 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.932 - ale.lives: 2.888\n",
      "\n",
      "Interval 153 (76000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.129 - mean_eps: 0.931 - ale.lives: 2.938\n",
      "\n",
      "Interval 154 (76500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.092 - mean_q: 0.124 - mean_eps: 0.931 - ale.lives: 2.828\n",
      "\n",
      "Interval 155 (77000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.001 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.930 - ale.lives: 3.082\n",
      "\n",
      "Interval 156 (77500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.089 - mean_q: 0.121 - mean_eps: 0.930 - ale.lives: 2.986\n",
      "\n",
      "Interval 157 (78000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.093 - mean_q: 0.126 - mean_eps: 0.930 - ale.lives: 2.802\n",
      "\n",
      "Interval 158 (78500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.000 - mae: 0.091 - mean_q: 0.122 - mean_eps: 0.929 - ale.lives: 2.956\n",
      "\n",
      "Interval 159 (79000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.000 - mae: 0.092 - mean_q: 0.124 - mean_eps: 0.929 - ale.lives: 2.800\n",
      "\n",
      "Interval 160 (79500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.127 - mean_eps: 0.928 - ale.lives: 2.504\n",
      "\n",
      "Interval 161 (80000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.750 [0.000, 2.000] - loss: 0.002 - mae: 0.103 - mean_q: 0.138 - mean_eps: 0.928 - ale.lives: 3.084\n",
      "\n",
      "Interval 162 (80500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.001 - mae: 0.098 - mean_q: 0.133 - mean_eps: 0.927 - ale.lives: 2.666\n",
      "\n",
      "Interval 163 (81000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.097 - mean_q: 0.129 - mean_eps: 0.927 - ale.lives: 2.974\n",
      "\n",
      "Interval 164 (81500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.250 [0.000, 1.000] - loss: 0.001 - mae: 0.101 - mean_q: 0.136 - mean_eps: 0.926 - ale.lives: 2.752\n",
      "\n",
      "Interval 165 (82000 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.926 - ale.lives: 3.120\n",
      "\n",
      "Interval 166 (82500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.128 - mean_eps: 0.926 - ale.lives: 3.266\n",
      "\n",
      "Interval 167 (83000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.000 - mae: 0.092 - mean_q: 0.124 - mean_eps: 0.925 - ale.lives: 2.870\n",
      "\n",
      "Interval 168 (83500 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.127 - mean_eps: 0.925 - ale.lives: 2.826\n",
      "\n",
      "Interval 169 (84000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.924 - ale.lives: 2.902\n",
      "\n",
      "Interval 170 (84500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.924 - ale.lives: 2.972\n",
      "\n",
      "Interval 171 (85000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.097 - mean_q: 0.130 - mean_eps: 0.923 - ale.lives: 2.962\n",
      "\n",
      "Interval 172 (85500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.923 - ale.lives: 3.016\n",
      "\n",
      "Interval 173 (86000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [1.000, 3.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.128 - mean_eps: 0.922 - ale.lives: 2.872\n",
      "\n",
      "Interval 174 (86500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.000 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.922 - ale.lives: 3.286\n",
      "\n",
      "Interval 175 (87000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.097 - mean_q: 0.131 - mean_eps: 0.921 - ale.lives: 2.916\n",
      "\n",
      "Interval 176 (87500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.921 - ale.lives: 2.898\n",
      "\n",
      "Interval 177 (88000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.100 - mean_q: 0.135 - mean_eps: 0.921 - ale.lives: 2.410\n",
      "\n",
      "Interval 178 (88500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.130 - mean_eps: 0.920 - ale.lives: 2.962\n",
      "\n",
      "Interval 179 (89000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.100 - mean_q: 0.135 - mean_eps: 0.920 - ale.lives: 2.814\n",
      "\n",
      "Interval 180 (89500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.131 - mean_eps: 0.919 - ale.lives: 2.798\n",
      "\n",
      "Interval 181 (90000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.002 - mae: 0.097 - mean_q: 0.129 - mean_eps: 0.919 - ale.lives: 3.088\n",
      "\n",
      "Interval 182 (90500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.127 - mean_eps: 0.918 - ale.lives: 2.704\n",
      "\n",
      "Interval 183 (91000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.918 - ale.lives: 2.688\n",
      "\n",
      "Interval 184 (91500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.094 - mean_q: 0.127 - mean_eps: 0.917 - ale.lives: 2.890\n",
      "\n",
      "Interval 185 (92000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.128 - mean_eps: 0.917 - ale.lives: 2.766\n",
      "\n",
      "Interval 186 (92500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.098 - mean_q: 0.131 - mean_eps: 0.917 - ale.lives: 2.998\n",
      "\n",
      "Interval 187 (93000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.916 - ale.lives: 3.050\n",
      "\n",
      "Interval 188 (93500 steps performed)\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.001 - mae: 0.098 - mean_q: 0.131 - mean_eps: 0.916 - ale.lives: 2.542\n",
      "\n",
      "Interval 189 (94000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.000 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.915 - ale.lives: 3.048\n",
      "\n",
      "Interval 190 (94500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.915 - ale.lives: 2.622\n",
      "\n",
      "Interval 191 (95000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.097 - mean_q: 0.131 - mean_eps: 0.914 - ale.lives: 2.976\n",
      "\n",
      "Interval 192 (95500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [0.000, 3.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.127 - mean_eps: 0.914 - ale.lives: 2.602\n",
      "\n",
      "Interval 193 (96000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.097 - mean_q: 0.131 - mean_eps: 0.913 - ale.lives: 2.788\n",
      "\n",
      "Interval 194 (96500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.127 - mean_eps: 0.913 - ale.lives: 2.666\n",
      "\n",
      "Interval 195 (97000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.000 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.912 - ale.lives: 2.696\n",
      "\n",
      "Interval 196 (97500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.912 - ale.lives: 2.720\n",
      "\n",
      "Interval 197 (98000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.128 - mean_eps: 0.912 - ale.lives: 3.210\n",
      "\n",
      "Interval 198 (98500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.094 - mean_q: 0.126 - mean_eps: 0.911 - ale.lives: 3.026\n",
      "\n",
      "Interval 199 (99000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.096 - mean_q: 0.129 - mean_eps: 0.911 - ale.lives: 2.986\n",
      "\n",
      "Interval 200 (99500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.001 - mae: 0.095 - mean_q: 0.128 - mean_eps: 0.910 - ale.lives: 2.816\n",
      "\n",
      "Interval 201 (100000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 0.115 - mean_q: 0.153 - mean_eps: 0.910 - ale.lives: 3.604\n",
      "\n",
      "Interval 202 (100500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.105 - mean_q: 0.142 - mean_eps: 0.909 - ale.lives: 2.966\n",
      "\n",
      "Interval 203 (101000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.909 - ale.lives: 3.130\n",
      "\n",
      "Interval 204 (101500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [0.000, 5.000] - loss: 0.001 - mae: 0.107 - mean_q: 0.142 - mean_eps: 0.908 - ale.lives: 2.742\n",
      "\n",
      "Interval 205 (102000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.108 - mean_q: 0.144 - mean_eps: 0.908 - ale.lives: 3.066\n",
      "\n",
      "Interval 206 (102500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.107 - mean_q: 0.143 - mean_eps: 0.908 - ale.lives: 3.158\n",
      "\n",
      "Interval 207 (103000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.105 - mean_q: 0.140 - mean_eps: 0.907 - ale.lives: 2.938\n",
      "\n",
      "Interval 208 (103500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.000 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.907 - ale.lives: 3.146\n",
      "\n",
      "Interval 209 (104000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.001 - mae: 0.111 - mean_q: 0.147 - mean_eps: 0.906 - ale.lives: 2.802\n",
      "\n",
      "Interval 210 (104500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.000 - mae: 0.106 - mean_q: 0.143 - mean_eps: 0.906 - ale.lives: 2.718\n",
      "\n",
      "Interval 211 (105000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.105 - mean_q: 0.142 - mean_eps: 0.905 - ale.lives: 3.424\n",
      "\n",
      "Interval 212 (105500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.750 [0.000, 2.000] - loss: 0.000 - mae: 0.105 - mean_q: 0.141 - mean_eps: 0.905 - ale.lives: 2.840\n",
      "\n",
      "Interval 213 (106000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.000 - mae: 0.103 - mean_q: 0.137 - mean_eps: 0.904 - ale.lives: 2.898\n",
      "\n",
      "Interval 214 (106500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 0.750 [0.000, 3.000] - loss: 0.000 - mae: 0.104 - mean_q: 0.138 - mean_eps: 0.904 - ale.lives: 2.908\n",
      "\n",
      "Interval 215 (107000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.000 - mae: 0.104 - mean_q: 0.139 - mean_eps: 0.903 - ale.lives: 3.198\n",
      "\n",
      "Interval 216 (107500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.000 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.903 - ale.lives: 2.548\n",
      "\n",
      "Interval 217 (108000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.102 - mean_q: 0.136 - mean_eps: 0.903 - ale.lives: 2.718\n",
      "\n",
      "Interval 218 (108500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0000e+00\n",
      "4 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.000 - mae: 0.102 - mean_q: 0.137 - mean_eps: 0.902 - ale.lives: 3.134\n",
      "\n",
      "Interval 219 (109000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.103 - mean_q: 0.138 - mean_eps: 0.902 - ale.lives: 2.680\n",
      "\n",
      "Interval 220 (109500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.107 - mean_q: 0.142 - mean_eps: 0.901 - ale.lives: 2.822\n",
      "\n",
      "Interval 221 (110000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.109 - mean_q: 0.145 - mean_eps: 0.901 - ale.lives: 2.574\n",
      "\n",
      "Interval 222 (110500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.001 - mae: 0.111 - mean_q: 0.147 - mean_eps: 0.900 - ale.lives: 2.920\n",
      "\n",
      "Interval 223 (111000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.108 - mean_q: 0.145 - mean_eps: 0.900 - ale.lives: 3.052\n",
      "\n",
      "Interval 224 (111500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.110 - mean_q: 0.148 - mean_eps: 0.899 - ale.lives: 2.992\n",
      "\n",
      "Interval 225 (112000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.106 - mean_q: 0.142 - mean_eps: 0.899 - ale.lives: 2.860\n",
      "\n",
      "Interval 226 (112500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.111 - mean_q: 0.148 - mean_eps: 0.899 - ale.lives: 2.960\n",
      "\n",
      "Interval 227 (113000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.109 - mean_q: 0.144 - mean_eps: 0.898 - ale.lives: 3.000\n",
      "\n",
      "Interval 228 (113500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.109 - mean_q: 0.146 - mean_eps: 0.898 - ale.lives: 2.962\n",
      "\n",
      "Interval 229 (114000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.112 - mean_q: 0.149 - mean_eps: 0.897 - ale.lives: 2.974\n",
      "\n",
      "Interval 230 (114500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.897 - ale.lives: 2.926\n",
      "\n",
      "Interval 231 (115000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.000 - mae: 0.107 - mean_q: 0.143 - mean_eps: 0.896 - ale.lives: 2.944\n",
      "\n",
      "Interval 232 (115500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.000 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.896 - ale.lives: 2.942\n",
      "\n",
      "Interval 233 (116000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.107 - mean_q: 0.143 - mean_eps: 0.895 - ale.lives: 3.102\n",
      "\n",
      "Interval 234 (116500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.000 - mae: 0.105 - mean_q: 0.140 - mean_eps: 0.895 - ale.lives: 3.090\n",
      "\n",
      "Interval 235 (117000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.001 - mae: 0.114 - mean_q: 0.153 - mean_eps: 0.894 - ale.lives: 2.648\n",
      "\n",
      "Interval 236 (117500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.109 - mean_q: 0.146 - mean_eps: 0.894 - ale.lives: 2.976\n",
      "\n",
      "Interval 237 (118000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 0.111 - mean_q: 0.148 - mean_eps: 0.894 - ale.lives: 3.188\n",
      "\n",
      "Interval 238 (118500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.000 - mae: 0.107 - mean_q: 0.143 - mean_eps: 0.893 - ale.lives: 3.112\n",
      "\n",
      "Interval 239 (119000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 1.250 [0.000, 4.000] - loss: 0.000 - mae: 0.107 - mean_q: 0.142 - mean_eps: 0.893 - ale.lives: 3.032\n",
      "\n",
      "Interval 240 (119500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.000 - mae: 0.109 - mean_q: 0.145 - mean_eps: 0.892 - ale.lives: 3.044\n",
      "\n",
      "Interval 241 (120000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 0.112 - mean_q: 0.150 - mean_eps: 0.892 - ale.lives: 3.146\n",
      "\n",
      "Interval 242 (120500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.114 - mean_q: 0.151 - mean_eps: 0.891 - ale.lives: 2.740\n",
      "\n",
      "Interval 243 (121000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.112 - mean_q: 0.149 - mean_eps: 0.891 - ale.lives: 3.240\n",
      "\n",
      "Interval 244 (121500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.109 - mean_q: 0.146 - mean_eps: 0.890 - ale.lives: 2.900\n",
      "\n",
      "Interval 245 (122000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.113 - mean_q: 0.150 - mean_eps: 0.890 - ale.lives: 2.886\n",
      "\n",
      "Interval 246 (122500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.113 - mean_q: 0.151 - mean_eps: 0.890 - ale.lives: 2.988\n",
      "\n",
      "Interval 247 (123000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 0.500 [0.000, 2.000] - loss: 0.001 - mae: 0.113 - mean_q: 0.152 - mean_eps: 0.889 - ale.lives: 3.060\n",
      "\n",
      "Interval 248 (123500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.109 - mean_q: 0.146 - mean_eps: 0.889 - ale.lives: 2.960\n",
      "\n",
      "Interval 249 (124000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 0.112 - mean_q: 0.150 - mean_eps: 0.888 - ale.lives: 3.092\n",
      "\n",
      "Interval 250 (124500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.118 - mean_q: 0.157 - mean_eps: 0.888 - ale.lives: 2.632\n",
      "\n",
      "Interval 251 (125000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.887 - ale.lives: 3.348\n",
      "\n",
      "Interval 252 (125500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.000 - mae: 0.108 - mean_q: 0.144 - mean_eps: 0.887 - ale.lives: 3.040\n",
      "\n",
      "Interval 253 (126000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.112 - mean_q: 0.150 - mean_eps: 0.886 - ale.lives: 2.938\n",
      "\n",
      "Interval 254 (126500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.107 - mean_q: 0.143 - mean_eps: 0.886 - ale.lives: 2.742\n",
      "\n",
      "Interval 255 (127000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.000 - mae: 0.110 - mean_q: 0.146 - mean_eps: 0.885 - ale.lives: 3.100\n",
      "\n",
      "Interval 256 (127500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.113 - mean_q: 0.151 - mean_eps: 0.885 - ale.lives: 2.852\n",
      "\n",
      "Interval 257 (128000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.112 - mean_q: 0.150 - mean_eps: 0.885 - ale.lives: 2.590\n",
      "\n",
      "Interval 258 (128500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.110 - mean_q: 0.147 - mean_eps: 0.884 - ale.lives: 2.690\n",
      "\n",
      "Interval 259 (129000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 0.750 [0.000, 1.000] - loss: 0.000 - mae: 0.111 - mean_q: 0.148 - mean_eps: 0.884 - ale.lives: 2.908\n",
      "\n",
      "Interval 260 (129500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.000 - mae: 0.113 - mean_q: 0.153 - mean_eps: 0.883 - ale.lives: 2.884\n",
      "\n",
      "Interval 261 (130000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.003 - mae: 0.123 - mean_q: 0.164 - mean_eps: 0.883 - ale.lives: 2.856\n",
      "\n",
      "Interval 262 (130500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.001 - mae: 0.115 - mean_q: 0.153 - mean_eps: 0.882 - ale.lives: 2.470\n",
      "\n",
      "Interval 263 (131000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 0.121 - mean_q: 0.162 - mean_eps: 0.882 - ale.lives: 2.904\n",
      "\n",
      "Interval 264 (131500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.116 - mean_q: 0.155 - mean_eps: 0.881 - ale.lives: 2.182\n",
      "\n",
      "Interval 265 (132000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.114 - mean_q: 0.152 - mean_eps: 0.881 - ale.lives: 3.124\n",
      "\n",
      "Interval 266 (132500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.001 - mae: 0.117 - mean_q: 0.156 - mean_eps: 0.881 - ale.lives: 2.726\n",
      "\n",
      "Interval 267 (133000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.115 - mean_q: 0.153 - mean_eps: 0.880 - ale.lives: 2.860\n",
      "\n",
      "Interval 268 (133500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.000 - mae: 0.119 - mean_q: 0.159 - mean_eps: 0.880 - ale.lives: 3.020\n",
      "\n",
      "Interval 269 (134000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.114 - mean_q: 0.153 - mean_eps: 0.879 - ale.lives: 3.010\n",
      "\n",
      "Interval 270 (134500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.250 [0.000, 1.000] - loss: 0.000 - mae: 0.113 - mean_q: 0.152 - mean_eps: 0.879 - ale.lives: 2.702\n",
      "\n",
      "Interval 271 (135000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.000 - mae: 0.119 - mean_q: 0.159 - mean_eps: 0.878 - ale.lives: 2.892\n",
      "\n",
      "Interval 272 (135500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.116 - mean_q: 0.155 - mean_eps: 0.878 - ale.lives: 2.828\n",
      "\n",
      "Interval 273 (136000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.000 - mae: 0.120 - mean_q: 0.160 - mean_eps: 0.877 - ale.lives: 2.774\n",
      "\n",
      "Interval 274 (136500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.116 - mean_q: 0.154 - mean_eps: 0.877 - ale.lives: 2.902\n",
      "\n",
      "Interval 275 (137000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.000 - mae: 0.111 - mean_q: 0.149 - mean_eps: 0.876 - ale.lives: 3.028\n",
      "\n",
      "Interval 276 (137500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.115 - mean_q: 0.153 - mean_eps: 0.876 - ale.lives: 3.376\n",
      "\n",
      "Interval 277 (138000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.000 - mae: 0.115 - mean_q: 0.155 - mean_eps: 0.876 - ale.lives: 2.792\n",
      "\n",
      "Interval 278 (138500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.112 - mean_q: 0.150 - mean_eps: 0.875 - ale.lives: 3.058\n",
      "\n",
      "Interval 279 (139000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.000 - mae: 0.119 - mean_q: 0.160 - mean_eps: 0.875 - ale.lives: 3.034\n",
      "\n",
      "Interval 280 (139500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.111 - mean_q: 0.149 - mean_eps: 0.874 - ale.lives: 2.900\n",
      "\n",
      "Interval 281 (140000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 0.122 - mean_q: 0.162 - mean_eps: 0.874 - ale.lives: 2.922\n",
      "\n",
      "Interval 282 (140500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.122 - mean_q: 0.162 - mean_eps: 0.873 - ale.lives: 2.778\n",
      "\n",
      "Interval 283 (141000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.122 - mean_q: 0.163 - mean_eps: 0.873 - ale.lives: 2.776\n",
      "\n",
      "Interval 284 (141500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.124 - mean_q: 0.165 - mean_eps: 0.872 - ale.lives: 2.912\n",
      "\n",
      "Interval 285 (142000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.001 - mae: 0.122 - mean_q: 0.163 - mean_eps: 0.872 - ale.lives: 2.668\n",
      "\n",
      "Interval 286 (142500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.124 - mean_q: 0.166 - mean_eps: 0.872 - ale.lives: 3.106\n",
      "\n",
      "Interval 287 (143000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.122 - mean_q: 0.163 - mean_eps: 0.871 - ale.lives: 3.064\n",
      "\n",
      "Interval 288 (143500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.123 - mean_q: 0.164 - mean_eps: 0.871 - ale.lives: 2.902\n",
      "\n",
      "Interval 289 (144000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.122 - mean_q: 0.163 - mean_eps: 0.870 - ale.lives: 3.310\n",
      "\n",
      "Interval 290 (144500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.123 - mean_q: 0.164 - mean_eps: 0.870 - ale.lives: 2.912\n",
      "\n",
      "Interval 291 (145000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.000 - mae: 0.122 - mean_q: 0.163 - mean_eps: 0.869 - ale.lives: 2.972\n",
      "\n",
      "Interval 292 (145500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.000 - mae: 0.125 - mean_q: 0.167 - mean_eps: 0.869 - ale.lives: 2.798\n",
      "\n",
      "Interval 293 (146000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.124 - mean_q: 0.166 - mean_eps: 0.868 - ale.lives: 3.118\n",
      "\n",
      "Interval 294 (146500 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.000 - mae: 0.121 - mean_q: 0.162 - mean_eps: 0.868 - ale.lives: 2.990\n",
      "\n",
      "Interval 295 (147000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.124 - mean_q: 0.165 - mean_eps: 0.867 - ale.lives: 3.028\n",
      "\n",
      "Interval 296 (147500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.125 - mean_q: 0.168 - mean_eps: 0.867 - ale.lives: 2.952\n",
      "\n",
      "Interval 297 (148000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.000 - mae: 0.124 - mean_q: 0.166 - mean_eps: 0.867 - ale.lives: 2.866\n",
      "\n",
      "Interval 298 (148500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.126 - mean_q: 0.168 - mean_eps: 0.866 - ale.lives: 3.096\n",
      "\n",
      "Interval 299 (149000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.000 - mae: 0.119 - mean_q: 0.160 - mean_eps: 0.866 - ale.lives: 3.608\n",
      "\n",
      "Interval 300 (149500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.124 - mean_q: 0.165 - mean_eps: 0.865 - ale.lives: 2.884\n",
      "\n",
      "Interval 301 (150000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.003 - mae: 0.136 - mean_q: 0.180 - mean_eps: 0.865 - ale.lives: 2.870\n",
      "\n",
      "Interval 302 (150500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.132 - mean_q: 0.176 - mean_eps: 0.864 - ale.lives: 3.096\n",
      "\n",
      "Interval 303 (151000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.001 - mae: 0.128 - mean_q: 0.171 - mean_eps: 0.864 - ale.lives: 3.168\n",
      "\n",
      "Interval 304 (151500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.000 - mae: 0.131 - mean_q: 0.175 - mean_eps: 0.863 - ale.lives: 2.278\n",
      "\n",
      "Interval 305 (152000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.132 - mean_q: 0.176 - mean_eps: 0.863 - ale.lives: 2.644\n",
      "\n",
      "Interval 306 (152500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.001 - mae: 0.130 - mean_q: 0.173 - mean_eps: 0.863 - ale.lives: 3.104\n",
      "\n",
      "Interval 307 (153000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.000 - mae: 0.133 - mean_q: 0.178 - mean_eps: 0.862 - ale.lives: 3.042\n",
      "\n",
      "Interval 308 (153500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.000 - mae: 0.129 - mean_q: 0.173 - mean_eps: 0.862 - ale.lives: 3.506\n",
      "\n",
      "Interval 309 (154000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.134 - mean_q: 0.178 - mean_eps: 0.861 - ale.lives: 3.012\n",
      "\n",
      "Interval 310 (154500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.126 - mean_q: 0.169 - mean_eps: 0.861 - ale.lives: 2.990\n",
      "\n",
      "Interval 311 (155000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.130 - mean_q: 0.174 - mean_eps: 0.860 - ale.lives: 3.126\n",
      "\n",
      "Interval 312 (155500 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.000 - mae: 0.128 - mean_q: 0.171 - mean_eps: 0.860 - ale.lives: 3.034\n",
      "\n",
      "Interval 313 (156000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.131 - mean_q: 0.174 - mean_eps: 0.859 - ale.lives: 3.242\n",
      "\n",
      "Interval 314 (156500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.000 - mae: 0.124 - mean_q: 0.166 - mean_eps: 0.859 - ale.lives: 2.670\n",
      "\n",
      "Interval 315 (157000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.135 - mean_q: 0.181 - mean_eps: 0.858 - ale.lives: 2.620\n",
      "\n",
      "Interval 316 (157500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.000 - mae: 0.130 - mean_q: 0.175 - mean_eps: 0.858 - ale.lives: 2.884\n",
      "\n",
      "Interval 317 (158000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.136 - mean_q: 0.182 - mean_eps: 0.858 - ale.lives: 2.434\n",
      "\n",
      "Interval 318 (158500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.135 - mean_q: 0.180 - mean_eps: 0.857 - ale.lives: 2.472\n",
      "\n",
      "Interval 319 (159000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.000 - mae: 0.123 - mean_q: 0.164 - mean_eps: 0.857 - ale.lives: 2.970\n",
      "\n",
      "Interval 320 (159500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.129 - mean_q: 0.172 - mean_eps: 0.856 - ale.lives: 2.902\n",
      "\n",
      "Interval 321 (160000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.141 - mean_q: 0.188 - mean_eps: 0.856 - ale.lives: 3.042\n",
      "\n",
      "Interval 322 (160500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.250 [0.000, 1.000] - loss: 0.002 - mae: 0.145 - mean_q: 0.191 - mean_eps: 0.855 - ale.lives: 2.916\n",
      "\n",
      "Interval 323 (161000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.001 - mae: 0.141 - mean_q: 0.187 - mean_eps: 0.855 - ale.lives: 3.052\n",
      "\n",
      "Interval 324 (161500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.001 - mae: 0.140 - mean_q: 0.186 - mean_eps: 0.854 - ale.lives: 2.978\n",
      "\n",
      "Interval 325 (162000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.136 - mean_q: 0.183 - mean_eps: 0.854 - ale.lives: 2.890\n",
      "\n",
      "Interval 326 (162500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.133 - mean_q: 0.178 - mean_eps: 0.854 - ale.lives: 2.264\n",
      "\n",
      "Interval 327 (163000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.001 - mae: 0.145 - mean_q: 0.194 - mean_eps: 0.853 - ale.lives: 2.926\n",
      "\n",
      "Interval 328 (163500 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.149 - mean_q: 0.199 - mean_eps: 0.853 - ale.lives: 3.046\n",
      "\n",
      "Interval 329 (164000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.000 - mae: 0.143 - mean_q: 0.191 - mean_eps: 0.852 - ale.lives: 3.352\n",
      "\n",
      "Interval 330 (164500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.000 - mae: 0.137 - mean_q: 0.183 - mean_eps: 0.852 - ale.lives: 3.076\n",
      "\n",
      "Interval 331 (165000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.141 - mean_q: 0.187 - mean_eps: 0.851 - ale.lives: 3.048\n",
      "\n",
      "Interval 332 (165500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.000 - mae: 0.141 - mean_q: 0.188 - mean_eps: 0.851 - ale.lives: 3.022\n",
      "\n",
      "Interval 333 (166000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.000 - mae: 0.139 - mean_q: 0.186 - mean_eps: 0.850 - ale.lives: 3.136\n",
      "\n",
      "Interval 334 (166500 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.000 - mae: 0.140 - mean_q: 0.187 - mean_eps: 0.850 - ale.lives: 3.350\n",
      "\n",
      "Interval 335 (167000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.141 - mean_q: 0.188 - mean_eps: 0.849 - ale.lives: 2.988\n",
      "\n",
      "Interval 336 (167500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.142 - mean_q: 0.190 - mean_eps: 0.849 - ale.lives: 2.880\n",
      "\n",
      "Interval 337 (168000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.000 - mae: 0.137 - mean_q: 0.182 - mean_eps: 0.849 - ale.lives: 2.260\n",
      "\n",
      "Interval 338 (168500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.000 - mae: 0.142 - mean_q: 0.190 - mean_eps: 0.848 - ale.lives: 2.400\n",
      "\n",
      "Interval 339 (169000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.000 - mae: 0.140 - mean_q: 0.186 - mean_eps: 0.848 - ale.lives: 3.108\n",
      "\n",
      "Interval 340 (169500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.139 - mean_q: 0.186 - mean_eps: 0.847 - ale.lives: 2.860\n",
      "\n",
      "Interval 341 (170000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.153 - mean_q: 0.205 - mean_eps: 0.847 - ale.lives: 3.268\n",
      "\n",
      "Interval 342 (170500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.156 - mean_q: 0.208 - mean_eps: 0.846 - ale.lives: 2.910\n",
      "\n",
      "Interval 343 (171000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.001 - mae: 0.155 - mean_q: 0.206 - mean_eps: 0.846 - ale.lives: 2.942\n",
      "\n",
      "Interval 344 (171500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.152 - mean_q: 0.203 - mean_eps: 0.845 - ale.lives: 2.886\n",
      "\n",
      "Interval 345 (172000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.151 - mean_q: 0.202 - mean_eps: 0.845 - ale.lives: 2.920\n",
      "\n",
      "Interval 346 (172500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.149 - mean_q: 0.199 - mean_eps: 0.845 - ale.lives: 2.552\n",
      "\n",
      "Interval 347 (173000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.150 - mean_q: 0.199 - mean_eps: 0.844 - ale.lives: 2.800\n",
      "\n",
      "Interval 348 (173500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.000 - mae: 0.148 - mean_q: 0.198 - mean_eps: 0.844 - ale.lives: 2.976\n",
      "\n",
      "Interval 349 (174000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.001 - mae: 0.148 - mean_q: 0.196 - mean_eps: 0.843 - ale.lives: 2.922\n",
      "\n",
      "Interval 350 (174500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.001 - mae: 0.148 - mean_q: 0.197 - mean_eps: 0.843 - ale.lives: 3.396\n",
      "\n",
      "Interval 351 (175000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.145 - mean_q: 0.193 - mean_eps: 0.842 - ale.lives: 2.884\n",
      "\n",
      "Interval 352 (175500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.143 - mean_q: 0.190 - mean_eps: 0.842 - ale.lives: 2.980\n",
      "\n",
      "Interval 353 (176000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.152 - mean_q: 0.203 - mean_eps: 0.841 - ale.lives: 2.798\n",
      "\n",
      "Interval 354 (176500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.000 - mae: 0.144 - mean_q: 0.192 - mean_eps: 0.841 - ale.lives: 2.960\n",
      "\n",
      "Interval 355 (177000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.144 - mean_q: 0.192 - mean_eps: 0.840 - ale.lives: 2.964\n",
      "\n",
      "Interval 356 (177500 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.144 - mean_q: 0.191 - mean_eps: 0.840 - ale.lives: 3.158\n",
      "\n",
      "Interval 357 (178000 steps performed)\n",
      "500/500 [==============================] - 21s 42ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.000 - mae: 0.150 - mean_q: 0.199 - mean_eps: 0.840 - ale.lives: 3.080\n",
      "\n",
      "Interval 358 (178500 steps performed)\n",
      "500/500 [==============================] - 21s 42ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.150 - mean_q: 0.200 - mean_eps: 0.839 - ale.lives: 3.204\n",
      "\n",
      "Interval 359 (179000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.000 - mae: 0.157 - mean_q: 0.208 - mean_eps: 0.839 - ale.lives: 3.074\n",
      "\n",
      "Interval 360 (179500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.144 - mean_q: 0.192 - mean_eps: 0.838 - ale.lives: 3.004\n",
      "\n",
      "Interval 361 (180000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.003 - mae: 0.164 - mean_q: 0.219 - mean_eps: 0.838 - ale.lives: 2.972\n",
      "\n",
      "Interval 362 (180500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.161 - mean_q: 0.215 - mean_eps: 0.837 - ale.lives: 2.890\n",
      "\n",
      "Interval 363 (181000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0000e+00\n",
      "4 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.161 - mean_q: 0.214 - mean_eps: 0.837 - ale.lives: 2.912\n",
      "\n",
      "Interval 364 (181500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.160 - mean_q: 0.213 - mean_eps: 0.836 - ale.lives: 3.112\n",
      "\n",
      "Interval 365 (182000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.161 - mean_q: 0.214 - mean_eps: 0.836 - ale.lives: 2.722\n",
      "\n",
      "Interval 366 (182500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.155 - mean_q: 0.207 - mean_eps: 0.836 - ale.lives: 3.372\n",
      "\n",
      "Interval 367 (183000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.001 - mae: 0.165 - mean_q: 0.219 - mean_eps: 0.835 - ale.lives: 2.922\n",
      "\n",
      "Interval 368 (183500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.163 - mean_q: 0.216 - mean_eps: 0.835 - ale.lives: 3.136\n",
      "\n",
      "Interval 369 (184000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.162 - mean_q: 0.216 - mean_eps: 0.834 - ale.lives: 3.006\n",
      "\n",
      "Interval 370 (184500 steps performed)\n",
      "500/500 [==============================] - 22s 43ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.163 - mean_q: 0.217 - mean_eps: 0.834 - ale.lives: 2.824\n",
      "\n",
      "Interval 371 (185000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.161 - mean_q: 0.214 - mean_eps: 0.833 - ale.lives: 2.612\n",
      "\n",
      "Interval 372 (185500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.164 - mean_q: 0.218 - mean_eps: 0.833 - ale.lives: 2.864\n",
      "\n",
      "Interval 373 (186000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.164 - mean_q: 0.219 - mean_eps: 0.832 - ale.lives: 3.054\n",
      "\n",
      "Interval 374 (186500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.000 - mae: 0.160 - mean_q: 0.213 - mean_eps: 0.832 - ale.lives: 2.684\n",
      "\n",
      "Interval 375 (187000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.156 - mean_q: 0.209 - mean_eps: 0.831 - ale.lives: 2.978\n",
      "\n",
      "Interval 376 (187500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.000 - mae: 0.161 - mean_q: 0.215 - mean_eps: 0.831 - ale.lives: 2.872\n",
      "\n",
      "Interval 377 (188000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.000 - mae: 0.163 - mean_q: 0.217 - mean_eps: 0.831 - ale.lives: 3.224\n",
      "\n",
      "Interval 378 (188500 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.000 - mae: 0.155 - mean_q: 0.207 - mean_eps: 0.830 - ale.lives: 2.668\n",
      "\n",
      "Interval 379 (189000 steps performed)\n",
      "500/500 [==============================] - 21s 43ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.000 - mae: 0.164 - mean_q: 0.219 - mean_eps: 0.830 - ale.lives: 2.794\n",
      "\n",
      "Interval 380 (189500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.000 - mae: 0.158 - mean_q: 0.211 - mean_eps: 0.829 - ale.lives: 2.614\n",
      "\n",
      "Interval 381 (190000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 0.166 - mean_q: 0.220 - mean_eps: 0.829 - ale.lives: 3.312\n",
      "\n",
      "Interval 382 (190500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.003 - mae: 0.176 - mean_q: 0.233 - mean_eps: 0.828 - ale.lives: 2.648\n",
      "\n",
      "Interval 383 (191000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.168 - mean_q: 0.223 - mean_eps: 0.828 - ale.lives: 3.044\n",
      "\n",
      "Interval 384 (191500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.167 - mean_q: 0.223 - mean_eps: 0.827 - ale.lives: 3.018\n",
      "\n",
      "Interval 385 (192000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.163 - mean_q: 0.217 - mean_eps: 0.827 - ale.lives: 3.180\n",
      "\n",
      "Interval 386 (192500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.001 - mae: 0.171 - mean_q: 0.228 - mean_eps: 0.827 - ale.lives: 2.832\n",
      "\n",
      "Interval 387 (193000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.000 - mae: 0.172 - mean_q: 0.228 - mean_eps: 0.826 - ale.lives: 2.666\n",
      "\n",
      "Interval 388 (193500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.168 - mean_q: 0.224 - mean_eps: 0.826 - ale.lives: 2.688\n",
      "\n",
      "Interval 389 (194000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.000 - mae: 0.167 - mean_q: 0.222 - mean_eps: 0.825 - ale.lives: 2.850\n",
      "\n",
      "Interval 390 (194500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.000 - mae: 0.161 - mean_q: 0.214 - mean_eps: 0.825 - ale.lives: 2.790\n",
      "\n",
      "Interval 391 (195000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.169 - mean_q: 0.226 - mean_eps: 0.824 - ale.lives: 3.514\n",
      "\n",
      "Interval 392 (195500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.000 - mae: 0.173 - mean_q: 0.231 - mean_eps: 0.824 - ale.lives: 3.150\n",
      "\n",
      "Interval 393 (196000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.170 - mean_q: 0.227 - mean_eps: 0.823 - ale.lives: 2.878\n",
      "\n",
      "Interval 394 (196500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.171 - mean_q: 0.228 - mean_eps: 0.823 - ale.lives: 2.888\n",
      "\n",
      "Interval 395 (197000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.000 - mae: 0.158 - mean_q: 0.211 - mean_eps: 0.822 - ale.lives: 2.794\n",
      "\n",
      "Interval 396 (197500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.168 - mean_q: 0.223 - mean_eps: 0.822 - ale.lives: 2.854\n",
      "\n",
      "Interval 397 (198000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.000 - mae: 0.160 - mean_q: 0.214 - mean_eps: 0.822 - ale.lives: 2.728\n",
      "\n",
      "Interval 398 (198500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.000 - mae: 0.169 - mean_q: 0.225 - mean_eps: 0.821 - ale.lives: 2.732\n",
      "\n",
      "Interval 399 (199000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.000 - mae: 0.158 - mean_q: 0.211 - mean_eps: 0.821 - ale.lives: 2.788\n",
      "\n",
      "Interval 400 (199500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.000 - mae: 0.158 - mean_q: 0.211 - mean_eps: 0.820 - ale.lives: 2.968\n",
      "\n",
      "Interval 401 (200000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 0.177 - mean_q: 0.234 - mean_eps: 0.820 - ale.lives: 3.154\n",
      "\n",
      "Interval 402 (200500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.162 - mean_q: 0.216 - mean_eps: 0.819 - ale.lives: 3.112\n",
      "\n",
      "Interval 403 (201000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.167 - mean_q: 0.223 - mean_eps: 0.819 - ale.lives: 3.024\n",
      "\n",
      "Interval 404 (201500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.166 - mean_q: 0.223 - mean_eps: 0.818 - ale.lives: 3.268\n",
      "\n",
      "Interval 405 (202000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.177 - mean_q: 0.237 - mean_eps: 0.818 - ale.lives: 2.924\n",
      "\n",
      "Interval 406 (202500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.001 - mae: 0.173 - mean_q: 0.232 - mean_eps: 0.818 - ale.lives: 2.942\n",
      "\n",
      "Interval 407 (203000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.001 - mae: 0.176 - mean_q: 0.235 - mean_eps: 0.817 - ale.lives: 3.138\n",
      "\n",
      "Interval 408 (203500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.176 - mean_q: 0.236 - mean_eps: 0.817 - ale.lives: 2.896\n",
      "\n",
      "Interval 409 (204000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.170 - mean_q: 0.227 - mean_eps: 0.816 - ale.lives: 3.586\n",
      "\n",
      "Interval 410 (204500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.169 - mean_q: 0.225 - mean_eps: 0.816 - ale.lives: 2.798\n",
      "\n",
      "Interval 411 (205000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0020\n",
      "4 episodes - episode_reward: 0.250 [0.000, 1.000] - loss: 0.001 - mae: 0.176 - mean_q: 0.233 - mean_eps: 0.815 - ale.lives: 2.796\n",
      "\n",
      "Interval 412 (205500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.178 - mean_q: 0.238 - mean_eps: 0.815 - ale.lives: 3.176\n",
      "\n",
      "Interval 413 (206000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.175 - mean_q: 0.233 - mean_eps: 0.814 - ale.lives: 2.888\n",
      "\n",
      "Interval 414 (206500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.000 - mae: 0.174 - mean_q: 0.232 - mean_eps: 0.814 - ale.lives: 2.668\n",
      "\n",
      "Interval 415 (207000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.176 - mean_q: 0.236 - mean_eps: 0.813 - ale.lives: 3.220\n",
      "\n",
      "Interval 416 (207500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.000 - mae: 0.177 - mean_q: 0.236 - mean_eps: 0.813 - ale.lives: 2.826\n",
      "\n",
      "Interval 417 (208000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.000 - mae: 0.175 - mean_q: 0.234 - mean_eps: 0.813 - ale.lives: 3.076\n",
      "\n",
      "Interval 418 (208500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.000 - mae: 0.172 - mean_q: 0.229 - mean_eps: 0.812 - ale.lives: 2.430\n",
      "\n",
      "Interval 419 (209000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.181 - mean_q: 0.242 - mean_eps: 0.812 - ale.lives: 2.974\n",
      "\n",
      "Interval 420 (209500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.000 - mae: 0.178 - mean_q: 0.237 - mean_eps: 0.811 - ale.lives: 2.946\n",
      "\n",
      "Interval 421 (210000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.003 - mae: 0.182 - mean_q: 0.244 - mean_eps: 0.811 - ale.lives: 2.834\n",
      "\n",
      "Interval 422 (210500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.178 - mean_q: 0.238 - mean_eps: 0.810 - ale.lives: 2.986\n",
      "\n",
      "Interval 423 (211000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.188 - mean_q: 0.250 - mean_eps: 0.810 - ale.lives: 3.034\n",
      "\n",
      "Interval 424 (211500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.187 - mean_q: 0.250 - mean_eps: 0.809 - ale.lives: 2.550\n",
      "\n",
      "Interval 425 (212000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.001 - mae: 0.185 - mean_q: 0.247 - mean_eps: 0.809 - ale.lives: 2.772\n",
      "\n",
      "Interval 426 (212500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.184 - mean_q: 0.244 - mean_eps: 0.809 - ale.lives: 3.142\n",
      "\n",
      "Interval 427 (213000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.187 - mean_q: 0.250 - mean_eps: 0.808 - ale.lives: 2.528\n",
      "\n",
      "Interval 428 (213500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.179 - mean_q: 0.239 - mean_eps: 0.808 - ale.lives: 3.080\n",
      "\n",
      "Interval 429 (214000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.001 - mae: 0.185 - mean_q: 0.247 - mean_eps: 0.807 - ale.lives: 2.880\n",
      "\n",
      "Interval 430 (214500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.185 - mean_q: 0.247 - mean_eps: 0.807 - ale.lives: 2.914\n",
      "\n",
      "Interval 431 (215000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.186 - mean_q: 0.249 - mean_eps: 0.806 - ale.lives: 2.902\n",
      "\n",
      "Interval 432 (215500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.001 - mae: 0.190 - mean_q: 0.254 - mean_eps: 0.806 - ale.lives: 3.088\n",
      "\n",
      "Interval 433 (216000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.184 - mean_q: 0.246 - mean_eps: 0.805 - ale.lives: 2.758\n",
      "\n",
      "Interval 434 (216500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.187 - mean_q: 0.250 - mean_eps: 0.805 - ale.lives: 3.364\n",
      "\n",
      "Interval 435 (217000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.188 - mean_q: 0.253 - mean_eps: 0.804 - ale.lives: 2.992\n",
      "\n",
      "Interval 436 (217500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.001 - mae: 0.186 - mean_q: 0.249 - mean_eps: 0.804 - ale.lives: 2.892\n",
      "\n",
      "Interval 437 (218000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.001 - mae: 0.188 - mean_q: 0.253 - mean_eps: 0.804 - ale.lives: 2.432\n",
      "\n",
      "Interval 438 (218500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.187 - mean_q: 0.250 - mean_eps: 0.803 - ale.lives: 2.548\n",
      "\n",
      "Interval 439 (219000 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.190 - mean_q: 0.254 - mean_eps: 0.803 - ale.lives: 2.906\n",
      "\n",
      "Interval 440 (219500 steps performed)\n",
      "500/500 [==============================] - 22s 44ms/step - reward: 0.0000e+00\n",
      "4 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 0.185 - mean_q: 0.249 - mean_eps: 0.802 - ale.lives: 2.910\n",
      "\n",
      "Interval 441 (220000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.004 - mae: 0.194 - mean_q: 0.260 - mean_eps: 0.802 - ale.lives: 2.794\n",
      "\n",
      "Interval 442 (220500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.002 - mae: 0.201 - mean_q: 0.271 - mean_eps: 0.801 - ale.lives: 2.622\n",
      "\n",
      "Interval 443 (221000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 0.197 - mean_q: 0.264 - mean_eps: 0.801 - ale.lives: 2.922\n",
      "\n",
      "Interval 444 (221500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.003 - mae: 0.193 - mean_q: 0.258 - mean_eps: 0.800 - ale.lives: 2.962\n",
      "\n",
      "Interval 445 (222000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.189 - mean_q: 0.255 - mean_eps: 0.800 - ale.lives: 2.780\n",
      "\n",
      "Interval 446 (222500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.195 - mean_q: 0.264 - mean_eps: 0.800 - ale.lives: 3.060\n",
      "\n",
      "Interval 447 (223000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.001 - mae: 0.200 - mean_q: 0.270 - mean_eps: 0.799 - ale.lives: 3.088\n",
      "\n",
      "Interval 448 (223500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.194 - mean_q: 0.262 - mean_eps: 0.799 - ale.lives: 2.736\n",
      "\n",
      "Interval 449 (224000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.198 - mean_q: 0.268 - mean_eps: 0.798 - ale.lives: 3.012\n",
      "\n",
      "Interval 450 (224500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.002 - mae: 0.196 - mean_q: 0.267 - mean_eps: 0.798 - ale.lives: 2.848\n",
      "\n",
      "Interval 451 (225000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.001 - mae: 0.195 - mean_q: 0.265 - mean_eps: 0.797 - ale.lives: 2.552\n",
      "\n",
      "Interval 452 (225500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.001 - mae: 0.194 - mean_q: 0.264 - mean_eps: 0.797 - ale.lives: 2.872\n",
      "\n",
      "Interval 453 (226000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.001 - mae: 0.195 - mean_q: 0.265 - mean_eps: 0.796 - ale.lives: 2.682\n",
      "\n",
      "Interval 454 (226500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.194 - mean_q: 0.263 - mean_eps: 0.796 - ale.lives: 3.174\n",
      "\n",
      "Interval 455 (227000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.001 - mae: 0.188 - mean_q: 0.255 - mean_eps: 0.795 - ale.lives: 2.612\n",
      "\n",
      "Interval 456 (227500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.198 - mean_q: 0.268 - mean_eps: 0.795 - ale.lives: 2.960\n",
      "\n",
      "Interval 457 (228000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.001 - mae: 0.196 - mean_q: 0.267 - mean_eps: 0.795 - ale.lives: 2.858\n",
      "\n",
      "Interval 458 (228500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.193 - mean_q: 0.263 - mean_eps: 0.794 - ale.lives: 3.148\n",
      "\n",
      "Interval 459 (229000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.001 - mae: 0.186 - mean_q: 0.253 - mean_eps: 0.794 - ale.lives: 3.080\n",
      "\n",
      "Interval 460 (229500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.001 - mae: 0.191 - mean_q: 0.258 - mean_eps: 0.793 - ale.lives: 3.008\n",
      "\n",
      "Interval 461 (230000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.004 - mae: 0.204 - mean_q: 0.277 - mean_eps: 0.793 - ale.lives: 2.630\n",
      "\n",
      "Interval 462 (230500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.212 - mean_q: 0.287 - mean_eps: 0.792 - ale.lives: 2.948\n",
      "\n",
      "Interval 463 (231000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 0.204 - mean_q: 0.280 - mean_eps: 0.792 - ale.lives: 3.282\n",
      "\n",
      "Interval 464 (231500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 0.208 - mean_q: 0.287 - mean_eps: 0.791 - ale.lives: 3.242\n",
      "\n",
      "Interval 465 (232000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 1.667 [0.000, 5.000] - loss: 0.002 - mae: 0.208 - mean_q: 0.286 - mean_eps: 0.791 - ale.lives: 2.764\n",
      "\n",
      "Interval 466 (232500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.204 - mean_q: 0.279 - mean_eps: 0.791 - ale.lives: 2.820\n",
      "\n",
      "Interval 467 (233000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.001 - mae: 0.210 - mean_q: 0.287 - mean_eps: 0.790 - ale.lives: 3.440\n",
      "\n",
      "Interval 468 (233500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [0.000, 5.000] - loss: 0.002 - mae: 0.200 - mean_q: 0.275 - mean_eps: 0.790 - ale.lives: 2.840\n",
      "\n",
      "Interval 469 (234000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.212 - mean_q: 0.290 - mean_eps: 0.789 - ale.lives: 3.206\n",
      "\n",
      "Interval 470 (234500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.001 - mae: 0.211 - mean_q: 0.291 - mean_eps: 0.789 - ale.lives: 2.756\n",
      "\n",
      "Interval 471 (235000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.001 - mae: 0.208 - mean_q: 0.283 - mean_eps: 0.788 - ale.lives: 2.994\n",
      "\n",
      "Interval 472 (235500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.001 - mae: 0.210 - mean_q: 0.286 - mean_eps: 0.788 - ale.lives: 2.812\n",
      "\n",
      "Interval 473 (236000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.001 - mae: 0.208 - mean_q: 0.286 - mean_eps: 0.787 - ale.lives: 2.726\n",
      "\n",
      "Interval 474 (236500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.210 - mean_q: 0.289 - mean_eps: 0.787 - ale.lives: 2.700\n",
      "\n",
      "Interval 475 (237000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.001 - mae: 0.207 - mean_q: 0.284 - mean_eps: 0.786 - ale.lives: 2.870\n",
      "\n",
      "Interval 476 (237500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.207 - mean_q: 0.286 - mean_eps: 0.786 - ale.lives: 3.058\n",
      "\n",
      "Interval 477 (238000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.202 - mean_q: 0.279 - mean_eps: 0.786 - ale.lives: 3.066\n",
      "\n",
      "Interval 478 (238500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "3 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.001 - mae: 0.204 - mean_q: 0.282 - mean_eps: 0.785 - ale.lives: 3.178\n",
      "\n",
      "Interval 479 (239000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.001 - mae: 0.204 - mean_q: 0.280 - mean_eps: 0.785 - ale.lives: 3.418\n",
      "\n",
      "Interval 480 (239500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.207 - mean_q: 0.286 - mean_eps: 0.784 - ale.lives: 3.050\n",
      "\n",
      "Interval 481 (240000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.004 - mae: 0.220 - mean_q: 0.305 - mean_eps: 0.784 - ale.lives: 2.982\n",
      "\n",
      "Interval 482 (240500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 0.217 - mean_q: 0.300 - mean_eps: 0.783 - ale.lives: 2.814\n",
      "\n",
      "Interval 483 (241000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.002 - mae: 0.215 - mean_q: 0.299 - mean_eps: 0.783 - ale.lives: 2.934\n",
      "\n",
      "Interval 484 (241500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.002 - mae: 0.213 - mean_q: 0.296 - mean_eps: 0.782 - ale.lives: 2.930\n",
      "\n",
      "Interval 485 (242000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 0.225 - mean_q: 0.313 - mean_eps: 0.782 - ale.lives: 2.876\n",
      "\n",
      "Interval 486 (242500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.001 - mae: 0.213 - mean_q: 0.295 - mean_eps: 0.782 - ale.lives: 3.186\n",
      "\n",
      "Interval 487 (243000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.001 - mae: 0.221 - mean_q: 0.306 - mean_eps: 0.781 - ale.lives: 2.924\n",
      "\n",
      "Interval 488 (243500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.001 - mae: 0.213 - mean_q: 0.294 - mean_eps: 0.781 - ale.lives: 2.696\n",
      "\n",
      "Interval 489 (244000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [0.000, 5.000] - loss: 0.001 - mae: 0.223 - mean_q: 0.309 - mean_eps: 0.780 - ale.lives: 3.018\n",
      "\n",
      "Interval 490 (244500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.213 - mean_q: 0.298 - mean_eps: 0.780 - ale.lives: 2.710\n",
      "\n",
      "Interval 491 (245000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.001 - mae: 0.230 - mean_q: 0.320 - mean_eps: 0.779 - ale.lives: 2.876\n",
      "\n",
      "Interval 492 (245500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.209 - mean_q: 0.292 - mean_eps: 0.779 - ale.lives: 2.908\n",
      "\n",
      "Interval 493 (246000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.223 - mean_q: 0.312 - mean_eps: 0.778 - ale.lives: 3.478\n",
      "\n",
      "Interval 494 (246500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.667 [1.000, 5.000] - loss: 0.001 - mae: 0.218 - mean_q: 0.305 - mean_eps: 0.778 - ale.lives: 3.092\n",
      "\n",
      "Interval 495 (247000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.001 - mae: 0.224 - mean_q: 0.313 - mean_eps: 0.777 - ale.lives: 3.324\n",
      "\n",
      "Interval 496 (247500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.002 - mae: 0.219 - mean_q: 0.307 - mean_eps: 0.777 - ale.lives: 3.076\n",
      "\n",
      "Interval 497 (248000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.226 - mean_q: 0.314 - mean_eps: 0.777 - ale.lives: 3.042\n",
      "\n",
      "Interval 498 (248500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.001 - mae: 0.221 - mean_q: 0.307 - mean_eps: 0.776 - ale.lives: 2.854\n",
      "\n",
      "Interval 499 (249000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.001 - mae: 0.225 - mean_q: 0.314 - mean_eps: 0.776 - ale.lives: 2.952\n",
      "\n",
      "Interval 500 (249500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.001 - mae: 0.218 - mean_q: 0.305 - mean_eps: 0.775 - ale.lives: 2.778\n",
      "\n",
      "Interval 501 (250000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.005 - mae: 0.240 - mean_q: 0.333 - mean_eps: 0.775 - ale.lives: 3.004\n",
      "\n",
      "Interval 502 (250500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.003 - mae: 0.243 - mean_q: 0.338 - mean_eps: 0.774 - ale.lives: 3.032\n",
      "\n",
      "Interval 503 (251000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 0.249 - mean_q: 0.347 - mean_eps: 0.774 - ale.lives: 2.676\n",
      "\n",
      "Interval 504 (251500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.002 - mae: 0.238 - mean_q: 0.332 - mean_eps: 0.773 - ale.lives: 2.970\n",
      "\n",
      "Interval 505 (252000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.002 - mae: 0.244 - mean_q: 0.342 - mean_eps: 0.773 - ale.lives: 2.946\n",
      "\n",
      "Interval 506 (252500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 0.237 - mean_q: 0.331 - mean_eps: 0.773 - ale.lives: 3.258\n",
      "\n",
      "Interval 507 (253000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.002 - mae: 0.243 - mean_q: 0.339 - mean_eps: 0.772 - ale.lives: 3.002\n",
      "\n",
      "Interval 508 (253500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.236 - mean_q: 0.332 - mean_eps: 0.772 - ale.lives: 2.326\n",
      "\n",
      "Interval 509 (254000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.235 - mean_q: 0.327 - mean_eps: 0.771 - ale.lives: 2.610\n",
      "\n",
      "Interval 510 (254500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.244 - mean_q: 0.343 - mean_eps: 0.771 - ale.lives: 3.018\n",
      "\n",
      "Interval 511 (255000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 0.233 - mean_q: 0.327 - mean_eps: 0.770 - ale.lives: 2.432\n",
      "\n",
      "Interval 512 (255500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 0.230 - mean_q: 0.321 - mean_eps: 0.770 - ale.lives: 3.472\n",
      "\n",
      "Interval 513 (256000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [1.000, 3.000] - loss: 0.001 - mae: 0.243 - mean_q: 0.342 - mean_eps: 0.769 - ale.lives: 2.568\n",
      "\n",
      "Interval 514 (256500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.236 - mean_q: 0.330 - mean_eps: 0.769 - ale.lives: 2.642\n",
      "\n",
      "Interval 515 (257000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.002 - mae: 0.239 - mean_q: 0.333 - mean_eps: 0.768 - ale.lives: 2.904\n",
      "\n",
      "Interval 516 (257500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.232 - mean_q: 0.323 - mean_eps: 0.768 - ale.lives: 3.006\n",
      "\n",
      "Interval 517 (258000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 0.237 - mean_q: 0.334 - mean_eps: 0.768 - ale.lives: 3.378\n",
      "\n",
      "Interval 518 (258500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.001 - mae: 0.246 - mean_q: 0.343 - mean_eps: 0.767 - ale.lives: 2.902\n",
      "\n",
      "Interval 519 (259000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.236 - mean_q: 0.331 - mean_eps: 0.767 - ale.lives: 2.706\n",
      "\n",
      "Interval 520 (259500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.001 - mae: 0.243 - mean_q: 0.341 - mean_eps: 0.766 - ale.lives: 2.824\n",
      "\n",
      "Interval 521 (260000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.008 - mae: 0.276 - mean_q: 0.382 - mean_eps: 0.766 - ale.lives: 3.440\n",
      "\n",
      "Interval 522 (260500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.004 - mae: 0.267 - mean_q: 0.376 - mean_eps: 0.765 - ale.lives: 2.976\n",
      "\n",
      "Interval 523 (261000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 0.268 - mean_q: 0.380 - mean_eps: 0.765 - ale.lives: 2.674\n",
      "\n",
      "Interval 524 (261500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.266 - mean_q: 0.376 - mean_eps: 0.764 - ale.lives: 2.678\n",
      "\n",
      "Interval 525 (262000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 0.277 - mean_q: 0.390 - mean_eps: 0.764 - ale.lives: 2.550\n",
      "\n",
      "Interval 526 (262500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.333 [0.000, 4.000] - loss: 0.002 - mae: 0.266 - mean_q: 0.375 - mean_eps: 0.764 - ale.lives: 3.184\n",
      "\n",
      "Interval 527 (263000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.264 - mean_q: 0.373 - mean_eps: 0.763 - ale.lives: 3.138\n",
      "\n",
      "Interval 528 (263500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.002 - mae: 0.270 - mean_q: 0.382 - mean_eps: 0.763 - ale.lives: 2.736\n",
      "\n",
      "Interval 529 (264000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.002 - mae: 0.273 - mean_q: 0.383 - mean_eps: 0.762 - ale.lives: 2.746\n",
      "\n",
      "Interval 530 (264500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.266 - mean_q: 0.377 - mean_eps: 0.762 - ale.lives: 3.442\n",
      "\n",
      "Interval 531 (265000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 0.259 - mean_q: 0.369 - mean_eps: 0.761 - ale.lives: 3.014\n",
      "\n",
      "Interval 532 (265500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 0.271 - mean_q: 0.383 - mean_eps: 0.761 - ale.lives: 2.668\n",
      "\n",
      "Interval 533 (266000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.002 - mae: 0.265 - mean_q: 0.376 - mean_eps: 0.760 - ale.lives: 2.988\n",
      "\n",
      "Interval 534 (266500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.263 - mean_q: 0.375 - mean_eps: 0.760 - ale.lives: 3.348\n",
      "\n",
      "Interval 535 (267000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.002 - mae: 0.258 - mean_q: 0.366 - mean_eps: 0.759 - ale.lives: 2.882\n",
      "\n",
      "Interval 536 (267500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.265 - mean_q: 0.378 - mean_eps: 0.759 - ale.lives: 2.876\n",
      "\n",
      "Interval 537 (268000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 0.266 - mean_q: 0.380 - mean_eps: 0.759 - ale.lives: 2.998\n",
      "\n",
      "Interval 538 (268500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.001 - mae: 0.254 - mean_q: 0.362 - mean_eps: 0.758 - ale.lives: 2.472\n",
      "\n",
      "Interval 539 (269000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.268 - mean_q: 0.381 - mean_eps: 0.758 - ale.lives: 3.588\n",
      "\n",
      "Interval 540 (269500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.001 - mae: 0.262 - mean_q: 0.371 - mean_eps: 0.757 - ale.lives: 3.084\n",
      "\n",
      "Interval 541 (270000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.007 - mae: 0.295 - mean_q: 0.414 - mean_eps: 0.757 - ale.lives: 2.784\n",
      "\n",
      "Interval 542 (270500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.003 - mae: 0.298 - mean_q: 0.423 - mean_eps: 0.756 - ale.lives: 2.438\n",
      "\n",
      "Interval 543 (271000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.003 - mae: 0.297 - mean_q: 0.420 - mean_eps: 0.756 - ale.lives: 3.714\n",
      "\n",
      "Interval 544 (271500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 0.290 - mean_q: 0.413 - mean_eps: 0.755 - ale.lives: 3.070\n",
      "\n",
      "Interval 545 (272000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 0.287 - mean_q: 0.409 - mean_eps: 0.755 - ale.lives: 2.878\n",
      "\n",
      "Interval 546 (272500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.290 - mean_q: 0.412 - mean_eps: 0.755 - ale.lives: 2.924\n",
      "\n",
      "Interval 547 (273000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 0.301 - mean_q: 0.426 - mean_eps: 0.754 - ale.lives: 3.026\n",
      "\n",
      "Interval 548 (273500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.291 - mean_q: 0.411 - mean_eps: 0.754 - ale.lives: 3.486\n",
      "\n",
      "Interval 549 (274000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.292 - mean_q: 0.414 - mean_eps: 0.753 - ale.lives: 2.046\n",
      "\n",
      "Interval 550 (274500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.300 - mean_q: 0.426 - mean_eps: 0.753 - ale.lives: 2.772\n",
      "\n",
      "Interval 551 (275000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.002 - mae: 0.292 - mean_q: 0.414 - mean_eps: 0.752 - ale.lives: 3.344\n",
      "\n",
      "Interval 552 (275500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 0.297 - mean_q: 0.420 - mean_eps: 0.752 - ale.lives: 3.264\n",
      "\n",
      "Interval 553 (276000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 0.304 - mean_q: 0.430 - mean_eps: 0.751 - ale.lives: 2.872\n",
      "\n",
      "Interval 554 (276500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.292 - mean_q: 0.411 - mean_eps: 0.751 - ale.lives: 2.726\n",
      "\n",
      "Interval 555 (277000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 0.302 - mean_q: 0.425 - mean_eps: 0.750 - ale.lives: 2.940\n",
      "\n",
      "Interval 556 (277500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.002 - mae: 0.289 - mean_q: 0.406 - mean_eps: 0.750 - ale.lives: 2.778\n",
      "\n",
      "Interval 557 (278000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.294 - mean_q: 0.416 - mean_eps: 0.750 - ale.lives: 3.180\n",
      "\n",
      "Interval 558 (278500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.294 - mean_q: 0.415 - mean_eps: 0.749 - ale.lives: 2.804\n",
      "\n",
      "Interval 559 (279000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.292 - mean_q: 0.415 - mean_eps: 0.749 - ale.lives: 2.836\n",
      "\n",
      "Interval 560 (279500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.298 - mean_q: 0.419 - mean_eps: 0.748 - ale.lives: 3.056\n",
      "\n",
      "Interval 561 (280000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.010 - mae: 0.321 - mean_q: 0.451 - mean_eps: 0.748 - ale.lives: 3.506\n",
      "\n",
      "Interval 562 (280500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 0.317 - mean_q: 0.449 - mean_eps: 0.747 - ale.lives: 3.144\n",
      "\n",
      "Interval 563 (281000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.003 - mae: 0.326 - mean_q: 0.462 - mean_eps: 0.747 - ale.lives: 2.888\n",
      "\n",
      "Interval 564 (281500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.002 - mae: 0.323 - mean_q: 0.455 - mean_eps: 0.746 - ale.lives: 2.814\n",
      "\n",
      "Interval 565 (282000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.331 - mean_q: 0.467 - mean_eps: 0.746 - ale.lives: 2.888\n",
      "\n",
      "Interval 566 (282500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.002 - mae: 0.315 - mean_q: 0.447 - mean_eps: 0.746 - ale.lives: 3.246\n",
      "\n",
      "Interval 567 (283000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.317 - mean_q: 0.452 - mean_eps: 0.745 - ale.lives: 2.850\n",
      "\n",
      "Interval 568 (283500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 0.314 - mean_q: 0.445 - mean_eps: 0.745 - ale.lives: 3.020\n",
      "\n",
      "Interval 569 (284000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.002 - mae: 0.319 - mean_q: 0.453 - mean_eps: 0.744 - ale.lives: 2.822\n",
      "\n",
      "Interval 570 (284500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.316 - mean_q: 0.447 - mean_eps: 0.744 - ale.lives: 3.262\n",
      "\n",
      "Interval 571 (285000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.319 - mean_q: 0.451 - mean_eps: 0.743 - ale.lives: 3.216\n",
      "\n",
      "Interval 572 (285500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "3 episodes - episode_reward: 2.333 [1.000, 5.000] - loss: 0.002 - mae: 0.325 - mean_q: 0.460 - mean_eps: 0.743 - ale.lives: 2.564\n",
      "\n",
      "Interval 573 (286000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 0.315 - mean_q: 0.445 - mean_eps: 0.742 - ale.lives: 3.022\n",
      "\n",
      "Interval 574 (286500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 0.323 - mean_q: 0.460 - mean_eps: 0.742 - ale.lives: 2.564\n",
      "\n",
      "Interval 575 (287000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.306 - mean_q: 0.432 - mean_eps: 0.741 - ale.lives: 3.132\n",
      "\n",
      "Interval 576 (287500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 0.320 - mean_q: 0.456 - mean_eps: 0.741 - ale.lives: 2.900\n",
      "\n",
      "Interval 577 (288000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.315 - mean_q: 0.447 - mean_eps: 0.741 - ale.lives: 2.910\n",
      "\n",
      "Interval 578 (288500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.314 - mean_q: 0.446 - mean_eps: 0.740 - ale.lives: 3.098\n",
      "\n",
      "Interval 579 (289000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 0.311 - mean_q: 0.443 - mean_eps: 0.740 - ale.lives: 2.918\n",
      "\n",
      "Interval 580 (289500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.001 - mae: 0.318 - mean_q: 0.455 - mean_eps: 0.739 - ale.lives: 2.484\n",
      "\n",
      "Interval 581 (290000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.010 - mae: 0.349 - mean_q: 0.487 - mean_eps: 0.739 - ale.lives: 2.512\n",
      "\n",
      "Interval 582 (290500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.004 - mae: 0.343 - mean_q: 0.482 - mean_eps: 0.738 - ale.lives: 2.838\n",
      "\n",
      "Interval 583 (291000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 0.357 - mean_q: 0.501 - mean_eps: 0.738 - ale.lives: 3.580\n",
      "\n",
      "Interval 584 (291500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.003 - mae: 0.354 - mean_q: 0.500 - mean_eps: 0.737 - ale.lives: 2.940\n",
      "\n",
      "Interval 585 (292000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [0.000, 6.000] - loss: 0.003 - mae: 0.341 - mean_q: 0.481 - mean_eps: 0.737 - ale.lives: 2.542\n",
      "\n",
      "Interval 586 (292500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.349 - mean_q: 0.489 - mean_eps: 0.737 - ale.lives: 2.500\n",
      "\n",
      "Interval 587 (293000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "3 episodes - episode_reward: 2.667 [2.000, 3.000] - loss: 0.003 - mae: 0.346 - mean_q: 0.485 - mean_eps: 0.736 - ale.lives: 3.482\n",
      "\n",
      "Interval 588 (293500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 0.355 - mean_q: 0.499 - mean_eps: 0.736 - ale.lives: 2.820\n",
      "\n",
      "Interval 589 (294000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.359 - mean_q: 0.505 - mean_eps: 0.735 - ale.lives: 3.104\n",
      "\n",
      "Interval 590 (294500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 0.338 - mean_q: 0.476 - mean_eps: 0.735 - ale.lives: 2.882\n",
      "\n",
      "Interval 591 (295000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.350 - mean_q: 0.490 - mean_eps: 0.734 - ale.lives: 3.298\n",
      "\n",
      "Interval 592 (295500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.002 - mae: 0.349 - mean_q: 0.491 - mean_eps: 0.734 - ale.lives: 3.088\n",
      "\n",
      "Interval 593 (296000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 0.352 - mean_q: 0.493 - mean_eps: 0.733 - ale.lives: 2.842\n",
      "\n",
      "Interval 594 (296500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 0.347 - mean_q: 0.487 - mean_eps: 0.733 - ale.lives: 2.844\n",
      "\n",
      "Interval 595 (297000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 0.343 - mean_q: 0.484 - mean_eps: 0.732 - ale.lives: 3.086\n",
      "\n",
      "Interval 596 (297500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.354 - mean_q: 0.496 - mean_eps: 0.732 - ale.lives: 3.248\n",
      "\n",
      "Interval 597 (298000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.351 - mean_q: 0.492 - mean_eps: 0.732 - ale.lives: 3.440\n",
      "\n",
      "Interval 598 (298500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.358 - mean_q: 0.499 - mean_eps: 0.731 - ale.lives: 2.802\n",
      "\n",
      "Interval 599 (299000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 1.250 [0.000, 2.000] - loss: 0.002 - mae: 0.338 - mean_q: 0.472 - mean_eps: 0.731 - ale.lives: 3.192\n",
      "\n",
      "Interval 600 (299500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 0.355 - mean_q: 0.499 - mean_eps: 0.730 - ale.lives: 3.276\n",
      "\n",
      "Interval 601 (300000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.010 - mae: 0.373 - mean_q: 0.514 - mean_eps: 0.730 - ale.lives: 2.924\n",
      "\n",
      "Interval 602 (300500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.004 - mae: 0.394 - mean_q: 0.553 - mean_eps: 0.729 - ale.lives: 2.812\n",
      "\n",
      "Interval 603 (301000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 0.384 - mean_q: 0.540 - mean_eps: 0.729 - ale.lives: 3.448\n",
      "\n",
      "Interval 604 (301500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.003 - mae: 0.384 - mean_q: 0.543 - mean_eps: 0.728 - ale.lives: 2.650\n",
      "\n",
      "Interval 605 (302000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.360 - mean_q: 0.507 - mean_eps: 0.728 - ale.lives: 2.820\n",
      "\n",
      "Interval 606 (302500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.000 [1.000, 7.000] - loss: 0.002 - mae: 0.378 - mean_q: 0.531 - mean_eps: 0.728 - ale.lives: 3.090\n",
      "\n",
      "Interval 607 (303000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.382 - mean_q: 0.539 - mean_eps: 0.727 - ale.lives: 3.156\n",
      "\n",
      "Interval 608 (303500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.003 - mae: 0.391 - mean_q: 0.550 - mean_eps: 0.727 - ale.lives: 2.618\n",
      "\n",
      "Interval 609 (304000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.003 - mae: 0.384 - mean_q: 0.545 - mean_eps: 0.726 - ale.lives: 2.678\n",
      "\n",
      "Interval 610 (304500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 0.390 - mean_q: 0.551 - mean_eps: 0.726 - ale.lives: 3.272\n",
      "\n",
      "Interval 611 (305000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.383 - mean_q: 0.538 - mean_eps: 0.725 - ale.lives: 3.004\n",
      "\n",
      "Interval 612 (305500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 0.372 - mean_q: 0.525 - mean_eps: 0.725 - ale.lives: 3.384\n",
      "\n",
      "Interval 613 (306000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 0.388 - mean_q: 0.547 - mean_eps: 0.724 - ale.lives: 2.782\n",
      "\n",
      "Interval 614 (306500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 4.000] - loss: 0.002 - mae: 0.374 - mean_q: 0.527 - mean_eps: 0.724 - ale.lives: 2.486\n",
      "\n",
      "Interval 615 (307000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.376 - mean_q: 0.530 - mean_eps: 0.723 - ale.lives: 2.648\n",
      "\n",
      "Interval 616 (307500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.000 [2.000, 5.000] - loss: 0.002 - mae: 0.380 - mean_q: 0.538 - mean_eps: 0.723 - ale.lives: 2.558\n",
      "\n",
      "Interval 617 (308000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 0.375 - mean_q: 0.528 - mean_eps: 0.723 - ale.lives: 3.076\n",
      "\n",
      "Interval 618 (308500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "4 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.383 - mean_q: 0.539 - mean_eps: 0.722 - ale.lives: 3.074\n",
      "\n",
      "Interval 619 (309000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.002 - mae: 0.372 - mean_q: 0.526 - mean_eps: 0.722 - ale.lives: 2.954\n",
      "\n",
      "Interval 620 (309500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.002 - mae: 0.376 - mean_q: 0.531 - mean_eps: 0.721 - ale.lives: 2.528\n",
      "\n",
      "Interval 621 (310000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.009 - mae: 0.414 - mean_q: 0.581 - mean_eps: 0.721 - ale.lives: 2.812\n",
      "\n",
      "Interval 622 (310500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.004 - mae: 0.415 - mean_q: 0.585 - mean_eps: 0.720 - ale.lives: 3.416\n",
      "\n",
      "Interval 623 (311000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.004 - mae: 0.415 - mean_q: 0.582 - mean_eps: 0.720 - ale.lives: 2.284\n",
      "\n",
      "Interval 624 (311500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.003 - mae: 0.411 - mean_q: 0.579 - mean_eps: 0.719 - ale.lives: 2.950\n",
      "\n",
      "Interval 625 (312000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.003 - mae: 0.408 - mean_q: 0.576 - mean_eps: 0.719 - ale.lives: 3.150\n",
      "\n",
      "Interval 626 (312500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.003 - mae: 0.407 - mean_q: 0.573 - mean_eps: 0.719 - ale.lives: 2.972\n",
      "\n",
      "Interval 627 (313000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.004 - mae: 0.403 - mean_q: 0.569 - mean_eps: 0.718 - ale.lives: 2.930\n",
      "\n",
      "Interval 628 (313500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.003 - mae: 0.414 - mean_q: 0.582 - mean_eps: 0.718 - ale.lives: 3.138\n",
      "\n",
      "Interval 629 (314000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.003 - mae: 0.407 - mean_q: 0.580 - mean_eps: 0.717 - ale.lives: 2.948\n",
      "\n",
      "Interval 630 (314500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 6.500 [3.000, 10.000] - loss: 0.002 - mae: 0.405 - mean_q: 0.571 - mean_eps: 0.717 - ale.lives: 3.086\n",
      "\n",
      "Interval 631 (315000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.004 - mae: 0.411 - mean_q: 0.581 - mean_eps: 0.716 - ale.lives: 3.486\n",
      "\n",
      "Interval 632 (315500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 0.407 - mean_q: 0.578 - mean_eps: 0.716 - ale.lives: 3.394\n",
      "\n",
      "Interval 633 (316000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 0.408 - mean_q: 0.578 - mean_eps: 0.715 - ale.lives: 2.512\n",
      "\n",
      "Interval 634 (316500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [0.000, 4.000] - loss: 0.003 - mae: 0.417 - mean_q: 0.590 - mean_eps: 0.715 - ale.lives: 3.184\n",
      "\n",
      "Interval 635 (317000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 0.412 - mean_q: 0.581 - mean_eps: 0.714 - ale.lives: 2.866\n",
      "\n",
      "Interval 636 (317500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 7.000 [6.000, 8.000] - loss: 0.003 - mae: 0.412 - mean_q: 0.586 - mean_eps: 0.714 - ale.lives: 2.476\n",
      "\n",
      "Interval 637 (318000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 0.415 - mean_q: 0.582 - mean_eps: 0.714 - ale.lives: 2.666\n",
      "\n",
      "Interval 638 (318500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 3.000 [0.000, 7.000] - loss: 0.003 - mae: 0.401 - mean_q: 0.569 - mean_eps: 0.713 - ale.lives: 3.324\n",
      "\n",
      "Interval 639 (319000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 0.411 - mean_q: 0.580 - mean_eps: 0.713 - ale.lives: 3.526\n",
      "\n",
      "Interval 640 (319500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 0.426 - mean_q: 0.601 - mean_eps: 0.712 - ale.lives: 3.054\n",
      "\n",
      "Interval 641 (320000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.333 [2.000, 5.000] - loss: 0.012 - mae: 0.452 - mean_q: 0.630 - mean_eps: 0.712 - ale.lives: 3.278\n",
      "\n",
      "Interval 642 (320500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.003 - mae: 0.455 - mean_q: 0.639 - mean_eps: 0.711 - ale.lives: 2.652\n",
      "\n",
      "Interval 643 (321000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 0.439 - mean_q: 0.621 - mean_eps: 0.711 - ale.lives: 2.880\n",
      "\n",
      "Interval 644 (321500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.446 - mean_q: 0.632 - mean_eps: 0.710 - ale.lives: 2.470\n",
      "\n",
      "Interval 645 (322000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 0.450 - mean_q: 0.636 - mean_eps: 0.710 - ale.lives: 2.884\n",
      "\n",
      "Interval 646 (322500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.003 - mae: 0.445 - mean_q: 0.625 - mean_eps: 0.710 - ale.lives: 2.756\n",
      "\n",
      "Interval 647 (323000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.432 - mean_q: 0.609 - mean_eps: 0.709 - ale.lives: 3.692\n",
      "\n",
      "Interval 648 (323500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [1.000, 7.000] - loss: 0.003 - mae: 0.454 - mean_q: 0.641 - mean_eps: 0.709 - ale.lives: 2.706\n",
      "\n",
      "Interval 649 (324000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 0.440 - mean_q: 0.621 - mean_eps: 0.708 - ale.lives: 2.350\n",
      "\n",
      "Interval 650 (324500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 0.439 - mean_q: 0.622 - mean_eps: 0.708 - ale.lives: 2.948\n",
      "\n",
      "Interval 651 (325000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.439 - mean_q: 0.622 - mean_eps: 0.707 - ale.lives: 3.102\n",
      "\n",
      "Interval 652 (325500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.003 - mae: 0.446 - mean_q: 0.627 - mean_eps: 0.707 - ale.lives: 2.274\n",
      "\n",
      "Interval 653 (326000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.003 - mae: 0.454 - mean_q: 0.636 - mean_eps: 0.706 - ale.lives: 3.090\n",
      "\n",
      "Interval 654 (326500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.002 - mae: 0.450 - mean_q: 0.635 - mean_eps: 0.706 - ale.lives: 2.788\n",
      "\n",
      "Interval 655 (327000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.003 - mae: 0.440 - mean_q: 0.621 - mean_eps: 0.705 - ale.lives: 3.238\n",
      "\n",
      "Interval 656 (327500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 0.441 - mean_q: 0.627 - mean_eps: 0.705 - ale.lives: 3.110\n",
      "\n",
      "Interval 657 (328000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.442 - mean_q: 0.623 - mean_eps: 0.705 - ale.lives: 3.044\n",
      "\n",
      "Interval 658 (328500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.002 - mae: 0.444 - mean_q: 0.628 - mean_eps: 0.704 - ale.lives: 3.200\n",
      "\n",
      "Interval 659 (329000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.441 - mean_q: 0.626 - mean_eps: 0.704 - ale.lives: 3.290\n",
      "\n",
      "Interval 660 (329500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 0.445 - mean_q: 0.628 - mean_eps: 0.703 - ale.lives: 2.756\n",
      "\n",
      "Interval 661 (330000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.008 - mae: 0.480 - mean_q: 0.671 - mean_eps: 0.703 - ale.lives: 3.550\n",
      "\n",
      "Interval 662 (330500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.003 - mae: 0.466 - mean_q: 0.658 - mean_eps: 0.702 - ale.lives: 3.442\n",
      "\n",
      "Interval 663 (331000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [0.000, 4.000] - loss: 0.003 - mae: 0.472 - mean_q: 0.668 - mean_eps: 0.702 - ale.lives: 2.886\n",
      "\n",
      "Interval 664 (331500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 0.468 - mean_q: 0.663 - mean_eps: 0.701 - ale.lives: 3.256\n",
      "\n",
      "Interval 665 (332000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 0.482 - mean_q: 0.677 - mean_eps: 0.701 - ale.lives: 2.764\n",
      "\n",
      "Interval 666 (332500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.003 - mae: 0.466 - mean_q: 0.659 - mean_eps: 0.701 - ale.lives: 2.940\n",
      "\n",
      "Interval 667 (333000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.003 - mae: 0.483 - mean_q: 0.685 - mean_eps: 0.700 - ale.lives: 3.034\n",
      "\n",
      "Interval 668 (333500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 0.460 - mean_q: 0.652 - mean_eps: 0.700 - ale.lives: 2.734\n",
      "\n",
      "Interval 669 (334000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.003 - mae: 0.462 - mean_q: 0.655 - mean_eps: 0.699 - ale.lives: 3.084\n",
      "\n",
      "Interval 670 (334500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.003 - mae: 0.467 - mean_q: 0.661 - mean_eps: 0.699 - ale.lives: 2.966\n",
      "\n",
      "Interval 671 (335000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 0.465 - mean_q: 0.660 - mean_eps: 0.698 - ale.lives: 2.566\n",
      "\n",
      "Interval 672 (335500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.002 - mae: 0.463 - mean_q: 0.653 - mean_eps: 0.698 - ale.lives: 3.146\n",
      "\n",
      "Interval 673 (336000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.002 - mae: 0.464 - mean_q: 0.654 - mean_eps: 0.697 - ale.lives: 2.874\n",
      "\n",
      "Interval 674 (336500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.003 - mae: 0.466 - mean_q: 0.663 - mean_eps: 0.697 - ale.lives: 2.966\n",
      "\n",
      "Interval 675 (337000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [0.000, 5.000] - loss: 0.002 - mae: 0.473 - mean_q: 0.671 - mean_eps: 0.696 - ale.lives: 2.696\n",
      "\n",
      "Interval 676 (337500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.475 - mean_q: 0.672 - mean_eps: 0.696 - ale.lives: 2.668\n",
      "\n",
      "Interval 677 (338000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 0.474 - mean_q: 0.670 - mean_eps: 0.696 - ale.lives: 3.270\n",
      "\n",
      "Interval 678 (338500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 0.449 - mean_q: 0.634 - mean_eps: 0.695 - ale.lives: 2.276\n",
      "\n",
      "Interval 679 (339000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.471 - mean_q: 0.663 - mean_eps: 0.695 - ale.lives: 2.770\n",
      "\n",
      "Interval 680 (339500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 0.478 - mean_q: 0.676 - mean_eps: 0.694 - ale.lives: 3.308\n",
      "\n",
      "Interval 681 (340000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.010 - mae: 0.516 - mean_q: 0.719 - mean_eps: 0.694 - ale.lives: 2.546\n",
      "\n",
      "Interval 682 (340500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.004 - mae: 0.521 - mean_q: 0.733 - mean_eps: 0.693 - ale.lives: 3.420\n",
      "\n",
      "Interval 683 (341000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.004 - mae: 0.513 - mean_q: 0.723 - mean_eps: 0.693 - ale.lives: 3.020\n",
      "\n",
      "Interval 684 (341500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.003 - mae: 0.515 - mean_q: 0.724 - mean_eps: 0.692 - ale.lives: 2.892\n",
      "\n",
      "Interval 685 (342000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.509 - mean_q: 0.716 - mean_eps: 0.692 - ale.lives: 3.144\n",
      "\n",
      "Interval 686 (342500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 0.516 - mean_q: 0.726 - mean_eps: 0.692 - ale.lives: 2.758\n",
      "\n",
      "Interval 687 (343000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.003 - mae: 0.518 - mean_q: 0.728 - mean_eps: 0.691 - ale.lives: 2.900\n",
      "\n",
      "Interval 688 (343500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 0.510 - mean_q: 0.717 - mean_eps: 0.691 - ale.lives: 2.634\n",
      "\n",
      "Interval 689 (344000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 0.515 - mean_q: 0.726 - mean_eps: 0.690 - ale.lives: 2.938\n",
      "\n",
      "Interval 690 (344500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.003 - mae: 0.513 - mean_q: 0.718 - mean_eps: 0.690 - ale.lives: 3.126\n",
      "\n",
      "Interval 691 (345000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.515 - mean_q: 0.726 - mean_eps: 0.689 - ale.lives: 2.980\n",
      "\n",
      "Interval 692 (345500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.003 - mae: 0.512 - mean_q: 0.723 - mean_eps: 0.689 - ale.lives: 2.760\n",
      "\n",
      "Interval 693 (346000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 0.517 - mean_q: 0.732 - mean_eps: 0.688 - ale.lives: 3.406\n",
      "\n",
      "Interval 694 (346500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 0.509 - mean_q: 0.716 - mean_eps: 0.688 - ale.lives: 2.648\n",
      "\n",
      "Interval 695 (347000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 0.526 - mean_q: 0.738 - mean_eps: 0.687 - ale.lives: 3.100\n",
      "\n",
      "Interval 696 (347500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 0.509 - mean_q: 0.718 - mean_eps: 0.687 - ale.lives: 2.878\n",
      "\n",
      "Interval 697 (348000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 3.000 [1.000, 6.000] - loss: 0.002 - mae: 0.514 - mean_q: 0.725 - mean_eps: 0.687 - ale.lives: 3.056\n",
      "\n",
      "Interval 698 (348500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.524 - mean_q: 0.739 - mean_eps: 0.686 - ale.lives: 2.950\n",
      "\n",
      "Interval 699 (349000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.002 - mae: 0.525 - mean_q: 0.736 - mean_eps: 0.686 - ale.lives: 3.330\n",
      "\n",
      "Interval 700 (349500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 1.667 [0.000, 5.000] - loss: 0.002 - mae: 0.526 - mean_q: 0.740 - mean_eps: 0.685 - ale.lives: 2.876\n",
      "\n",
      "Interval 701 (350000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.010 - mae: 0.556 - mean_q: 0.776 - mean_eps: 0.685 - ale.lives: 2.924\n",
      "\n",
      "Interval 702 (350500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.004 - mae: 0.554 - mean_q: 0.782 - mean_eps: 0.684 - ale.lives: 2.602\n",
      "\n",
      "Interval 703 (351000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.003 - mae: 0.558 - mean_q: 0.787 - mean_eps: 0.684 - ale.lives: 3.138\n",
      "\n",
      "Interval 704 (351500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.003 - mae: 0.553 - mean_q: 0.782 - mean_eps: 0.683 - ale.lives: 2.874\n",
      "\n",
      "Interval 705 (352000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.003 - mae: 0.552 - mean_q: 0.779 - mean_eps: 0.683 - ale.lives: 2.862\n",
      "\n",
      "Interval 706 (352500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 0.548 - mean_q: 0.776 - mean_eps: 0.683 - ale.lives: 2.432\n",
      "\n",
      "Interval 707 (353000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 0.557 - mean_q: 0.786 - mean_eps: 0.682 - ale.lives: 3.354\n",
      "\n",
      "Interval 708 (353500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.558 - mean_q: 0.789 - mean_eps: 0.682 - ale.lives: 3.214\n",
      "\n",
      "Interval 709 (354000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 0.542 - mean_q: 0.764 - mean_eps: 0.681 - ale.lives: 2.626\n",
      "\n",
      "Interval 710 (354500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 0.552 - mean_q: 0.780 - mean_eps: 0.681 - ale.lives: 2.694\n",
      "\n",
      "Interval 711 (355000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.002 - mae: 0.549 - mean_q: 0.773 - mean_eps: 0.680 - ale.lives: 3.300\n",
      "\n",
      "Interval 712 (355500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 0.542 - mean_q: 0.767 - mean_eps: 0.680 - ale.lives: 3.334\n",
      "\n",
      "Interval 713 (356000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 0.547 - mean_q: 0.774 - mean_eps: 0.679 - ale.lives: 2.658\n",
      "\n",
      "Interval 714 (356500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 0.547 - mean_q: 0.776 - mean_eps: 0.679 - ale.lives: 2.812\n",
      "\n",
      "Interval 715 (357000 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 0.561 - mean_q: 0.793 - mean_eps: 0.678 - ale.lives: 3.096\n",
      "\n",
      "Interval 716 (357500 steps performed)\n",
      "500/500 [==============================] - 22s 45ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 0.550 - mean_q: 0.779 - mean_eps: 0.678 - ale.lives: 2.672\n",
      "\n",
      "Interval 717 (358000 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [1.000, 4.000] - loss: 0.003 - mae: 0.555 - mean_q: 0.789 - mean_eps: 0.678 - ale.lives: 3.450\n",
      "\n",
      "Interval 718 (358500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.550 - mean_q: 0.780 - mean_eps: 0.677 - ale.lives: 3.242\n",
      "\n",
      "Interval 719 (359000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.548 - mean_q: 0.775 - mean_eps: 0.677 - ale.lives: 2.798\n",
      "\n",
      "Interval 720 (359500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 0.559 - mean_q: 0.788 - mean_eps: 0.676 - ale.lives: 2.956\n",
      "\n",
      "Interval 721 (360000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.020 - mae: 0.605 - mean_q: 0.882 - mean_eps: 0.676 - ale.lives: 3.218\n",
      "\n",
      "Interval 722 (360500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.014 - mae: 0.603 - mean_q: 0.889 - mean_eps: 0.675 - ale.lives: 2.368\n",
      "\n",
      "Interval 723 (361000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.020 - mae: 0.602 - mean_q: 0.907 - mean_eps: 0.675 - ale.lives: 3.288\n",
      "\n",
      "Interval 724 (361500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.018 - mae: 0.613 - mean_q: 0.921 - mean_eps: 0.674 - ale.lives: 2.970\n",
      "\n",
      "Interval 725 (362000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.014 - mae: 0.594 - mean_q: 0.894 - mean_eps: 0.674 - ale.lives: 2.966\n",
      "\n",
      "Interval 726 (362500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.014 - mae: 0.601 - mean_q: 0.917 - mean_eps: 0.674 - ale.lives: 3.142\n",
      "\n",
      "Interval 727 (363000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.013 - mae: 0.599 - mean_q: 0.899 - mean_eps: 0.673 - ale.lives: 2.922\n",
      "\n",
      "Interval 728 (363500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.012 - mae: 0.601 - mean_q: 0.915 - mean_eps: 0.673 - ale.lives: 2.864\n",
      "\n",
      "Interval 729 (364000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.012 - mae: 0.600 - mean_q: 0.911 - mean_eps: 0.672 - ale.lives: 2.550\n",
      "\n",
      "Interval 730 (364500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.012 - mae: 0.601 - mean_q: 0.914 - mean_eps: 0.672 - ale.lives: 2.198\n",
      "\n",
      "Interval 731 (365000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.333 [1.000, 6.000] - loss: 0.010 - mae: 0.603 - mean_q: 0.925 - mean_eps: 0.671 - ale.lives: 3.118\n",
      "\n",
      "Interval 732 (365500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.011 - mae: 0.599 - mean_q: 0.917 - mean_eps: 0.671 - ale.lives: 3.284\n",
      "\n",
      "Interval 733 (366000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.011 - mae: 0.616 - mean_q: 0.953 - mean_eps: 0.670 - ale.lives: 2.958\n",
      "\n",
      "Interval 734 (366500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.011 - mae: 0.598 - mean_q: 0.922 - mean_eps: 0.670 - ale.lives: 3.312\n",
      "\n",
      "Interval 735 (367000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.009 - mae: 0.595 - mean_q: 0.912 - mean_eps: 0.669 - ale.lives: 2.982\n",
      "\n",
      "Interval 736 (367500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.009 - mae: 0.594 - mean_q: 0.908 - mean_eps: 0.669 - ale.lives: 3.110\n",
      "\n",
      "Interval 737 (368000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [2.000, 4.000] - loss: 0.008 - mae: 0.600 - mean_q: 0.913 - mean_eps: 0.669 - ale.lives: 2.612\n",
      "\n",
      "Interval 738 (368500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.010 - mae: 0.594 - mean_q: 0.917 - mean_eps: 0.668 - ale.lives: 3.222\n",
      "\n",
      "Interval 739 (369000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.010 - mae: 0.598 - mean_q: 0.914 - mean_eps: 0.668 - ale.lives: 2.454\n",
      "\n",
      "Interval 740 (369500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.008 - mae: 0.610 - mean_q: 0.935 - mean_eps: 0.667 - ale.lives: 3.450\n",
      "\n",
      "Interval 741 (370000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.024 - mae: 0.702 - mean_q: 0.998 - mean_eps: 0.667 - ale.lives: 2.464\n",
      "\n",
      "Interval 742 (370500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.019 - mae: 0.696 - mean_q: 0.988 - mean_eps: 0.666 - ale.lives: 2.938\n",
      "\n",
      "Interval 743 (371000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.017 - mae: 0.696 - mean_q: 0.982 - mean_eps: 0.666 - ale.lives: 2.576\n",
      "\n",
      "Interval 744 (371500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.017 - mae: 0.705 - mean_q: 1.002 - mean_eps: 0.665 - ale.lives: 3.242\n",
      "\n",
      "Interval 745 (372000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.016 - mae: 0.693 - mean_q: 0.977 - mean_eps: 0.665 - ale.lives: 3.184\n",
      "\n",
      "Interval 746 (372500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.017 - mae: 0.690 - mean_q: 0.972 - mean_eps: 0.665 - ale.lives: 3.242\n",
      "\n",
      "Interval 747 (373000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.016 - mae: 0.696 - mean_q: 0.984 - mean_eps: 0.664 - ale.lives: 2.558\n",
      "\n",
      "Interval 748 (373500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.000 [1.000, 4.000] - loss: 0.015 - mae: 0.689 - mean_q: 0.975 - mean_eps: 0.664 - ale.lives: 3.136\n",
      "\n",
      "Interval 749 (374000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.017 - mae: 0.702 - mean_q: 0.987 - mean_eps: 0.663 - ale.lives: 3.732\n",
      "\n",
      "Interval 750 (374500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 6.000 [4.000, 8.000] - loss: 0.016 - mae: 0.702 - mean_q: 0.993 - mean_eps: 0.663 - ale.lives: 2.746\n",
      "\n",
      "Interval 751 (375000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.016 - mae: 0.699 - mean_q: 0.992 - mean_eps: 0.662 - ale.lives: 2.872\n",
      "\n",
      "Interval 752 (375500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [1.000, 3.000] - loss: 0.015 - mae: 0.688 - mean_q: 0.983 - mean_eps: 0.662 - ale.lives: 3.170\n",
      "\n",
      "Interval 753 (376000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.015 - mae: 0.702 - mean_q: 0.993 - mean_eps: 0.661 - ale.lives: 3.046\n",
      "\n",
      "Interval 754 (376500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.016 - mae: 0.706 - mean_q: 1.005 - mean_eps: 0.661 - ale.lives: 3.074\n",
      "\n",
      "Interval 755 (377000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.015 - mae: 0.704 - mean_q: 1.007 - mean_eps: 0.660 - ale.lives: 3.178\n",
      "\n",
      "Interval 756 (377500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [0.000, 8.000] - loss: 0.018 - mae: 0.701 - mean_q: 0.993 - mean_eps: 0.660 - ale.lives: 2.974\n",
      "\n",
      "Interval 757 (378000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [0.000, 5.000] - loss: 0.015 - mae: 0.700 - mean_q: 0.994 - mean_eps: 0.660 - ale.lives: 3.392\n",
      "\n",
      "Interval 758 (378500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.016 - mae: 0.700 - mean_q: 0.987 - mean_eps: 0.659 - ale.lives: 2.574\n",
      "\n",
      "Interval 759 (379000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.015 - mae: 0.700 - mean_q: 0.997 - mean_eps: 0.659 - ale.lives: 2.718\n",
      "\n",
      "Interval 760 (379500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.016 - mae: 0.695 - mean_q: 0.988 - mean_eps: 0.658 - ale.lives: 2.782\n",
      "\n",
      "Interval 761 (380000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.019 - mae: 0.759 - mean_q: 1.059 - mean_eps: 0.658 - ale.lives: 2.768\n",
      "\n",
      "Interval 762 (380500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.014 - mae: 0.751 - mean_q: 1.047 - mean_eps: 0.657 - ale.lives: 3.116\n",
      "\n",
      "Interval 763 (381000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.014 - mae: 0.754 - mean_q: 1.050 - mean_eps: 0.657 - ale.lives: 1.826\n",
      "\n",
      "Interval 764 (381500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.014 - mae: 0.741 - mean_q: 1.032 - mean_eps: 0.656 - ale.lives: 2.800\n",
      "\n",
      "Interval 765 (382000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.013 - mae: 0.750 - mean_q: 1.046 - mean_eps: 0.656 - ale.lives: 2.858\n",
      "\n",
      "Interval 766 (382500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.016 - mae: 0.758 - mean_q: 1.052 - mean_eps: 0.656 - ale.lives: 3.468\n",
      "\n",
      "Interval 767 (383000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.014 - mae: 0.754 - mean_q: 1.055 - mean_eps: 0.655 - ale.lives: 2.462\n",
      "\n",
      "Interval 768 (383500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.013 - mae: 0.749 - mean_q: 1.046 - mean_eps: 0.655 - ale.lives: 2.264\n",
      "\n",
      "Interval 769 (384000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.013 - mae: 0.753 - mean_q: 1.048 - mean_eps: 0.654 - ale.lives: 2.820\n",
      "\n",
      "Interval 770 (384500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.013 - mae: 0.753 - mean_q: 1.054 - mean_eps: 0.654 - ale.lives: 3.330\n",
      "\n",
      "Interval 771 (385000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [1.000, 4.000] - loss: 0.015 - mae: 0.749 - mean_q: 1.049 - mean_eps: 0.653 - ale.lives: 3.080\n",
      "\n",
      "Interval 772 (385500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.013 - mae: 0.755 - mean_q: 1.057 - mean_eps: 0.653 - ale.lives: 2.858\n",
      "\n",
      "Interval 773 (386000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.013 - mae: 0.752 - mean_q: 1.052 - mean_eps: 0.652 - ale.lives: 2.954\n",
      "\n",
      "Interval 774 (386500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [1.000, 7.000] - loss: 0.012 - mae: 0.747 - mean_q: 1.044 - mean_eps: 0.652 - ale.lives: 3.266\n",
      "\n",
      "Interval 775 (387000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.013 - mae: 0.753 - mean_q: 1.050 - mean_eps: 0.651 - ale.lives: 3.586\n",
      "\n",
      "Interval 776 (387500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.013 - mae: 0.749 - mean_q: 1.050 - mean_eps: 0.651 - ale.lives: 2.900\n",
      "\n",
      "Interval 777 (388000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.011 - mae: 0.738 - mean_q: 1.033 - mean_eps: 0.651 - ale.lives: 3.404\n",
      "\n",
      "Interval 778 (388500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [0.000, 4.000] - loss: 0.014 - mae: 0.759 - mean_q: 1.062 - mean_eps: 0.650 - ale.lives: 3.278\n",
      "\n",
      "Interval 779 (389000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.014 - mae: 0.766 - mean_q: 1.071 - mean_eps: 0.650 - ale.lives: 3.530\n",
      "\n",
      "Interval 780 (389500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.014 - mae: 0.758 - mean_q: 1.059 - mean_eps: 0.649 - ale.lives: 3.494\n",
      "\n",
      "Interval 781 (390000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.011 - mae: 0.790 - mean_q: 1.096 - mean_eps: 0.649 - ale.lives: 3.240\n",
      "\n",
      "Interval 782 (390500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.008 - mae: 0.801 - mean_q: 1.110 - mean_eps: 0.648 - ale.lives: 3.008\n",
      "\n",
      "Interval 783 (391000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.010 - mae: 0.782 - mean_q: 1.087 - mean_eps: 0.648 - ale.lives: 2.668\n",
      "\n",
      "Interval 784 (391500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.010 - mae: 0.787 - mean_q: 1.091 - mean_eps: 0.647 - ale.lives: 3.194\n",
      "\n",
      "Interval 785 (392000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.010 - mae: 0.792 - mean_q: 1.106 - mean_eps: 0.647 - ale.lives: 3.610\n",
      "\n",
      "Interval 786 (392500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.009 - mae: 0.786 - mean_q: 1.091 - mean_eps: 0.647 - ale.lives: 3.000\n",
      "\n",
      "Interval 787 (393000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [1.000, 2.000] - loss: 0.009 - mae: 0.800 - mean_q: 1.115 - mean_eps: 0.646 - ale.lives: 2.622\n",
      "\n",
      "Interval 788 (393500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.010 - mae: 0.790 - mean_q: 1.098 - mean_eps: 0.646 - ale.lives: 3.246\n",
      "\n",
      "Interval 789 (394000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.008 - mae: 0.800 - mean_q: 1.116 - mean_eps: 0.645 - ale.lives: 2.910\n",
      "\n",
      "Interval 790 (394500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.008 - mae: 0.786 - mean_q: 1.099 - mean_eps: 0.645 - ale.lives: 2.884\n",
      "\n",
      "Interval 791 (395000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.008 - mae: 0.789 - mean_q: 1.099 - mean_eps: 0.644 - ale.lives: 3.360\n",
      "\n",
      "Interval 792 (395500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.009 - mae: 0.796 - mean_q: 1.103 - mean_eps: 0.644 - ale.lives: 3.364\n",
      "\n",
      "Interval 793 (396000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 4.000] - loss: 0.008 - mae: 0.801 - mean_q: 1.116 - mean_eps: 0.643 - ale.lives: 2.788\n",
      "\n",
      "Interval 794 (396500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.007 - mae: 0.790 - mean_q: 1.100 - mean_eps: 0.643 - ale.lives: 3.338\n",
      "\n",
      "Interval 795 (397000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.008 - mae: 0.784 - mean_q: 1.089 - mean_eps: 0.642 - ale.lives: 2.560\n",
      "\n",
      "Interval 796 (397500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.009 - mae: 0.788 - mean_q: 1.097 - mean_eps: 0.642 - ale.lives: 2.720\n",
      "\n",
      "Interval 797 (398000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.008 - mae: 0.797 - mean_q: 1.111 - mean_eps: 0.642 - ale.lives: 2.798\n",
      "\n",
      "Interval 798 (398500 steps performed)\n",
      "500/500 [==============================] - 23s 45ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.011 - mae: 0.789 - mean_q: 1.095 - mean_eps: 0.641 - ale.lives: 1.800\n",
      "\n",
      "Interval 799 (399000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.009 - mae: 0.797 - mean_q: 1.109 - mean_eps: 0.641 - ale.lives: 3.476\n",
      "\n",
      "Interval 800 (399500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [2.000, 8.000] - loss: 0.009 - mae: 0.783 - mean_q: 1.089 - mean_eps: 0.640 - ale.lives: 2.726\n",
      "\n",
      "Interval 801 (400000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.009 - mae: 0.823 - mean_q: 1.139 - mean_eps: 0.640 - ale.lives: 2.538\n",
      "\n",
      "Interval 802 (400500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.007 - mae: 0.830 - mean_q: 1.149 - mean_eps: 0.639 - ale.lives: 3.300\n",
      "\n",
      "Interval 803 (401000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.008 - mae: 0.832 - mean_q: 1.147 - mean_eps: 0.639 - ale.lives: 2.754\n",
      "\n",
      "Interval 804 (401500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.007 - mae: 0.816 - mean_q: 1.129 - mean_eps: 0.638 - ale.lives: 2.964\n",
      "\n",
      "Interval 805 (402000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.667 [0.000, 4.000] - loss: 0.008 - mae: 0.828 - mean_q: 1.144 - mean_eps: 0.638 - ale.lives: 2.838\n",
      "\n",
      "Interval 806 (402500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0180\n",
      "Interval 807 (403000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 6.000 [3.000, 9.000] - loss: 0.006 - mae: 0.829 - mean_q: 1.149 - mean_eps: 0.637 - ale.lives: 2.830\n",
      "\n",
      "Interval 808 (403500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [0.000, 6.000] - loss: 0.007 - mae: 0.819 - mean_q: 1.132 - mean_eps: 0.637 - ale.lives: 2.522\n",
      "\n",
      "Interval 809 (404000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.007 - mae: 0.834 - mean_q: 1.156 - mean_eps: 0.636 - ale.lives: 2.834\n",
      "\n",
      "Interval 810 (404500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [0.000, 5.000] - loss: 0.006 - mae: 0.818 - mean_q: 1.130 - mean_eps: 0.636 - ale.lives: 2.570\n",
      "\n",
      "Interval 811 (405000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.006 - mae: 0.830 - mean_q: 1.146 - mean_eps: 0.635 - ale.lives: 2.852\n",
      "\n",
      "Interval 812 (405500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.006 - mae: 0.831 - mean_q: 1.147 - mean_eps: 0.635 - ale.lives: 3.074\n",
      "\n",
      "Interval 813 (406000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.006 - mae: 0.821 - mean_q: 1.136 - mean_eps: 0.634 - ale.lives: 3.510\n",
      "\n",
      "Interval 814 (406500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.006 - mae: 0.828 - mean_q: 1.147 - mean_eps: 0.634 - ale.lives: 2.472\n",
      "\n",
      "Interval 815 (407000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.007 - mae: 0.826 - mean_q: 1.143 - mean_eps: 0.633 - ale.lives: 2.626\n",
      "\n",
      "Interval 816 (407500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.006 - mae: 0.827 - mean_q: 1.145 - mean_eps: 0.633 - ale.lives: 2.734\n",
      "\n",
      "Interval 817 (408000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 5.000] - loss: 0.006 - mae: 0.826 - mean_q: 1.145 - mean_eps: 0.633 - ale.lives: 3.714\n",
      "\n",
      "Interval 818 (408500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.007 - mae: 0.821 - mean_q: 1.139 - mean_eps: 0.632 - ale.lives: 3.222\n",
      "\n",
      "Interval 819 (409000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 3.000] - loss: 0.007 - mae: 0.832 - mean_q: 1.154 - mean_eps: 0.632 - ale.lives: 3.386\n",
      "\n",
      "Interval 820 (409500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.007 - mae: 0.816 - mean_q: 1.132 - mean_eps: 0.631 - ale.lives: 3.106\n",
      "\n",
      "Interval 821 (410000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.007 - mae: 0.864 - mean_q: 1.197 - mean_eps: 0.631 - ale.lives: 2.948\n",
      "\n",
      "Interval 822 (410500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.006 - mae: 0.856 - mean_q: 1.182 - mean_eps: 0.630 - ale.lives: 2.864\n",
      "\n",
      "Interval 823 (411000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.006 - mae: 0.863 - mean_q: 1.193 - mean_eps: 0.630 - ale.lives: 2.774\n",
      "\n",
      "Interval 824 (411500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.006 - mae: 0.870 - mean_q: 1.201 - mean_eps: 0.629 - ale.lives: 2.934\n",
      "\n",
      "Interval 825 (412000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 2.333 [0.000, 6.000] - loss: 0.006 - mae: 0.861 - mean_q: 1.188 - mean_eps: 0.629 - ale.lives: 2.648\n",
      "\n",
      "Interval 826 (412500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.006 - mae: 0.865 - mean_q: 1.195 - mean_eps: 0.629 - ale.lives: 3.096\n",
      "\n",
      "Interval 827 (413000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.007 - mae: 0.856 - mean_q: 1.181 - mean_eps: 0.628 - ale.lives: 3.188\n",
      "\n",
      "Interval 828 (413500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.006 - mae: 0.858 - mean_q: 1.189 - mean_eps: 0.628 - ale.lives: 3.544\n",
      "\n",
      "Interval 829 (414000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [0.000, 3.000] - loss: 0.006 - mae: 0.866 - mean_q: 1.197 - mean_eps: 0.627 - ale.lives: 3.028\n",
      "\n",
      "Interval 830 (414500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.006 - mae: 0.861 - mean_q: 1.188 - mean_eps: 0.627 - ale.lives: 3.092\n",
      "\n",
      "Interval 831 (415000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.007 - mae: 0.857 - mean_q: 1.186 - mean_eps: 0.626 - ale.lives: 2.946\n",
      "\n",
      "Interval 832 (415500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.006 - mae: 0.859 - mean_q: 1.188 - mean_eps: 0.626 - ale.lives: 3.484\n",
      "\n",
      "Interval 833 (416000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 6.000 [2.000, 10.000] - loss: 0.007 - mae: 0.848 - mean_q: 1.173 - mean_eps: 0.625 - ale.lives: 2.878\n",
      "\n",
      "Interval 834 (416500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.005 - mae: 0.861 - mean_q: 1.194 - mean_eps: 0.625 - ale.lives: 3.014\n",
      "\n",
      "Interval 835 (417000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.006 - mae: 0.864 - mean_q: 1.194 - mean_eps: 0.624 - ale.lives: 2.614\n",
      "\n",
      "Interval 836 (417500 steps performed)\n",
      "500/500 [==============================] - 28s 56ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.006 - mae: 0.860 - mean_q: 1.186 - mean_eps: 0.624 - ale.lives: 3.214\n",
      "\n",
      "Interval 837 (418000 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.006 - mae: 0.862 - mean_q: 1.192 - mean_eps: 0.624 - ale.lives: 2.662\n",
      "\n",
      "Interval 838 (418500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.006 - mae: 0.863 - mean_q: 1.189 - mean_eps: 0.623 - ale.lives: 2.140\n",
      "\n",
      "Interval 839 (419000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 5.000 [3.000, 7.000] - loss: 0.006 - mae: 0.863 - mean_q: 1.192 - mean_eps: 0.623 - ale.lives: 2.712\n",
      "\n",
      "Interval 840 (419500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.006 - mae: 0.864 - mean_q: 1.193 - mean_eps: 0.622 - ale.lives: 2.980\n",
      "\n",
      "Interval 841 (420000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.006 - mae: 0.880 - mean_q: 1.208 - mean_eps: 0.622 - ale.lives: 3.688\n",
      "\n",
      "Interval 842 (420500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 5.500 [4.000, 7.000] - loss: 0.006 - mae: 0.883 - mean_q: 1.219 - mean_eps: 0.621 - ale.lives: 3.486\n",
      "\n",
      "Interval 843 (421000 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.006 - mae: 0.877 - mean_q: 1.212 - mean_eps: 0.621 - ale.lives: 2.876\n",
      "\n",
      "Interval 844 (421500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.005 - mae: 0.877 - mean_q: 1.210 - mean_eps: 0.620 - ale.lives: 2.876\n",
      "\n",
      "Interval 845 (422000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 6.000 [4.000, 8.000] - loss: 0.005 - mae: 0.878 - mean_q: 1.212 - mean_eps: 0.620 - ale.lives: 3.604\n",
      "\n",
      "Interval 846 (422500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.005 - mae: 0.879 - mean_q: 1.210 - mean_eps: 0.620 - ale.lives: 2.112\n",
      "\n",
      "Interval 847 (423000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.005 - mae: 0.877 - mean_q: 1.207 - mean_eps: 0.619 - ale.lives: 2.858\n",
      "\n",
      "Interval 848 (423500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.005 - mae: 0.889 - mean_q: 1.224 - mean_eps: 0.619 - ale.lives: 2.828\n",
      "\n",
      "Interval 849 (424000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.006 - mae: 0.885 - mean_q: 1.221 - mean_eps: 0.618 - ale.lives: 2.730\n",
      "\n",
      "Interval 850 (424500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.005 - mae: 0.880 - mean_q: 1.212 - mean_eps: 0.618 - ale.lives: 3.180\n",
      "\n",
      "Interval 851 (425000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.004 - mae: 0.880 - mean_q: 1.213 - mean_eps: 0.617 - ale.lives: 3.358\n",
      "\n",
      "Interval 852 (425500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.004 - mae: 0.880 - mean_q: 1.213 - mean_eps: 0.617 - ale.lives: 3.770\n",
      "\n",
      "Interval 853 (426000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.005 - mae: 0.877 - mean_q: 1.207 - mean_eps: 0.616 - ale.lives: 3.208\n",
      "\n",
      "Interval 854 (426500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.005 - mae: 0.881 - mean_q: 1.211 - mean_eps: 0.616 - ale.lives: 3.236\n",
      "\n",
      "Interval 855 (427000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 7.000 [6.000, 8.000] - loss: 0.005 - mae: 0.886 - mean_q: 1.217 - mean_eps: 0.615 - ale.lives: 2.386\n",
      "\n",
      "Interval 856 (427500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.005 - mae: 0.869 - mean_q: 1.198 - mean_eps: 0.615 - ale.lives: 3.038\n",
      "\n",
      "Interval 857 (428000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.005 - mae: 0.876 - mean_q: 1.207 - mean_eps: 0.615 - ale.lives: 2.744\n",
      "\n",
      "Interval 858 (428500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.004 - mae: 0.877 - mean_q: 1.209 - mean_eps: 0.614 - ale.lives: 2.348\n",
      "\n",
      "Interval 859 (429000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.005 - mae: 0.878 - mean_q: 1.212 - mean_eps: 0.614 - ale.lives: 3.078\n",
      "\n",
      "Interval 860 (429500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 4.000 [1.000, 10.000] - loss: 0.005 - mae: 0.887 - mean_q: 1.221 - mean_eps: 0.613 - ale.lives: 3.282\n",
      "\n",
      "Interval 861 (430000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.005 - mae: 0.912 - mean_q: 1.249 - mean_eps: 0.613 - ale.lives: 3.484\n",
      "\n",
      "Interval 862 (430500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 7.500 [4.000, 11.000] - loss: 0.005 - mae: 0.909 - mean_q: 1.247 - mean_eps: 0.612 - ale.lives: 2.736\n",
      "\n",
      "Interval 863 (431000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.004 - mae: 0.913 - mean_q: 1.250 - mean_eps: 0.612 - ale.lives: 2.964\n",
      "\n",
      "Interval 864 (431500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 6.500 [6.000, 7.000] - loss: 0.004 - mae: 0.913 - mean_q: 1.250 - mean_eps: 0.611 - ale.lives: 2.160\n",
      "\n",
      "Interval 865 (432000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.005 - mae: 0.906 - mean_q: 1.240 - mean_eps: 0.611 - ale.lives: 3.312\n",
      "\n",
      "Interval 866 (432500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.004 - mae: 0.909 - mean_q: 1.246 - mean_eps: 0.611 - ale.lives: 2.950\n",
      "\n",
      "Interval 867 (433000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.004 - mae: 0.907 - mean_q: 1.241 - mean_eps: 0.610 - ale.lives: 2.478\n",
      "\n",
      "Interval 868 (433500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.005 - mae: 0.907 - mean_q: 1.243 - mean_eps: 0.610 - ale.lives: 3.128\n",
      "\n",
      "Interval 869 (434000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.004 - mae: 0.912 - mean_q: 1.250 - mean_eps: 0.609 - ale.lives: 2.286\n",
      "\n",
      "Interval 870 (434500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 6.000 [5.000, 7.000] - loss: 0.005 - mae: 0.911 - mean_q: 1.248 - mean_eps: 0.609 - ale.lives: 2.828\n",
      "\n",
      "Interval 871 (435000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.005 - mae: 0.902 - mean_q: 1.238 - mean_eps: 0.608 - ale.lives: 3.408\n",
      "\n",
      "Interval 872 (435500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.004 - mae: 0.910 - mean_q: 1.244 - mean_eps: 0.608 - ale.lives: 2.606\n",
      "\n",
      "Interval 873 (436000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.004 - mae: 0.905 - mean_q: 1.242 - mean_eps: 0.607 - ale.lives: 2.910\n",
      "\n",
      "Interval 874 (436500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.005 - mae: 0.911 - mean_q: 1.249 - mean_eps: 0.607 - ale.lives: 3.386\n",
      "\n",
      "Interval 875 (437000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.004 - mae: 0.913 - mean_q: 1.249 - mean_eps: 0.606 - ale.lives: 3.204\n",
      "\n",
      "Interval 876 (437500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.005 - mae: 0.910 - mean_q: 1.249 - mean_eps: 0.606 - ale.lives: 2.964\n",
      "\n",
      "Interval 877 (438000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.004 - mae: 0.915 - mean_q: 1.254 - mean_eps: 0.606 - ale.lives: 2.794\n",
      "\n",
      "Interval 878 (438500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.005 - mae: 0.917 - mean_q: 1.258 - mean_eps: 0.605 - ale.lives: 3.022\n",
      "\n",
      "Interval 879 (439000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.004 - mae: 0.911 - mean_q: 1.249 - mean_eps: 0.605 - ale.lives: 2.720\n",
      "\n",
      "Interval 880 (439500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 7.000 [6.000, 8.000] - loss: 0.004 - mae: 0.909 - mean_q: 1.246 - mean_eps: 0.604 - ale.lives: 3.104\n",
      "\n",
      "Interval 881 (440000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.005 - mae: 0.940 - mean_q: 1.282 - mean_eps: 0.604 - ale.lives: 2.670\n",
      "\n",
      "Interval 882 (440500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.500 [1.000, 8.000] - loss: 0.004 - mae: 0.944 - mean_q: 1.289 - mean_eps: 0.603 - ale.lives: 3.824\n",
      "\n",
      "Interval 883 (441000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 0.944 - mean_q: 1.287 - mean_eps: 0.603 - ale.lives: 2.962\n",
      "\n",
      "Interval 884 (441500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.003 - mae: 0.943 - mean_q: 1.290 - mean_eps: 0.602 - ale.lives: 3.120\n",
      "\n",
      "Interval 885 (442000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 0.948 - mean_q: 1.294 - mean_eps: 0.602 - ale.lives: 3.758\n",
      "\n",
      "Interval 886 (442500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.003 - mae: 0.944 - mean_q: 1.289 - mean_eps: 0.602 - ale.lives: 2.618\n",
      "\n",
      "Interval 887 (443000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.004 - mae: 0.943 - mean_q: 1.288 - mean_eps: 0.601 - ale.lives: 3.878\n",
      "\n",
      "Interval 888 (443500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 0.939 - mean_q: 1.282 - mean_eps: 0.601 - ale.lives: 2.814\n",
      "\n",
      "Interval 889 (444000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.003 - mae: 0.942 - mean_q: 1.287 - mean_eps: 0.600 - ale.lives: 2.598\n",
      "\n",
      "Interval 890 (444500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.004 - mae: 0.948 - mean_q: 1.293 - mean_eps: 0.600 - ale.lives: 3.404\n",
      "\n",
      "Interval 891 (445000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.003 - mae: 0.938 - mean_q: 1.283 - mean_eps: 0.599 - ale.lives: 2.614\n",
      "\n",
      "Interval 892 (445500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.004 - mae: 0.942 - mean_q: 1.288 - mean_eps: 0.599 - ale.lives: 3.898\n",
      "\n",
      "Interval 893 (446000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.003 - mae: 0.939 - mean_q: 1.285 - mean_eps: 0.598 - ale.lives: 2.490\n",
      "\n",
      "Interval 894 (446500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 0.941 - mean_q: 1.283 - mean_eps: 0.598 - ale.lives: 3.628\n",
      "\n",
      "Interval 895 (447000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.003 - mae: 0.943 - mean_q: 1.290 - mean_eps: 0.597 - ale.lives: 2.776\n",
      "\n",
      "Interval 896 (447500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.004 - mae: 0.941 - mean_q: 1.287 - mean_eps: 0.597 - ale.lives: 3.158\n",
      "\n",
      "Interval 897 (448000 steps performed)\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [0.000, 9.000] - loss: 0.003 - mae: 0.938 - mean_q: 1.285 - mean_eps: 0.597 - ale.lives: 2.954\n",
      "\n",
      "Interval 898 (448500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 6.500 [6.000, 7.000] - loss: 0.004 - mae: 0.941 - mean_q: 1.283 - mean_eps: 0.596 - ale.lives: 2.182\n",
      "\n",
      "Interval 899 (449000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.938 - mean_q: 1.283 - mean_eps: 0.596 - ale.lives: 2.778\n",
      "\n",
      "Interval 900 (449500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.004 - mae: 0.942 - mean_q: 1.288 - mean_eps: 0.595 - ale.lives: 3.550\n",
      "\n",
      "Interval 901 (450000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.004 - mae: 0.967 - mean_q: 1.317 - mean_eps: 0.595 - ale.lives: 3.184\n",
      "\n",
      "Interval 902 (450500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.004 - mae: 0.956 - mean_q: 1.301 - mean_eps: 0.594 - ale.lives: 3.198\n",
      "\n",
      "Interval 903 (451000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.500 [2.000, 7.000] - loss: 0.003 - mae: 0.958 - mean_q: 1.306 - mean_eps: 0.594 - ale.lives: 2.442\n",
      "\n",
      "Interval 904 (451500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.003 - mae: 0.967 - mean_q: 1.315 - mean_eps: 0.593 - ale.lives: 3.020\n",
      "\n",
      "Interval 905 (452000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 0.963 - mean_q: 1.311 - mean_eps: 0.593 - ale.lives: 3.254\n",
      "\n",
      "Interval 906 (452500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 6.500 [4.000, 9.000] - loss: 0.003 - mae: 0.963 - mean_q: 1.310 - mean_eps: 0.593 - ale.lives: 2.686\n",
      "\n",
      "Interval 907 (453000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.003 - mae: 0.961 - mean_q: 1.307 - mean_eps: 0.592 - ale.lives: 3.702\n",
      "\n",
      "Interval 908 (453500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 0.959 - mean_q: 1.304 - mean_eps: 0.592 - ale.lives: 2.692\n",
      "\n",
      "Interval 909 (454000 steps performed)\n",
      "500/500 [==============================] - 29s 57ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 0.957 - mean_q: 1.302 - mean_eps: 0.591 - ale.lives: 3.130\n",
      "\n",
      "Interval 910 (454500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 0.962 - mean_q: 1.310 - mean_eps: 0.591 - ale.lives: 2.534\n",
      "\n",
      "Interval 911 (455000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.965 - mean_q: 1.309 - mean_eps: 0.590 - ale.lives: 2.808\n",
      "\n",
      "Interval 912 (455500 steps performed)\n",
      "500/500 [==============================] - 28s 56ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.003 - mae: 0.959 - mean_q: 1.302 - mean_eps: 0.590 - ale.lives: 2.332\n",
      "\n",
      "Interval 913 (456000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 0.963 - mean_q: 1.309 - mean_eps: 0.589 - ale.lives: 2.788\n",
      "\n",
      "Interval 914 (456500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.004 - mae: 0.959 - mean_q: 1.303 - mean_eps: 0.589 - ale.lives: 3.628\n",
      "\n",
      "Interval 915 (457000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 0.962 - mean_q: 1.308 - mean_eps: 0.588 - ale.lives: 3.250\n",
      "\n",
      "Interval 916 (457500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.003 - mae: 0.958 - mean_q: 1.303 - mean_eps: 0.588 - ale.lives: 2.688\n",
      "\n",
      "Interval 917 (458000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.003 - mae: 0.955 - mean_q: 1.298 - mean_eps: 0.588 - ale.lives: 2.466\n",
      "\n",
      "Interval 918 (458500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 0.955 - mean_q: 1.300 - mean_eps: 0.587 - ale.lives: 3.076\n",
      "\n",
      "Interval 919 (459000 steps performed)\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 6.000 [5.000, 7.000] - loss: 0.003 - mae: 0.963 - mean_q: 1.311 - mean_eps: 0.587 - ale.lives: 2.242\n",
      "\n",
      "Interval 920 (459500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 0.963 - mean_q: 1.309 - mean_eps: 0.586 - ale.lives: 2.410\n",
      "\n",
      "Interval 921 (460000 steps performed)\n",
      "500/500 [==============================] - 29s 59ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 0.986 - mean_q: 1.334 - mean_eps: 0.586 - ale.lives: 2.778\n",
      "\n",
      "Interval 922 (460500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 0.983 - mean_q: 1.331 - mean_eps: 0.585 - ale.lives: 3.072\n",
      "\n",
      "Interval 923 (461000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.003 - mae: 0.976 - mean_q: 1.321 - mean_eps: 0.585 - ale.lives: 2.014\n",
      "\n",
      "Interval 924 (461500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.003 - mae: 0.975 - mean_q: 1.321 - mean_eps: 0.584 - ale.lives: 3.038\n",
      "\n",
      "Interval 925 (462000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 8.000 [5.000, 11.000] - loss: 0.003 - mae: 0.976 - mean_q: 1.322 - mean_eps: 0.584 - ale.lives: 3.306\n",
      "\n",
      "Interval 926 (462500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.003 - mae: 0.970 - mean_q: 1.312 - mean_eps: 0.584 - ale.lives: 3.070\n",
      "\n",
      "Interval 927 (463000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.500 [1.000, 8.000] - loss: 0.004 - mae: 0.977 - mean_q: 1.321 - mean_eps: 0.583 - ale.lives: 3.128\n",
      "\n",
      "Interval 928 (463500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 0.978 - mean_q: 1.325 - mean_eps: 0.583 - ale.lives: 2.926\n",
      "\n",
      "Interval 929 (464000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.978 - mean_q: 1.326 - mean_eps: 0.582 - ale.lives: 3.700\n",
      "\n",
      "Interval 930 (464500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.004 - mae: 0.968 - mean_q: 1.312 - mean_eps: 0.582 - ale.lives: 3.318\n",
      "\n",
      "Interval 931 (465000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.667 [0.000, 5.000] - loss: 0.003 - mae: 0.976 - mean_q: 1.324 - mean_eps: 0.581 - ale.lives: 2.774\n",
      "\n",
      "Interval 932 (465500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 0.974 - mean_q: 1.318 - mean_eps: 0.581 - ale.lives: 3.030\n",
      "\n",
      "Interval 933 (466000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.004 - mae: 0.979 - mean_q: 1.327 - mean_eps: 0.580 - ale.lives: 3.002\n",
      "\n",
      "Interval 934 (466500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.003 - mae: 0.983 - mean_q: 1.330 - mean_eps: 0.580 - ale.lives: 2.510\n",
      "\n",
      "Interval 935 (467000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.003 - mae: 0.973 - mean_q: 1.317 - mean_eps: 0.579 - ale.lives: 3.036\n",
      "\n",
      "Interval 936 (467500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.004 - mae: 0.972 - mean_q: 1.319 - mean_eps: 0.579 - ale.lives: 2.880\n",
      "\n",
      "Interval 937 (468000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.003 - mae: 0.975 - mean_q: 1.322 - mean_eps: 0.579 - ale.lives: 3.262\n",
      "\n",
      "Interval 938 (468500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 0.975 - mean_q: 1.323 - mean_eps: 0.578 - ale.lives: 3.262\n",
      "\n",
      "Interval 939 (469000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 0.979 - mean_q: 1.326 - mean_eps: 0.578 - ale.lives: 3.014\n",
      "\n",
      "Interval 940 (469500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 0.977 - mean_q: 1.324 - mean_eps: 0.577 - ale.lives: 2.736\n",
      "\n",
      "Interval 941 (470000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 0.993 - mean_q: 1.342 - mean_eps: 0.577 - ale.lives: 2.664\n",
      "\n",
      "Interval 942 (470500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.004 - mae: 0.994 - mean_q: 1.346 - mean_eps: 0.576 - ale.lives: 2.762\n",
      "\n",
      "Interval 943 (471000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 0.988 - mean_q: 1.336 - mean_eps: 0.576 - ale.lives: 3.186\n",
      "\n",
      "Interval 944 (471500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [0.000, 5.000] - loss: 0.003 - mae: 0.992 - mean_q: 1.342 - mean_eps: 0.575 - ale.lives: 2.976\n",
      "\n",
      "Interval 945 (472000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 0.989 - mean_q: 1.339 - mean_eps: 0.575 - ale.lives: 3.194\n",
      "\n",
      "Interval 946 (472500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 0.993 - mean_q: 1.343 - mean_eps: 0.575 - ale.lives: 2.734\n",
      "\n",
      "Interval 947 (473000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [2.000, 3.000] - loss: 0.004 - mae: 0.992 - mean_q: 1.343 - mean_eps: 0.574 - ale.lives: 2.788\n",
      "\n",
      "Interval 948 (473500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 0.996 - mean_q: 1.349 - mean_eps: 0.574 - ale.lives: 3.060\n",
      "\n",
      "Interval 949 (474000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.003 - mae: 0.997 - mean_q: 1.350 - mean_eps: 0.573 - ale.lives: 2.904\n",
      "\n",
      "Interval 950 (474500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 0.994 - mean_q: 1.346 - mean_eps: 0.573 - ale.lives: 2.668\n",
      "\n",
      "Interval 951 (475000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "Interval 952 (475500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 9.000 [7.000, 11.000] - loss: 0.003 - mae: 0.991 - mean_q: 1.341 - mean_eps: 0.572 - ale.lives: 2.762\n",
      "\n",
      "Interval 953 (476000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 0.994 - mean_q: 1.345 - mean_eps: 0.571 - ale.lives: 2.714\n",
      "\n",
      "Interval 954 (476500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.003 - mae: 0.994 - mean_q: 1.345 - mean_eps: 0.571 - ale.lives: 2.480\n",
      "\n",
      "Interval 955 (477000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.003 - mae: 0.996 - mean_q: 1.349 - mean_eps: 0.570 - ale.lives: 3.216\n",
      "\n",
      "Interval 956 (477500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.004 - mae: 0.989 - mean_q: 1.340 - mean_eps: 0.570 - ale.lives: 2.758\n",
      "\n",
      "Interval 957 (478000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.003 - mae: 0.990 - mean_q: 1.338 - mean_eps: 0.570 - ale.lives: 2.752\n",
      "\n",
      "Interval 958 (478500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 0.987 - mean_q: 1.336 - mean_eps: 0.569 - ale.lives: 2.720\n",
      "\n",
      "Interval 959 (479000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [0.000, 6.000] - loss: 0.004 - mae: 0.990 - mean_q: 1.340 - mean_eps: 0.569 - ale.lives: 2.970\n",
      "\n",
      "Interval 960 (479500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 0.989 - mean_q: 1.339 - mean_eps: 0.568 - ale.lives: 3.164\n",
      "\n",
      "Interval 961 (480000 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.003 - mae: 1.002 - mean_q: 1.350 - mean_eps: 0.568 - ale.lives: 2.586\n",
      "\n",
      "Interval 962 (480500 steps performed)\n",
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 1.006 - mean_q: 1.358 - mean_eps: 0.567 - ale.lives: 3.070\n",
      "\n",
      "Interval 963 (481000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [0.000, 6.000] - loss: 0.003 - mae: 1.004 - mean_q: 1.353 - mean_eps: 0.567 - ale.lives: 2.616\n",
      "\n",
      "Interval 964 (481500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.005 - mean_q: 1.356 - mean_eps: 0.566 - ale.lives: 2.310\n",
      "\n",
      "Interval 965 (482000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.003 - mae: 1.010 - mean_q: 1.362 - mean_eps: 0.566 - ale.lives: 3.054\n",
      "\n",
      "Interval 966 (482500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.003 - mae: 1.006 - mean_q: 1.358 - mean_eps: 0.566 - ale.lives: 3.016\n",
      "\n",
      "Interval 967 (483000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.003 - mae: 1.005 - mean_q: 1.355 - mean_eps: 0.565 - ale.lives: 3.300\n",
      "\n",
      "Interval 968 (483500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 5.000 [2.000, 8.000] - loss: 0.003 - mae: 1.005 - mean_q: 1.355 - mean_eps: 0.565 - ale.lives: 2.600\n",
      "\n",
      "Interval 969 (484000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 1.003 - mean_q: 1.355 - mean_eps: 0.564 - ale.lives: 2.780\n",
      "\n",
      "Interval 970 (484500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.003 - mae: 1.006 - mean_q: 1.360 - mean_eps: 0.564 - ale.lives: 2.330\n",
      "\n",
      "Interval 971 (485000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.003 - mae: 1.013 - mean_q: 1.368 - mean_eps: 0.563 - ale.lives: 2.284\n",
      "\n",
      "Interval 972 (485500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.004 - mean_q: 1.358 - mean_eps: 0.563 - ale.lives: 2.522\n",
      "\n",
      "Interval 973 (486000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 1.006 - mean_q: 1.359 - mean_eps: 0.562 - ale.lives: 3.490\n",
      "\n",
      "Interval 974 (486500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.667 [0.000, 5.000] - loss: 0.003 - mae: 1.001 - mean_q: 1.354 - mean_eps: 0.562 - ale.lives: 2.624\n",
      "\n",
      "Interval 975 (487000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.003 - mae: 1.002 - mean_q: 1.353 - mean_eps: 0.561 - ale.lives: 2.790\n",
      "\n",
      "Interval 976 (487500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "3 episodes - episode_reward: 3.333 [0.000, 5.000] - loss: 0.002 - mae: 1.005 - mean_q: 1.355 - mean_eps: 0.561 - ale.lives: 2.298\n",
      "\n",
      "Interval 977 (488000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.003 - mae: 1.002 - mean_q: 1.354 - mean_eps: 0.561 - ale.lives: 2.510\n",
      "\n",
      "Interval 978 (488500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 1.003 - mean_q: 1.356 - mean_eps: 0.560 - ale.lives: 3.000\n",
      "\n",
      "Interval 979 (489000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.005 - mean_q: 1.358 - mean_eps: 0.560 - ale.lives: 2.910\n",
      "\n",
      "Interval 980 (489500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.006 - mean_q: 1.360 - mean_eps: 0.559 - ale.lives: 2.452\n",
      "\n",
      "Interval 981 (490000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 1.014 - mean_q: 1.367 - mean_eps: 0.559 - ale.lives: 2.876\n",
      "\n",
      "Interval 982 (490500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.010 - mean_q: 1.360 - mean_eps: 0.558 - ale.lives: 2.968\n",
      "\n",
      "Interval 983 (491000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.003 - mae: 1.010 - mean_q: 1.361 - mean_eps: 0.558 - ale.lives: 3.076\n",
      "\n",
      "Interval 984 (491500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.003 - mae: 1.003 - mean_q: 1.353 - mean_eps: 0.557 - ale.lives: 2.420\n",
      "\n",
      "Interval 985 (492000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.014 - mean_q: 1.365 - mean_eps: 0.557 - ale.lives: 3.152\n",
      "\n",
      "Interval 986 (492500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.003 - mae: 1.010 - mean_q: 1.360 - mean_eps: 0.557 - ale.lives: 3.232\n",
      "\n",
      "Interval 987 (493000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 1.015 - mean_q: 1.368 - mean_eps: 0.556 - ale.lives: 3.208\n",
      "\n",
      "Interval 988 (493500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 4.333 [2.000, 9.000] - loss: 0.002 - mae: 1.015 - mean_q: 1.368 - mean_eps: 0.556 - ale.lives: 2.500\n",
      "\n",
      "Interval 989 (494000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.003 - mae: 1.014 - mean_q: 1.364 - mean_eps: 0.555 - ale.lives: 3.076\n",
      "\n",
      "Interval 990 (494500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 1.018 - mean_q: 1.373 - mean_eps: 0.555 - ale.lives: 2.914\n",
      "\n",
      "Interval 991 (495000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.003 - mae: 1.011 - mean_q: 1.363 - mean_eps: 0.554 - ale.lives: 2.452\n",
      "\n",
      "Interval 992 (495500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.008 - mean_q: 1.359 - mean_eps: 0.554 - ale.lives: 2.286\n",
      "\n",
      "Interval 993 (496000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.012 - mean_q: 1.365 - mean_eps: 0.553 - ale.lives: 3.454\n",
      "\n",
      "Interval 994 (496500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.007 - mean_q: 1.357 - mean_eps: 0.553 - ale.lives: 2.792\n",
      "\n",
      "Interval 995 (497000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.500 [2.000, 7.000] - loss: 0.003 - mae: 1.008 - mean_q: 1.357 - mean_eps: 0.552 - ale.lives: 2.546\n",
      "\n",
      "Interval 996 (497500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [0.000, 7.000] - loss: 0.002 - mae: 1.011 - mean_q: 1.362 - mean_eps: 0.552 - ale.lives: 3.096\n",
      "\n",
      "Interval 997 (498000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.003 - mae: 1.013 - mean_q: 1.364 - mean_eps: 0.552 - ale.lives: 2.992\n",
      "\n",
      "Interval 998 (498500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.003 - mae: 1.014 - mean_q: 1.368 - mean_eps: 0.551 - ale.lives: 2.920\n",
      "\n",
      "Interval 999 (499000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.010 - mean_q: 1.361 - mean_eps: 0.551 - ale.lives: 3.026\n",
      "\n",
      "Interval 1000 (499500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.010 - mean_q: 1.361 - mean_eps: 0.550 - ale.lives: 3.300\n",
      "\n",
      "Interval 1001 (500000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 1.029 - mean_q: 1.386 - mean_eps: 0.550 - ale.lives: 2.924\n",
      "\n",
      "Interval 1002 (500500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 1.024 - mean_q: 1.380 - mean_eps: 0.549 - ale.lives: 2.266\n",
      "\n",
      "Interval 1003 (501000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.003 - mae: 1.023 - mean_q: 1.379 - mean_eps: 0.549 - ale.lives: 2.004\n",
      "\n",
      "Interval 1004 (501500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 1.024 - mean_q: 1.381 - mean_eps: 0.548 - ale.lives: 3.502\n",
      "\n",
      "Interval 1005 (502000 steps performed)\n",
      "500/500 [==============================] - 30s 59ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.027 - mean_q: 1.383 - mean_eps: 0.548 - ale.lives: 2.880\n",
      "\n",
      "Interval 1006 (502500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 1.027 - mean_q: 1.385 - mean_eps: 0.548 - ale.lives: 2.642\n",
      "\n",
      "Interval 1007 (503000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.025 - mean_q: 1.381 - mean_eps: 0.547 - ale.lives: 2.834\n",
      "\n",
      "Interval 1008 (503500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.003 - mae: 1.019 - mean_q: 1.372 - mean_eps: 0.547 - ale.lives: 2.604\n",
      "\n",
      "Interval 1009 (504000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 1.021 - mean_q: 1.375 - mean_eps: 0.546 - ale.lives: 2.288\n",
      "\n",
      "Interval 1010 (504500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.021 - mean_q: 1.377 - mean_eps: 0.546 - ale.lives: 2.966\n",
      "\n",
      "Interval 1011 (505000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.021 - mean_q: 1.374 - mean_eps: 0.545 - ale.lives: 3.198\n",
      "\n",
      "Interval 1012 (505500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.003 - mae: 1.020 - mean_q: 1.374 - mean_eps: 0.545 - ale.lives: 2.840\n",
      "\n",
      "Interval 1013 (506000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.002 - mae: 1.023 - mean_q: 1.381 - mean_eps: 0.544 - ale.lives: 3.540\n",
      "\n",
      "Interval 1014 (506500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 1.021 - mean_q: 1.376 - mean_eps: 0.544 - ale.lives: 2.630\n",
      "\n",
      "Interval 1015 (507000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 1.016 - mean_q: 1.369 - mean_eps: 0.543 - ale.lives: 2.918\n",
      "\n",
      "Interval 1016 (507500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 1.028 - mean_q: 1.385 - mean_eps: 0.543 - ale.lives: 2.166\n",
      "\n",
      "Interval 1017 (508000 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.018 - mean_q: 1.372 - mean_eps: 0.543 - ale.lives: 3.320\n",
      "\n",
      "Interval 1018 (508500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.003 - mae: 1.021 - mean_q: 1.375 - mean_eps: 0.542 - ale.lives: 2.562\n",
      "\n",
      "Interval 1019 (509000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [0.000, 5.000] - loss: 0.003 - mae: 1.031 - mean_q: 1.389 - mean_eps: 0.542 - ale.lives: 3.416\n",
      "\n",
      "Interval 1020 (509500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.003 - mae: 1.023 - mean_q: 1.376 - mean_eps: 0.541 - ale.lives: 3.128\n",
      "\n",
      "Interval 1021 (510000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.033 - mean_q: 1.387 - mean_eps: 0.541 - ale.lives: 2.954\n",
      "\n",
      "Interval 1022 (510500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.003 - mae: 1.028 - mean_q: 1.382 - mean_eps: 0.540 - ale.lives: 2.098\n",
      "\n",
      "Interval 1023 (511000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 1.031 - mean_q: 1.386 - mean_eps: 0.540 - ale.lives: 2.546\n",
      "\n",
      "Interval 1024 (511500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.003 - mae: 1.028 - mean_q: 1.382 - mean_eps: 0.539 - ale.lives: 2.760\n",
      "\n",
      "Interval 1025 (512000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.032 - mean_q: 1.390 - mean_eps: 0.539 - ale.lives: 3.200\n",
      "\n",
      "Interval 1026 (512500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 3.000 [1.000, 7.000] - loss: 0.003 - mae: 1.033 - mean_q: 1.391 - mean_eps: 0.539 - ale.lives: 2.398\n",
      "\n",
      "Interval 1027 (513000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.031 - mean_q: 1.386 - mean_eps: 0.538 - ale.lives: 2.618\n",
      "\n",
      "Interval 1028 (513500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.003 - mae: 1.029 - mean_q: 1.385 - mean_eps: 0.538 - ale.lives: 2.874\n",
      "\n",
      "Interval 1029 (514000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 1.035 - mean_q: 1.393 - mean_eps: 0.537 - ale.lives: 2.610\n",
      "\n",
      "Interval 1030 (514500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.002 - mae: 1.033 - mean_q: 1.391 - mean_eps: 0.537 - ale.lives: 2.446\n",
      "\n",
      "Interval 1031 (515000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 1.031 - mean_q: 1.387 - mean_eps: 0.536 - ale.lives: 2.776\n",
      "\n",
      "Interval 1032 (515500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.003 - mae: 1.031 - mean_q: 1.388 - mean_eps: 0.536 - ale.lives: 2.824\n",
      "\n",
      "Interval 1033 (516000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 1.028 - mean_q: 1.383 - mean_eps: 0.535 - ale.lives: 2.438\n",
      "\n",
      "Interval 1034 (516500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.030 - mean_q: 1.385 - mean_eps: 0.535 - ale.lives: 2.784\n",
      "\n",
      "Interval 1035 (517000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 1.032 - mean_q: 1.389 - mean_eps: 0.534 - ale.lives: 2.970\n",
      "\n",
      "Interval 1036 (517500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 5.000 [0.000, 10.000] - loss: 0.003 - mae: 1.034 - mean_q: 1.391 - mean_eps: 0.534 - ale.lives: 2.686\n",
      "\n",
      "Interval 1037 (518000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.034 - mean_q: 1.391 - mean_eps: 0.534 - ale.lives: 2.236\n",
      "\n",
      "Interval 1038 (518500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [2.000, 7.000] - loss: 0.002 - mae: 1.034 - mean_q: 1.392 - mean_eps: 0.533 - ale.lives: 2.482\n",
      "\n",
      "Interval 1039 (519000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 1.026 - mean_q: 1.385 - mean_eps: 0.533 - ale.lives: 2.332\n",
      "\n",
      "Interval 1040 (519500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.002 - mae: 1.027 - mean_q: 1.382 - mean_eps: 0.532 - ale.lives: 2.922\n",
      "\n",
      "Interval 1041 (520000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 1.042 - mean_q: 1.402 - mean_eps: 0.532 - ale.lives: 2.954\n",
      "\n",
      "Interval 1042 (520500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 1.037 - mean_q: 1.395 - mean_eps: 0.531 - ale.lives: 2.494\n",
      "\n",
      "Interval 1043 (521000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.003 - mae: 1.036 - mean_q: 1.394 - mean_eps: 0.531 - ale.lives: 1.752\n",
      "\n",
      "Interval 1044 (521500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.033 - mean_q: 1.389 - mean_eps: 0.530 - ale.lives: 2.766\n",
      "\n",
      "Interval 1045 (522000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.038 - mean_q: 1.397 - mean_eps: 0.530 - ale.lives: 2.730\n",
      "\n",
      "Interval 1046 (522500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.032 - mean_q: 1.389 - mean_eps: 0.530 - ale.lives: 2.404\n",
      "\n",
      "Interval 1047 (523000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.040 - mean_q: 1.399 - mean_eps: 0.529 - ale.lives: 3.036\n",
      "\n",
      "Interval 1048 (523500 steps performed)\n",
      "500/500 [==============================] - 28s 56ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.038 - mean_q: 1.397 - mean_eps: 0.529 - ale.lives: 2.818\n",
      "\n",
      "Interval 1049 (524000 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 6.500 [6.000, 7.000] - loss: 0.002 - mae: 1.035 - mean_q: 1.394 - mean_eps: 0.528 - ale.lives: 2.834\n",
      "\n",
      "Interval 1050 (524500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 1.036 - mean_q: 1.393 - mean_eps: 0.528 - ale.lives: 3.014\n",
      "\n",
      "Interval 1051 (525000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 3.333 [2.000, 6.000] - loss: 0.003 - mae: 1.046 - mean_q: 1.406 - mean_eps: 0.527 - ale.lives: 2.964\n",
      "\n",
      "Interval 1052 (525500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.033 - mean_q: 1.391 - mean_eps: 0.527 - ale.lives: 2.630\n",
      "\n",
      "Interval 1053 (526000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.002 - mae: 1.033 - mean_q: 1.389 - mean_eps: 0.526 - ale.lives: 2.034\n",
      "\n",
      "Interval 1054 (526500 steps performed)\n",
      "500/500 [==============================] - 28s 56ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.033 - mean_q: 1.390 - mean_eps: 0.526 - ale.lives: 2.606\n",
      "\n",
      "Interval 1055 (527000 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.037 - mean_q: 1.394 - mean_eps: 0.525 - ale.lives: 2.560\n",
      "\n",
      "Interval 1056 (527500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.036 - mean_q: 1.394 - mean_eps: 0.525 - ale.lives: 2.464\n",
      "\n",
      "Interval 1057 (528000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.041 - mean_q: 1.402 - mean_eps: 0.525 - ale.lives: 2.418\n",
      "\n",
      "Interval 1058 (528500 steps performed)\n",
      "500/500 [==============================] - 28s 56ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 1.037 - mean_q: 1.396 - mean_eps: 0.524 - ale.lives: 2.764\n",
      "\n",
      "Interval 1059 (529000 steps performed)\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [0.000, 5.000] - loss: 0.003 - mae: 1.039 - mean_q: 1.398 - mean_eps: 0.524 - ale.lives: 3.330\n",
      "\n",
      "Interval 1060 (529500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 1.037 - mean_q: 1.394 - mean_eps: 0.523 - ale.lives: 2.784\n",
      "\n",
      "Interval 1061 (530000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.048 - mean_q: 1.411 - mean_eps: 0.523 - ale.lives: 2.992\n",
      "\n",
      "Interval 1062 (530500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 1.045 - mean_q: 1.406 - mean_eps: 0.522 - ale.lives: 2.260\n",
      "\n",
      "Interval 1063 (531000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.002 - mae: 1.047 - mean_q: 1.407 - mean_eps: 0.522 - ale.lives: 2.814\n",
      "\n",
      "Interval 1064 (531500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.041 - mean_q: 1.399 - mean_eps: 0.521 - ale.lives: 2.716\n",
      "\n",
      "Interval 1065 (532000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 4.000] - loss: 0.002 - mae: 1.049 - mean_q: 1.412 - mean_eps: 0.521 - ale.lives: 2.876\n",
      "\n",
      "Interval 1066 (532500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.045 - mean_q: 1.408 - mean_eps: 0.521 - ale.lives: 2.680\n",
      "\n",
      "Interval 1067 (533000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 1.046 - mean_q: 1.406 - mean_eps: 0.520 - ale.lives: 3.452\n",
      "\n",
      "Interval 1068 (533500 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 3.667 [0.000, 7.000] - loss: 0.002 - mae: 1.045 - mean_q: 1.406 - mean_eps: 0.520 - ale.lives: 2.686\n",
      "\n",
      "Interval 1069 (534000 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.002 - mae: 1.041 - mean_q: 1.401 - mean_eps: 0.519 - ale.lives: 2.800\n",
      "\n",
      "Interval 1070 (534500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.048 - mean_q: 1.410 - mean_eps: 0.519 - ale.lives: 3.104\n",
      "\n",
      "Interval 1071 (535000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.333 [0.000, 4.000] - loss: 0.003 - mae: 1.047 - mean_q: 1.412 - mean_eps: 0.518 - ale.lives: 2.894\n",
      "\n",
      "Interval 1072 (535500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 1.047 - mean_q: 1.409 - mean_eps: 0.518 - ale.lives: 3.154\n",
      "\n",
      "Interval 1073 (536000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.044 - mean_q: 1.406 - mean_eps: 0.517 - ale.lives: 2.594\n",
      "\n",
      "Interval 1074 (536500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.002 - mae: 1.041 - mean_q: 1.399 - mean_eps: 0.517 - ale.lives: 2.244\n",
      "\n",
      "Interval 1075 (537000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.047 - mean_q: 1.408 - mean_eps: 0.516 - ale.lives: 2.316\n",
      "\n",
      "Interval 1076 (537500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.044 - mean_q: 1.404 - mean_eps: 0.516 - ale.lives: 2.622\n",
      "\n",
      "Interval 1077 (538000 steps performed)\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.042 - mean_q: 1.402 - mean_eps: 0.516 - ale.lives: 2.810\n",
      "\n",
      "Interval 1078 (538500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [0.000, 7.000] - loss: 0.002 - mae: 1.048 - mean_q: 1.408 - mean_eps: 0.515 - ale.lives: 2.690\n",
      "\n",
      "Interval 1079 (539000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.043 - mean_q: 1.405 - mean_eps: 0.515 - ale.lives: 2.706\n",
      "\n",
      "Interval 1080 (539500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.043 - mean_q: 1.404 - mean_eps: 0.514 - ale.lives: 2.308\n",
      "\n",
      "Interval 1081 (540000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.003 - mae: 1.046 - mean_q: 1.406 - mean_eps: 0.514 - ale.lives: 3.258\n",
      "\n",
      "Interval 1082 (540500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.002 - mae: 1.046 - mean_q: 1.407 - mean_eps: 0.513 - ale.lives: 3.096\n",
      "\n",
      "Interval 1083 (541000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.052 - mean_q: 1.415 - mean_eps: 0.513 - ale.lives: 2.546\n",
      "\n",
      "Interval 1084 (541500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.049 - mean_q: 1.410 - mean_eps: 0.512 - ale.lives: 3.084\n",
      "\n",
      "Interval 1085 (542000 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 1.041 - mean_q: 1.400 - mean_eps: 0.512 - ale.lives: 3.116\n",
      "\n",
      "Interval 1086 (542500 steps performed)\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.049 - mean_q: 1.409 - mean_eps: 0.512 - ale.lives: 2.394\n",
      "\n",
      "Interval 1087 (543000 steps performed)\n",
      "500/500 [==============================] - 28s 56ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.002 - mae: 1.042 - mean_q: 1.400 - mean_eps: 0.511 - ale.lives: 3.002\n",
      "\n",
      "Interval 1088 (543500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.048 - mean_q: 1.408 - mean_eps: 0.511 - ale.lives: 2.592\n",
      "\n",
      "Interval 1089 (544000 steps performed)\n",
      "500/500 [==============================] - 29s 58ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.001 - mae: 1.042 - mean_q: 1.400 - mean_eps: 0.510 - ale.lives: 2.754\n",
      "\n",
      "Interval 1090 (544500 steps performed)\n",
      "500/500 [==============================] - 29s 59ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.049 - mean_q: 1.410 - mean_eps: 0.510 - ale.lives: 2.188\n",
      "\n",
      "Interval 1091 (545000 steps performed)\n",
      "500/500 [==============================] - 30s 60ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.045 - mean_q: 1.405 - mean_eps: 0.509 - ale.lives: 2.950\n",
      "\n",
      "Interval 1092 (545500 steps performed)\n",
      "500/500 [==============================] - 28s 57ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 1.045 - mean_q: 1.405 - mean_eps: 0.509 - ale.lives: 3.214\n",
      "\n",
      "Interval 1093 (546000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.002 - mae: 1.043 - mean_q: 1.402 - mean_eps: 0.508 - ale.lives: 2.684\n",
      "\n",
      "Interval 1094 (546500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.051 - mean_q: 1.413 - mean_eps: 0.508 - ale.lives: 2.440\n",
      "\n",
      "Interval 1095 (547000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 1.049 - mean_q: 1.409 - mean_eps: 0.507 - ale.lives: 2.674\n",
      "\n",
      "Interval 1096 (547500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.051 - mean_q: 1.415 - mean_eps: 0.507 - ale.lives: 2.606\n",
      "\n",
      "Interval 1097 (548000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 1.044 - mean_q: 1.405 - mean_eps: 0.507 - ale.lives: 3.006\n",
      "\n",
      "Interval 1098 (548500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.051 - mean_q: 1.414 - mean_eps: 0.506 - ale.lives: 3.126\n",
      "\n",
      "Interval 1099 (549000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.045 - mean_q: 1.406 - mean_eps: 0.506 - ale.lives: 2.832\n",
      "\n",
      "Interval 1100 (549500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.002 - mae: 1.046 - mean_q: 1.408 - mean_eps: 0.505 - ale.lives: 2.846\n",
      "\n",
      "Interval 1101 (550000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.003 - mae: 1.057 - mean_q: 1.421 - mean_eps: 0.505 - ale.lives: 2.304\n",
      "\n",
      "Interval 1102 (550500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.050 - mean_q: 1.409 - mean_eps: 0.504 - ale.lives: 2.304\n",
      "\n",
      "Interval 1103 (551000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.055 - mean_q: 1.419 - mean_eps: 0.504 - ale.lives: 2.554\n",
      "\n",
      "Interval 1104 (551500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.002 - mae: 1.050 - mean_q: 1.412 - mean_eps: 0.503 - ale.lives: 2.346\n",
      "\n",
      "Interval 1105 (552000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.048 - mean_q: 1.407 - mean_eps: 0.503 - ale.lives: 2.442\n",
      "\n",
      "Interval 1106 (552500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.059 - mean_q: 1.423 - mean_eps: 0.503 - ale.lives: 2.778\n",
      "\n",
      "Interval 1107 (553000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 1.056 - mean_q: 1.421 - mean_eps: 0.502 - ale.lives: 3.016\n",
      "\n",
      "Interval 1108 (553500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [0.000, 3.000] - loss: 0.002 - mae: 1.049 - mean_q: 1.412 - mean_eps: 0.502 - ale.lives: 2.892\n",
      "\n",
      "Interval 1109 (554000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.053 - mean_q: 1.417 - mean_eps: 0.501 - ale.lives: 3.156\n",
      "\n",
      "Interval 1110 (554500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.056 - mean_q: 1.421 - mean_eps: 0.501 - ale.lives: 2.986\n",
      "\n",
      "Interval 1111 (555000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.002 - mae: 1.053 - mean_q: 1.417 - mean_eps: 0.500 - ale.lives: 3.090\n",
      "\n",
      "Interval 1112 (555500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.054 - mean_q: 1.419 - mean_eps: 0.500 - ale.lives: 2.274\n",
      "\n",
      "Interval 1113 (556000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.003 - mae: 1.053 - mean_q: 1.416 - mean_eps: 0.499 - ale.lives: 2.636\n",
      "\n",
      "Interval 1114 (556500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.002 - mae: 1.056 - mean_q: 1.421 - mean_eps: 0.499 - ale.lives: 3.486\n",
      "\n",
      "Interval 1115 (557000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.052 - mean_q: 1.414 - mean_eps: 0.498 - ale.lives: 2.546\n",
      "\n",
      "Interval 1116 (557500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.053 - mean_q: 1.417 - mean_eps: 0.498 - ale.lives: 2.862\n",
      "\n",
      "Interval 1117 (558000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.055 - mean_q: 1.419 - mean_eps: 0.498 - ale.lives: 2.244\n",
      "\n",
      "Interval 1118 (558500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.056 - mean_q: 1.420 - mean_eps: 0.497 - ale.lives: 2.774\n",
      "\n",
      "Interval 1119 (559000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.667 [0.000, 6.000] - loss: 0.002 - mae: 1.052 - mean_q: 1.416 - mean_eps: 0.497 - ale.lives: 2.768\n",
      "\n",
      "Interval 1120 (559500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [0.000, 7.000] - loss: 0.002 - mae: 1.052 - mean_q: 1.415 - mean_eps: 0.496 - ale.lives: 2.598\n",
      "\n",
      "Interval 1121 (560000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.059 - mean_q: 1.423 - mean_eps: 0.496 - ale.lives: 2.830\n",
      "\n",
      "Interval 1122 (560500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.059 - mean_q: 1.422 - mean_eps: 0.495 - ale.lives: 2.514\n",
      "\n",
      "Interval 1123 (561000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 1.667 [0.000, 5.000] - loss: 0.002 - mae: 1.061 - mean_q: 1.426 - mean_eps: 0.495 - ale.lives: 2.800\n",
      "\n",
      "Interval 1124 (561500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.055 - mean_q: 1.419 - mean_eps: 0.494 - ale.lives: 2.544\n",
      "\n",
      "Interval 1125 (562000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [3.000, 7.000] - loss: 0.002 - mae: 1.053 - mean_q: 1.417 - mean_eps: 0.494 - ale.lives: 2.704\n",
      "\n",
      "Interval 1126 (562500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.001 - mae: 1.051 - mean_q: 1.415 - mean_eps: 0.494 - ale.lives: 2.112\n",
      "\n",
      "Interval 1127 (563000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.058 - mean_q: 1.424 - mean_eps: 0.493 - ale.lives: 2.616\n",
      "\n",
      "Interval 1128 (563500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 1.054 - mean_q: 1.417 - mean_eps: 0.493 - ale.lives: 3.114\n",
      "\n",
      "Interval 1129 (564000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.002 - mae: 1.059 - mean_q: 1.423 - mean_eps: 0.492 - ale.lives: 2.368\n",
      "\n",
      "Interval 1130 (564500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 1.056 - mean_q: 1.419 - mean_eps: 0.492 - ale.lives: 2.956\n",
      "\n",
      "Interval 1131 (565000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.049 - mean_q: 1.411 - mean_eps: 0.491 - ale.lives: 2.746\n",
      "\n",
      "Interval 1132 (565500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 1.054 - mean_q: 1.417 - mean_eps: 0.491 - ale.lives: 2.616\n",
      "\n",
      "Interval 1133 (566000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.057 - mean_q: 1.423 - mean_eps: 0.490 - ale.lives: 2.756\n",
      "\n",
      "Interval 1134 (566500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.002 - mae: 1.054 - mean_q: 1.416 - mean_eps: 0.490 - ale.lives: 3.122\n",
      "\n",
      "Interval 1135 (567000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.055 - mean_q: 1.420 - mean_eps: 0.489 - ale.lives: 2.416\n",
      "\n",
      "Interval 1136 (567500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 6.000 [3.000, 9.000] - loss: 0.002 - mae: 1.059 - mean_q: 1.424 - mean_eps: 0.489 - ale.lives: 2.346\n",
      "\n",
      "Interval 1137 (568000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 1.057 - mean_q: 1.423 - mean_eps: 0.489 - ale.lives: 2.260\n",
      "\n",
      "Interval 1138 (568500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.055 - mean_q: 1.420 - mean_eps: 0.488 - ale.lives: 2.952\n",
      "\n",
      "Interval 1139 (569000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.050 - mean_q: 1.413 - mean_eps: 0.488 - ale.lives: 2.870\n",
      "\n",
      "Interval 1140 (569500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.057 - mean_q: 1.423 - mean_eps: 0.487 - ale.lives: 2.946\n",
      "\n",
      "Interval 1141 (570000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.431 - mean_eps: 0.487 - ale.lives: 2.230\n",
      "\n",
      "Interval 1142 (570500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.003 - mae: 1.059 - mean_q: 1.426 - mean_eps: 0.486 - ale.lives: 2.302\n",
      "\n",
      "Interval 1143 (571000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.431 - mean_eps: 0.486 - ale.lives: 2.774\n",
      "\n",
      "Interval 1144 (571500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "4 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.431 - mean_eps: 0.485 - ale.lives: 3.058\n",
      "\n",
      "Interval 1145 (572000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.067 - mean_q: 1.434 - mean_eps: 0.485 - ale.lives: 2.442\n",
      "\n",
      "Interval 1146 (572500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.436 - mean_eps: 0.485 - ale.lives: 2.514\n",
      "\n",
      "Interval 1147 (573000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.667 [1.000, 3.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.484 - ale.lives: 3.230\n",
      "\n",
      "Interval 1148 (573500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 23s 46ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.064 - mean_q: 1.429 - mean_eps: 0.484 - ale.lives: 2.156\n",
      "\n",
      "Interval 1149 (574000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.056 - mean_q: 1.421 - mean_eps: 0.483 - ale.lives: 2.120\n",
      "\n",
      "Interval 1150 (574500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.060 - mean_q: 1.426 - mean_eps: 0.483 - ale.lives: 2.686\n",
      "\n",
      "Interval 1151 (575000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.054 - mean_q: 1.418 - mean_eps: 0.482 - ale.lives: 2.968\n",
      "\n",
      "Interval 1152 (575500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.001 - mae: 1.063 - mean_q: 1.428 - mean_eps: 0.482 - ale.lives: 2.828\n",
      "\n",
      "Interval 1153 (576000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.432 - mean_eps: 0.481 - ale.lives: 2.714\n",
      "\n",
      "Interval 1154 (576500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 1.064 - mean_q: 1.432 - mean_eps: 0.481 - ale.lives: 2.926\n",
      "\n",
      "Interval 1155 (577000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.002 - mae: 1.056 - mean_q: 1.420 - mean_eps: 0.480 - ale.lives: 2.148\n",
      "\n",
      "Interval 1156 (577500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.062 - mean_q: 1.427 - mean_eps: 0.480 - ale.lives: 2.774\n",
      "\n",
      "Interval 1157 (578000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.060 - mean_q: 1.426 - mean_eps: 0.480 - ale.lives: 2.196\n",
      "\n",
      "Interval 1158 (578500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 2.000 [0.000, 6.000] - loss: 0.002 - mae: 1.062 - mean_q: 1.430 - mean_eps: 0.479 - ale.lives: 2.842\n",
      "\n",
      "Interval 1159 (579000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.058 - mean_q: 1.422 - mean_eps: 0.479 - ale.lives: 2.814\n",
      "\n",
      "Interval 1160 (579500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.064 - mean_q: 1.431 - mean_eps: 0.478 - ale.lives: 2.666\n",
      "\n",
      "Interval 1161 (580000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.003 - mae: 1.069 - mean_q: 1.435 - mean_eps: 0.478 - ale.lives: 3.006\n",
      "\n",
      "Interval 1162 (580500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.440 - mean_eps: 0.477 - ale.lives: 2.222\n",
      "\n",
      "Interval 1163 (581000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.443 - mean_eps: 0.477 - ale.lives: 2.440\n",
      "\n",
      "Interval 1164 (581500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [0.000, 5.000] - loss: 0.002 - mae: 1.070 - mean_q: 1.437 - mean_eps: 0.476 - ale.lives: 2.448\n",
      "\n",
      "Interval 1165 (582000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.064 - mean_q: 1.429 - mean_eps: 0.476 - ale.lives: 2.514\n",
      "\n",
      "Interval 1166 (582500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 1.070 - mean_q: 1.437 - mean_eps: 0.476 - ale.lives: 2.542\n",
      "\n",
      "Interval 1167 (583000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.475 - ale.lives: 2.634\n",
      "\n",
      "Interval 1168 (583500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.437 - mean_eps: 0.475 - ale.lives: 2.806\n",
      "\n",
      "Interval 1169 (584000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.067 - mean_q: 1.435 - mean_eps: 0.474 - ale.lives: 2.950\n",
      "\n",
      "Interval 1170 (584500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.437 - mean_eps: 0.474 - ale.lives: 2.224\n",
      "\n",
      "Interval 1171 (585000 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.434 - mean_eps: 0.473 - ale.lives: 2.626\n",
      "\n",
      "Interval 1172 (585500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.432 - mean_eps: 0.473 - ale.lives: 2.356\n",
      "\n",
      "Interval 1173 (586000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.333 [0.000, 4.000] - loss: 0.002 - mae: 1.067 - mean_q: 1.434 - mean_eps: 0.472 - ale.lives: 2.702\n",
      "\n",
      "Interval 1174 (586500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.001 - mae: 1.070 - mean_q: 1.439 - mean_eps: 0.472 - ale.lives: 2.594\n",
      "\n",
      "Interval 1175 (587000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [1.000, 8.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.430 - mean_eps: 0.471 - ale.lives: 2.096\n",
      "\n",
      "Interval 1176 (587500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.061 - mean_q: 1.427 - mean_eps: 0.471 - ale.lives: 2.832\n",
      "\n",
      "Interval 1177 (588000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.070 - mean_q: 1.436 - mean_eps: 0.471 - ale.lives: 2.370\n",
      "\n",
      "Interval 1178 (588500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.441 - mean_eps: 0.470 - ale.lives: 2.524\n",
      "\n",
      "Interval 1179 (589000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 1.062 - mean_q: 1.429 - mean_eps: 0.470 - ale.lives: 3.006\n",
      "\n",
      "Interval 1180 (589500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.002 - mae: 1.071 - mean_q: 1.440 - mean_eps: 0.469 - ale.lives: 2.802\n",
      "\n",
      "Interval 1181 (590000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.441 - mean_eps: 0.469 - ale.lives: 2.432\n",
      "\n",
      "Interval 1182 (590500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.003 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.468 - ale.lives: 2.274\n",
      "\n",
      "Interval 1183 (591000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 5.500 [4.000, 7.000] - loss: 0.002 - mae: 1.070 - mean_q: 1.438 - mean_eps: 0.468 - ale.lives: 3.386\n",
      "\n",
      "Interval 1184 (591500 steps performed)\n",
      "500/500 [==============================] - 23s 47ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.446 - mean_eps: 0.467 - ale.lives: 2.954\n",
      "\n",
      "Interval 1185 (592000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.441 - mean_eps: 0.467 - ale.lives: 2.422\n",
      "\n",
      "Interval 1186 (592500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.333 [0.000, 1.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.437 - mean_eps: 0.467 - ale.lives: 2.924\n",
      "\n",
      "Interval 1187 (593000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.444 - mean_eps: 0.466 - ale.lives: 2.442\n",
      "\n",
      "Interval 1188 (593500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.667 [0.000, 6.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.440 - mean_eps: 0.466 - ale.lives: 2.588\n",
      "\n",
      "Interval 1189 (594000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.465 - ale.lives: 2.116\n",
      "\n",
      "Interval 1190 (594500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [0.000, 4.000] - loss: 0.002 - mae: 1.064 - mean_q: 1.428 - mean_eps: 0.465 - ale.lives: 2.504\n",
      "\n",
      "Interval 1191 (595000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 0.500 [0.000, 1.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.436 - mean_eps: 0.464 - ale.lives: 3.520\n",
      "\n",
      "Interval 1192 (595500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.000 [0.000, 8.000] - loss: 0.002 - mae: 1.070 - mean_q: 1.439 - mean_eps: 0.464 - ale.lives: 2.566\n",
      "\n",
      "Interval 1193 (596000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.444 - mean_eps: 0.463 - ale.lives: 2.432\n",
      "\n",
      "Interval 1194 (596500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.441 - mean_eps: 0.463 - ale.lives: 2.220\n",
      "\n",
      "Interval 1195 (597000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.440 - mean_eps: 0.462 - ale.lives: 2.978\n",
      "\n",
      "Interval 1196 (597500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.441 - mean_eps: 0.462 - ale.lives: 2.282\n",
      "\n",
      "Interval 1197 (598000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.450 - mean_eps: 0.462 - ale.lives: 2.652\n",
      "\n",
      "Interval 1198 (598500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 1.076 - mean_q: 1.445 - mean_eps: 0.461 - ale.lives: 2.740\n",
      "\n",
      "Interval 1199 (599000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.440 - mean_eps: 0.461 - ale.lives: 2.698\n",
      "\n",
      "Interval 1200 (599500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.001 - mae: 1.077 - mean_q: 1.447 - mean_eps: 0.460 - ale.lives: 2.094\n",
      "\n",
      "Interval 1201 (600000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.448 - mean_eps: 0.460 - ale.lives: 2.452\n",
      "\n",
      "Interval 1202 (600500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.444 - mean_eps: 0.459 - ale.lives: 2.118\n",
      "\n",
      "Interval 1203 (601000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.451 - mean_eps: 0.459 - ale.lives: 2.730\n",
      "\n",
      "Interval 1204 (601500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.446 - mean_eps: 0.458 - ale.lives: 2.886\n",
      "\n",
      "Interval 1205 (602000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.446 - mean_eps: 0.458 - ale.lives: 2.254\n",
      "\n",
      "Interval 1206 (602500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [0.000, 7.000] - loss: 0.003 - mae: 1.078 - mean_q: 1.446 - mean_eps: 0.458 - ale.lives: 2.296\n",
      "\n",
      "Interval 1207 (603000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 1.070 - mean_q: 1.436 - mean_eps: 0.457 - ale.lives: 2.656\n",
      "\n",
      "Interval 1208 (603500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 2.667 [0.000, 7.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.451 - mean_eps: 0.457 - ale.lives: 2.792\n",
      "\n",
      "Interval 1209 (604000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.440 - mean_eps: 0.456 - ale.lives: 2.984\n",
      "\n",
      "Interval 1210 (604500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.084 - mean_q: 1.455 - mean_eps: 0.456 - ale.lives: 2.526\n",
      "\n",
      "Interval 1211 (605000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.448 - mean_eps: 0.455 - ale.lives: 2.288\n",
      "\n",
      "Interval 1212 (605500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 3.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.444 - mean_eps: 0.455 - ale.lives: 2.930\n",
      "\n",
      "Interval 1213 (606000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.447 - mean_eps: 0.454 - ale.lives: 2.182\n",
      "\n",
      "Interval 1214 (606500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0000e+00\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.447 - mean_eps: 0.454 - ale.lives: 3.020\n",
      "\n",
      "Interval 1215 (607000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 1.085 - mean_q: 1.456 - mean_eps: 0.453 - ale.lives: 2.716\n",
      "\n",
      "Interval 1216 (607500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 2.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.443 - mean_eps: 0.453 - ale.lives: 2.610\n",
      "\n",
      "Interval 1217 (608000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.451 - mean_eps: 0.453 - ale.lives: 2.192\n",
      "\n",
      "Interval 1218 (608500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 1.086 - mean_q: 1.456 - mean_eps: 0.452 - ale.lives: 2.840\n",
      "\n",
      "Interval 1219 (609000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.071 - mean_q: 1.438 - mean_eps: 0.452 - ale.lives: 2.344\n",
      "\n",
      "Interval 1220 (609500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.446 - mean_eps: 0.451 - ale.lives: 2.098\n",
      "\n",
      "Interval 1221 (610000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.451 - ale.lives: 2.384\n",
      "\n",
      "Interval 1222 (610500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.446 - mean_eps: 0.450 - ale.lives: 2.790\n",
      "\n",
      "Interval 1223 (611000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.439 - mean_eps: 0.450 - ale.lives: 2.334\n",
      "\n",
      "Interval 1224 (611500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.449 - ale.lives: 3.054\n",
      "\n",
      "Interval 1225 (612000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.084 - mean_q: 1.453 - mean_eps: 0.449 - ale.lives: 2.926\n",
      "\n",
      "Interval 1226 (612500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 1.667 [0.000, 4.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.440 - mean_eps: 0.449 - ale.lives: 2.778\n",
      "\n",
      "Interval 1227 (613000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.440 - mean_eps: 0.448 - ale.lives: 3.132\n",
      "\n",
      "Interval 1228 (613500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.003 - mae: 1.079 - mean_q: 1.446 - mean_eps: 0.448 - ale.lives: 2.694\n",
      "\n",
      "Interval 1229 (614000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [1.000, 4.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.444 - mean_eps: 0.447 - ale.lives: 2.314\n",
      "\n",
      "Interval 1230 (614500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.437 - mean_eps: 0.447 - ale.lives: 2.574\n",
      "\n",
      "Interval 1231 (615000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.448 - mean_eps: 0.446 - ale.lives: 2.480\n",
      "\n",
      "Interval 1232 (615500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.447 - mean_eps: 0.446 - ale.lives: 2.282\n",
      "\n",
      "Interval 1233 (616000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.446 - mean_eps: 0.445 - ale.lives: 2.300\n",
      "\n",
      "Interval 1234 (616500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.449 - mean_eps: 0.445 - ale.lives: 2.508\n",
      "\n",
      "Interval 1235 (617000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.445 - mean_eps: 0.444 - ale.lives: 2.636\n",
      "\n",
      "Interval 1236 (617500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.444 - mean_eps: 0.444 - ale.lives: 2.570\n",
      "\n",
      "Interval 1237 (618000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.500 [2.000, 9.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.443 - mean_eps: 0.444 - ale.lives: 2.440\n",
      "\n",
      "Interval 1238 (618500 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.447 - mean_eps: 0.443 - ale.lives: 3.012\n",
      "\n",
      "Interval 1239 (619000 steps performed)\n",
      "500/500 [==============================] - 24s 47ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 6.000 [4.000, 8.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.441 - mean_eps: 0.443 - ale.lives: 1.682\n",
      "\n",
      "Interval 1240 (619500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0020\n",
      "3 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.001 - mae: 1.075 - mean_q: 1.441 - mean_eps: 0.442 - ale.lives: 3.210\n",
      "\n",
      "Interval 1241 (620000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.433 - mean_eps: 0.442 - ale.lives: 2.700\n",
      "\n",
      "Interval 1242 (620500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [2.000, 6.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.442 - mean_eps: 0.441 - ale.lives: 2.300\n",
      "\n",
      "Interval 1243 (621000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.444 - mean_eps: 0.441 - ale.lives: 2.288\n",
      "\n",
      "Interval 1244 (621500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.444 - mean_eps: 0.440 - ale.lives: 2.588\n",
      "\n",
      "Interval 1245 (622000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [0.000, 6.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.440 - ale.lives: 2.314\n",
      "\n",
      "Interval 1246 (622500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.444 - mean_eps: 0.440 - ale.lives: 3.002\n",
      "\n",
      "Interval 1247 (623000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.446 - mean_eps: 0.439 - ale.lives: 2.622\n",
      "\n",
      "Interval 1248 (623500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.444 - mean_eps: 0.439 - ale.lives: 2.536\n",
      "\n",
      "Interval 1249 (624000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.667 [1.000, 6.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.450 - mean_eps: 0.438 - ale.lives: 2.726\n",
      "\n",
      "Interval 1250 (624500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.071 - mean_q: 1.438 - mean_eps: 0.438 - ale.lives: 3.202\n",
      "\n",
      "Interval 1251 (625000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 5.000 [0.000, 10.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.445 - mean_eps: 0.437 - ale.lives: 2.602\n",
      "\n",
      "Interval 1252 (625500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.442 - mean_eps: 0.437 - ale.lives: 1.880\n",
      "\n",
      "Interval 1253 (626000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0040\n",
      "3 episodes - episode_reward: 0.667 [0.000, 1.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.445 - mean_eps: 0.436 - ale.lives: 2.742\n",
      "\n",
      "Interval 1254 (626500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0040\n",
      "2 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.448 - mean_eps: 0.436 - ale.lives: 3.366\n",
      "\n",
      "Interval 1255 (627000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.447 - mean_eps: 0.435 - ale.lives: 2.762\n",
      "\n",
      "Interval 1256 (627500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.442 - mean_eps: 0.435 - ale.lives: 2.586\n",
      "\n",
      "Interval 1257 (628000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.447 - mean_eps: 0.435 - ale.lives: 2.694\n",
      "\n",
      "Interval 1258 (628500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.001 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.434 - ale.lives: 2.514\n",
      "\n",
      "Interval 1259 (629000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.446 - mean_eps: 0.434 - ale.lives: 2.160\n",
      "\n",
      "Interval 1260 (629500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.446 - mean_eps: 0.433 - ale.lives: 2.366\n",
      "\n",
      "Interval 1261 (630000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [0.000, 7.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.443 - mean_eps: 0.433 - ale.lives: 2.488\n",
      "\n",
      "Interval 1262 (630500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.432 - ale.lives: 2.392\n",
      "\n",
      "Interval 1263 (631000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.450 - mean_eps: 0.432 - ale.lives: 3.616\n",
      "\n",
      "Interval 1264 (631500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.441 - mean_eps: 0.431 - ale.lives: 2.360\n",
      "\n",
      "Interval 1265 (632000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 5.500 [5.000, 6.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.440 - mean_eps: 0.431 - ale.lives: 3.360\n",
      "\n",
      "Interval 1266 (632500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 1.667 [1.000, 2.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.444 - mean_eps: 0.431 - ale.lives: 2.846\n",
      "\n",
      "Interval 1267 (633000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.449 - mean_eps: 0.430 - ale.lives: 2.796\n",
      "\n",
      "Interval 1268 (633500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.442 - mean_eps: 0.430 - ale.lives: 2.220\n",
      "\n",
      "Interval 1269 (634000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.443 - mean_eps: 0.429 - ale.lives: 3.362\n",
      "\n",
      "Interval 1270 (634500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.440 - mean_eps: 0.429 - ale.lives: 2.310\n",
      "\n",
      "Interval 1271 (635000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.440 - mean_eps: 0.428 - ale.lives: 2.674\n",
      "\n",
      "Interval 1272 (635500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 2.000 [0.000, 6.000] - loss: 0.002 - mae: 1.067 - mean_q: 1.432 - mean_eps: 0.428 - ale.lives: 3.026\n",
      "\n",
      "Interval 1273 (636000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.441 - mean_eps: 0.427 - ale.lives: 2.614\n",
      "\n",
      "Interval 1274 (636500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.083 - mean_q: 1.452 - mean_eps: 0.427 - ale.lives: 3.120\n",
      "\n",
      "Interval 1275 (637000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [4.000, 6.000] - loss: 0.001 - mae: 1.073 - mean_q: 1.440 - mean_eps: 0.426 - ale.lives: 3.136\n",
      "\n",
      "Interval 1276 (637500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.444 - mean_eps: 0.426 - ale.lives: 3.228\n",
      "\n",
      "Interval 1277 (638000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.445 - mean_eps: 0.426 - ale.lives: 2.952\n",
      "\n",
      "Interval 1278 (638500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 3.333 [1.000, 8.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.443 - mean_eps: 0.425 - ale.lives: 2.534\n",
      "\n",
      "Interval 1279 (639000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.080 - mean_q: 1.448 - mean_eps: 0.425 - ale.lives: 2.830\n",
      "\n",
      "Interval 1280 (639500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.000 [2.000, 4.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.442 - mean_eps: 0.424 - ale.lives: 2.782\n",
      "\n",
      "Interval 1281 (640000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [1.000, 2.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.434 - mean_eps: 0.424 - ale.lives: 2.856\n",
      "\n",
      "Interval 1282 (640500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.436 - mean_eps: 0.423 - ale.lives: 2.306\n",
      "\n",
      "Interval 1283 (641000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.067 - mean_q: 1.433 - mean_eps: 0.423 - ale.lives: 3.032\n",
      "\n",
      "Interval 1284 (641500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.003 - mae: 1.067 - mean_q: 1.432 - mean_eps: 0.422 - ale.lives: 2.668\n",
      "\n",
      "Interval 1285 (642000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.064 - mean_q: 1.430 - mean_eps: 0.422 - ale.lives: 1.980\n",
      "\n",
      "Interval 1286 (642500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.500 [4.000, 7.000] - loss: 0.002 - mae: 1.066 - mean_q: 1.432 - mean_eps: 0.422 - ale.lives: 2.434\n",
      "\n",
      "Interval 1287 (643000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.441 - mean_eps: 0.421 - ale.lives: 2.380\n",
      "\n",
      "Interval 1288 (643500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.434 - mean_eps: 0.421 - ale.lives: 2.432\n",
      "\n",
      "Interval 1289 (644000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.500 [3.000, 6.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.420 - ale.lives: 2.464\n",
      "\n",
      "Interval 1290 (644500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 1.000 [1.000, 1.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.443 - mean_eps: 0.420 - ale.lives: 3.286\n",
      "\n",
      "Interval 1291 (645000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.001 - mae: 1.071 - mean_q: 1.439 - mean_eps: 0.419 - ale.lives: 2.674\n",
      "\n",
      "Interval 1292 (645500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 5.000 [2.000, 8.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.436 - mean_eps: 0.419 - ale.lives: 2.488\n",
      "\n",
      "Interval 1293 (646000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.000 [1.000, 5.000] - loss: 0.002 - mae: 1.065 - mean_q: 1.431 - mean_eps: 0.418 - ale.lives: 3.422\n",
      "\n",
      "Interval 1294 (646500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.071 - mean_q: 1.437 - mean_eps: 0.418 - ale.lives: 2.868\n",
      "\n",
      "Interval 1295 (647000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0060\n",
      "3 episodes - episode_reward: 1.333 [0.000, 2.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.417 - ale.lives: 2.550\n",
      "\n",
      "Interval 1296 (647500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.417 - ale.lives: 3.150\n",
      "\n",
      "Interval 1297 (648000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.000 [0.000, 2.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.440 - mean_eps: 0.417 - ale.lives: 2.700\n",
      "\n",
      "Interval 1298 (648500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.438 - mean_eps: 0.416 - ale.lives: 2.700\n",
      "\n",
      "Interval 1299 (649000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0080\n",
      "3 episodes - episode_reward: 2.333 [0.000, 4.000] - loss: 0.001 - mae: 1.076 - mean_q: 1.446 - mean_eps: 0.416 - ale.lives: 3.074\n",
      "\n",
      "Interval 1300 (649500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.001 - mae: 1.075 - mean_q: 1.444 - mean_eps: 0.415 - ale.lives: 2.844\n",
      "\n",
      "Interval 1301 (650000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.451 - mean_eps: 0.415 - ale.lives: 2.988\n",
      "\n",
      "Interval 1302 (650500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.069 - mean_q: 1.436 - mean_eps: 0.414 - ale.lives: 3.002\n",
      "\n",
      "Interval 1303 (651000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.434 - mean_eps: 0.414 - ale.lives: 3.106\n",
      "\n",
      "Interval 1304 (651500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.071 - mean_q: 1.438 - mean_eps: 0.413 - ale.lives: 2.712\n",
      "\n",
      "Interval 1305 (652000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [1.000, 6.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.443 - mean_eps: 0.413 - ale.lives: 2.992\n",
      "\n",
      "Interval 1306 (652500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.446 - mean_eps: 0.413 - ale.lives: 2.228\n",
      "\n",
      "Interval 1307 (653000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.066 - mean_q: 1.434 - mean_eps: 0.412 - ale.lives: 3.124\n",
      "\n",
      "Interval 1308 (653500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.441 - mean_eps: 0.412 - ale.lives: 2.996\n",
      "\n",
      "Interval 1309 (654000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.066 - mean_q: 1.435 - mean_eps: 0.411 - ale.lives: 2.984\n",
      "\n",
      "Interval 1310 (654500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 6.000 [4.000, 8.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.447 - mean_eps: 0.411 - ale.lives: 2.748\n",
      "\n",
      "Interval 1311 (655000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 2.000 [2.000, 2.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.443 - mean_eps: 0.410 - ale.lives: 2.870\n",
      "\n",
      "Interval 1312 (655500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 6.500 [4.000, 9.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.441 - mean_eps: 0.410 - ale.lives: 2.472\n",
      "\n",
      "Interval 1313 (656000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0060\n",
      "2 episodes - episode_reward: 1.500 [0.000, 3.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.441 - mean_eps: 0.409 - ale.lives: 2.462\n",
      "\n",
      "Interval 1314 (656500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.444 - mean_eps: 0.409 - ale.lives: 2.612\n",
      "\n",
      "Interval 1315 (657000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.443 - mean_eps: 0.408 - ale.lives: 2.588\n",
      "\n",
      "Interval 1316 (657500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [3.000, 7.000] - loss: 0.001 - mae: 1.073 - mean_q: 1.443 - mean_eps: 0.408 - ale.lives: 3.144\n",
      "\n",
      "Interval 1317 (658000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.000 [1.000, 3.000] - loss: 0.001 - mae: 1.075 - mean_q: 1.445 - mean_eps: 0.408 - ale.lives: 2.998\n",
      "\n",
      "Interval 1318 (658500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.001 - mae: 1.073 - mean_q: 1.442 - mean_eps: 0.407 - ale.lives: 2.308\n",
      "\n",
      "Interval 1319 (659000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "3 episodes - episode_reward: 2.667 [2.000, 3.000] - loss: 0.002 - mae: 1.071 - mean_q: 1.439 - mean_eps: 0.407 - ale.lives: 3.122\n",
      "\n",
      "Interval 1320 (659500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 2.500 [2.000, 3.000] - loss: 0.001 - mae: 1.066 - mean_q: 1.434 - mean_eps: 0.406 - ale.lives: 2.720\n",
      "\n",
      "Interval 1321 (660000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.442 - mean_eps: 0.406 - ale.lives: 2.758\n",
      "\n",
      "Interval 1322 (660500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.500 [4.000, 5.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.445 - mean_eps: 0.405 - ale.lives: 3.048\n",
      "\n",
      "Interval 1323 (661000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.083 - mean_q: 1.455 - mean_eps: 0.405 - ale.lives: 2.494\n",
      "\n",
      "Interval 1324 (661500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.000 [3.000, 3.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.448 - mean_eps: 0.404 - ale.lives: 2.792\n",
      "\n",
      "Interval 1325 (662000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.443 - mean_eps: 0.404 - ale.lives: 3.092\n",
      "\n",
      "Interval 1326 (662500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.001 - mae: 1.081 - mean_q: 1.454 - mean_eps: 0.404 - ale.lives: 3.788\n",
      "\n",
      "Interval 1327 (663000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 6.000 [2.000, 10.000] - loss: 0.001 - mae: 1.070 - mean_q: 1.438 - mean_eps: 0.403 - ale.lives: 2.998\n",
      "\n",
      "Interval 1328 (663500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.068 - mean_q: 1.435 - mean_eps: 0.403 - ale.lives: 3.268\n",
      "\n",
      "Interval 1329 (664000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 2.500 [0.000, 5.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.447 - mean_eps: 0.402 - ale.lives: 2.840\n",
      "\n",
      "Interval 1330 (664500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.000 [3.000, 7.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.450 - mean_eps: 0.402 - ale.lives: 2.070\n",
      "\n",
      "Interval 1331 (665000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.448 - mean_eps: 0.401 - ale.lives: 2.948\n",
      "\n",
      "Interval 1332 (665500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.066 - mean_q: 1.434 - mean_eps: 0.401 - ale.lives: 2.636\n",
      "\n",
      "Interval 1333 (666000 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 4.000 [1.000, 7.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.450 - mean_eps: 0.400 - ale.lives: 3.562\n",
      "\n",
      "Interval 1334 (666500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0100\n",
      "2 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.439 - mean_eps: 0.400 - ale.lives: 3.002\n",
      "\n",
      "Interval 1335 (667000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.062 - mean_q: 1.429 - mean_eps: 0.399 - ale.lives: 2.626\n",
      "\n",
      "Interval 1336 (667500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.082 - mean_q: 1.454 - mean_eps: 0.399 - ale.lives: 2.942\n",
      "\n",
      "Interval 1337 (668000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.001 - mae: 1.076 - mean_q: 1.447 - mean_eps: 0.399 - ale.lives: 3.052\n",
      "\n",
      "Interval 1338 (668500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 4.000 [3.000, 5.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.448 - mean_eps: 0.398 - ale.lives: 2.914\n",
      "\n",
      "Interval 1339 (669000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.448 - mean_eps: 0.398 - ale.lives: 2.954\n",
      "\n",
      "Interval 1340 (669500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.078 - mean_q: 1.451 - mean_eps: 0.397 - ale.lives: 2.276\n",
      "\n",
      "Interval 1341 (670000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.450 - mean_eps: 0.397 - ale.lives: 2.390\n",
      "\n",
      "Interval 1342 (670500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.451 - mean_eps: 0.396 - ale.lives: 2.810\n",
      "\n",
      "Interval 1343 (671000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.453 - mean_eps: 0.396 - ale.lives: 3.288\n",
      "\n",
      "Interval 1344 (671500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.073 - mean_q: 1.446 - mean_eps: 0.395 - ale.lives: 3.356\n",
      "\n",
      "Interval 1345 (672000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.072 - mean_q: 1.443 - mean_eps: 0.395 - ale.lives: 2.836\n",
      "\n",
      "Interval 1346 (672500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.454 - mean_eps: 0.395 - ale.lives: 3.144\n",
      "\n",
      "Interval 1347 (673000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.001 - mae: 1.084 - mean_q: 1.459 - mean_eps: 0.394 - ale.lives: 2.530\n",
      "\n",
      "Interval 1348 (673500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.454 - mean_eps: 0.394 - ale.lives: 2.726\n",
      "\n",
      "Interval 1349 (674000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 8.500 [6.000, 11.000] - loss: 0.002 - mae: 1.077 - mean_q: 1.451 - mean_eps: 0.393 - ale.lives: 2.546\n",
      "\n",
      "Interval 1350 (674500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.074 - mean_q: 1.446 - mean_eps: 0.393 - ale.lives: 3.186\n",
      "\n",
      "Interval 1351 (675000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.081 - mean_q: 1.456 - mean_eps: 0.392 - ale.lives: 2.354\n",
      "\n",
      "Interval 1352 (675500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.079 - mean_q: 1.453 - mean_eps: 0.392 - ale.lives: 3.226\n",
      "\n",
      "Interval 1353 (676000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.082 - mean_q: 1.457 - mean_eps: 0.391 - ale.lives: 3.038\n",
      "\n",
      "Interval 1354 (676500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0080\n",
      "2 episodes - episode_reward: 5.500 [3.000, 8.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.450 - mean_eps: 0.391 - ale.lives: 2.818\n",
      "\n",
      "Interval 1355 (677000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.084 - mean_q: 1.459 - mean_eps: 0.390 - ale.lives: 3.306\n",
      "\n",
      "Interval 1356 (677500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 6.500 [5.000, 8.000] - loss: 0.001 - mae: 1.083 - mean_q: 1.458 - mean_eps: 0.390 - ale.lives: 2.988\n",
      "\n",
      "Interval 1357 (678000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.076 - mean_q: 1.451 - mean_eps: 0.390 - ale.lives: 3.894\n",
      "\n",
      "Interval 1358 (678500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.001 - mae: 1.077 - mean_q: 1.451 - mean_eps: 0.389 - ale.lives: 2.558\n",
      "\n",
      "Interval 1359 (679000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.001 - mae: 1.075 - mean_q: 1.449 - mean_eps: 0.389 - ale.lives: 3.054\n",
      "\n",
      "Interval 1360 (679500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0120\n",
      "2 episodes - episode_reward: 3.500 [3.000, 4.000] - loss: 0.002 - mae: 1.075 - mean_q: 1.449 - mean_eps: 0.388 - ale.lives: 2.828\n",
      "\n",
      "Interval 1361 (680000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.096 - mean_q: 1.475 - mean_eps: 0.388 - ale.lives: 4.000\n",
      "\n",
      "Interval 1362 (680500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.092 - mean_q: 1.473 - mean_eps: 0.387 - ale.lives: 3.766\n",
      "\n",
      "Interval 1363 (681000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.089 - mean_q: 1.469 - mean_eps: 0.387 - ale.lives: 2.864\n",
      "\n",
      "Interval 1364 (681500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.001 - mae: 1.092 - mean_q: 1.470 - mean_eps: 0.386 - ale.lives: 2.898\n",
      "\n",
      "Interval 1365 (682000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.092 - mean_q: 1.471 - mean_eps: 0.386 - ale.lives: 3.206\n",
      "\n",
      "Interval 1366 (682500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 7.500 [7.000, 8.000] - loss: 0.002 - mae: 1.089 - mean_q: 1.468 - mean_eps: 0.386 - ale.lives: 3.062\n",
      "\n",
      "Interval 1367 (683000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.089 - mean_q: 1.468 - mean_eps: 0.385 - ale.lives: 3.256\n",
      "\n",
      "Interval 1368 (683500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.083 - mean_q: 1.459 - mean_eps: 0.385 - ale.lives: 2.528\n",
      "\n",
      "Interval 1369 (684000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.088 - mean_q: 1.466 - mean_eps: 0.384 - ale.lives: 3.148\n",
      "\n",
      "Interval 1370 (684500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.001 - mae: 1.085 - mean_q: 1.463 - mean_eps: 0.384 - ale.lives: 3.290\n",
      "\n",
      "Interval 1371 (685000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.085 - mean_q: 1.463 - mean_eps: 0.383 - ale.lives: 2.590\n",
      "\n",
      "Interval 1372 (685500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "Interval 1373 (686000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 8.000 [5.000, 11.000] - loss: 0.001 - mae: 1.089 - mean_q: 1.468 - mean_eps: 0.382 - ale.lives: 3.690\n",
      "\n",
      "Interval 1374 (686500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.089 - mean_q: 1.467 - mean_eps: 0.382 - ale.lives: 3.240\n",
      "\n",
      "Interval 1375 (687000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.500 [4.000, 7.000] - loss: 0.002 - mae: 1.086 - mean_q: 1.463 - mean_eps: 0.381 - ale.lives: 3.200\n",
      "\n",
      "Interval 1376 (687500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.087 - mean_q: 1.464 - mean_eps: 0.381 - ale.lives: 3.024\n",
      "\n",
      "Interval 1377 (688000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.089 - mean_q: 1.466 - mean_eps: 0.381 - ale.lives: 2.542\n",
      "\n",
      "Interval 1378 (688500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.086 - mean_q: 1.465 - mean_eps: 0.380 - ale.lives: 2.908\n",
      "\n",
      "Interval 1379 (689000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.087 - mean_q: 1.461 - mean_eps: 0.380 - ale.lives: 2.680\n",
      "\n",
      "Interval 1380 (689500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.001 - mae: 1.092 - mean_q: 1.471 - mean_eps: 0.379 - ale.lives: 3.394\n",
      "\n",
      "Interval 1381 (690000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.089 - mean_q: 1.466 - mean_eps: 0.379 - ale.lives: 3.292\n",
      "\n",
      "Interval 1382 (690500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.098 - mean_q: 1.480 - mean_eps: 0.378 - ale.lives: 3.380\n",
      "\n",
      "Interval 1383 (691000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.094 - mean_q: 1.474 - mean_eps: 0.378 - ale.lives: 3.136\n",
      "\n",
      "Interval 1384 (691500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 6.500 [5.000, 8.000] - loss: 0.002 - mae: 1.093 - mean_q: 1.473 - mean_eps: 0.377 - ale.lives: 2.712\n",
      "\n",
      "Interval 1385 (692000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.090 - mean_q: 1.472 - mean_eps: 0.377 - ale.lives: 3.648\n",
      "\n",
      "Interval 1386 (692500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.106 - mean_q: 1.491 - mean_eps: 0.377 - ale.lives: 3.886\n",
      "\n",
      "Interval 1387 (693000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.099 - mean_q: 1.482 - mean_eps: 0.376 - ale.lives: 2.710\n",
      "\n",
      "Interval 1388 (693500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.100 - mean_q: 1.482 - mean_eps: 0.376 - ale.lives: 2.994\n",
      "\n",
      "Interval 1389 (694000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.086 - mean_q: 1.464 - mean_eps: 0.375 - ale.lives: 3.128\n",
      "\n",
      "Interval 1390 (694500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 5.500 [3.000, 8.000] - loss: 0.001 - mae: 1.095 - mean_q: 1.477 - mean_eps: 0.375 - ale.lives: 2.634\n",
      "\n",
      "Interval 1391 (695000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "Interval 1392 (695500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 8.000 [4.000, 12.000] - loss: 0.002 - mae: 1.095 - mean_q: 1.476 - mean_eps: 0.374 - ale.lives: 2.780\n",
      "\n",
      "Interval 1393 (696000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.096 - mean_q: 1.477 - mean_eps: 0.373 - ale.lives: 2.406\n",
      "\n",
      "Interval 1394 (696500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1395 (697000 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 9.500 [7.000, 12.000] - loss: 0.002 - mae: 1.095 - mean_q: 1.476 - mean_eps: 0.372 - ale.lives: 3.308\n",
      "\n",
      "Interval 1396 (697500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.095 - mean_q: 1.475 - mean_eps: 0.372 - ale.lives: 3.058\n",
      "\n",
      "Interval 1397 (698000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.093 - mean_q: 1.471 - mean_eps: 0.372 - ale.lives: 2.610\n",
      "\n",
      "Interval 1398 (698500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.001 - mae: 1.096 - mean_q: 1.476 - mean_eps: 0.371 - ale.lives: 3.076\n",
      "\n",
      "Interval 1399 (699000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.090 - mean_q: 1.471 - mean_eps: 0.371 - ale.lives: 3.322\n",
      "\n",
      "Interval 1400 (699500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.097 - mean_q: 1.478 - mean_eps: 0.370 - ale.lives: 3.222\n",
      "\n",
      "Interval 1401 (700000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 1.106 - mean_q: 1.488 - mean_eps: 0.370 - ale.lives: 2.734\n",
      "\n",
      "Interval 1402 (700500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.104 - mean_q: 1.489 - mean_eps: 0.369 - ale.lives: 3.662\n",
      "\n",
      "Interval 1403 (701000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.095 - mean_q: 1.477 - mean_eps: 0.369 - ale.lives: 3.400\n",
      "\n",
      "Interval 1404 (701500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.109 - mean_q: 1.495 - mean_eps: 0.368 - ale.lives: 2.638\n",
      "\n",
      "Interval 1405 (702000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.105 - mean_q: 1.490 - mean_eps: 0.368 - ale.lives: 2.846\n",
      "\n",
      "Interval 1406 (702500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.097 - mean_q: 1.479 - mean_eps: 0.368 - ale.lives: 3.290\n",
      "\n",
      "Interval 1407 (703000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.097 - mean_q: 1.481 - mean_eps: 0.367 - ale.lives: 2.648\n",
      "\n",
      "Interval 1408 (703500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.098 - mean_q: 1.481 - mean_eps: 0.367 - ale.lives: 3.316\n",
      "\n",
      "Interval 1409 (704000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0220\n",
      "Interval 1410 (704500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.100 - mean_q: 1.483 - mean_eps: 0.366 - ale.lives: 3.346\n",
      "\n",
      "Interval 1411 (705000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 8.000 [6.000, 10.000] - loss: 0.002 - mae: 1.104 - mean_q: 1.488 - mean_eps: 0.365 - ale.lives: 2.606\n",
      "\n",
      "Interval 1412 (705500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.095 - mean_q: 1.479 - mean_eps: 0.365 - ale.lives: 2.834\n",
      "\n",
      "Interval 1413 (706000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.096 - mean_q: 1.478 - mean_eps: 0.364 - ale.lives: 3.072\n",
      "\n",
      "Interval 1414 (706500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.104 - mean_q: 1.490 - mean_eps: 0.364 - ale.lives: 2.852\n",
      "\n",
      "Interval 1415 (707000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.095 - mean_q: 1.477 - mean_eps: 0.363 - ale.lives: 3.312\n",
      "\n",
      "Interval 1416 (707500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "Interval 1417 (708000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 11.000 [8.000, 14.000] - loss: 0.002 - mae: 1.101 - mean_q: 1.485 - mean_eps: 0.363 - ale.lives: 3.548\n",
      "\n",
      "Interval 1418 (708500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.104 - mean_q: 1.490 - mean_eps: 0.362 - ale.lives: 3.976\n",
      "\n",
      "Interval 1419 (709000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.109 - mean_q: 1.497 - mean_eps: 0.362 - ale.lives: 3.288\n",
      "\n",
      "Interval 1420 (709500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.112 - mean_q: 1.498 - mean_eps: 0.361 - ale.lives: 3.262\n",
      "\n",
      "Interval 1421 (710000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0140\n",
      "2 episodes - episode_reward: 5.500 [3.000, 8.000] - loss: 0.002 - mae: 1.110 - mean_q: 1.497 - mean_eps: 0.361 - ale.lives: 2.610\n",
      "\n",
      "Interval 1422 (710500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.111 - mean_q: 1.498 - mean_eps: 0.360 - ale.lives: 3.566\n",
      "\n",
      "Interval 1423 (711000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.114 - mean_q: 1.503 - mean_eps: 0.360 - ale.lives: 2.930\n",
      "\n",
      "Interval 1424 (711500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 5.500 [4.000, 7.000] - loss: 0.002 - mae: 1.107 - mean_q: 1.493 - mean_eps: 0.359 - ale.lives: 3.282\n",
      "\n",
      "Interval 1425 (712000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.109 - mean_q: 1.497 - mean_eps: 0.359 - ale.lives: 3.078\n",
      "\n",
      "Interval 1426 (712500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.111 - mean_q: 1.500 - mean_eps: 0.359 - ale.lives: 2.504\n",
      "\n",
      "Interval 1427 (713000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.113 - mean_q: 1.502 - mean_eps: 0.358 - ale.lives: 3.102\n",
      "\n",
      "Interval 1428 (713500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.108 - mean_q: 1.497 - mean_eps: 0.358 - ale.lives: 2.942\n",
      "\n",
      "Interval 1429 (714000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 7.000 [6.000, 8.000] - loss: 0.002 - mae: 1.111 - mean_q: 1.501 - mean_eps: 0.357 - ale.lives: 3.332\n",
      "\n",
      "Interval 1430 (714500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.115 - mean_q: 1.506 - mean_eps: 0.357 - ale.lives: 3.860\n",
      "\n",
      "Interval 1431 (715000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.111 - mean_q: 1.500 - mean_eps: 0.356 - ale.lives: 2.976\n",
      "\n",
      "Interval 1432 (715500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.106 - mean_q: 1.493 - mean_eps: 0.356 - ale.lives: 3.572\n",
      "\n",
      "Interval 1433 (716000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.108 - mean_q: 1.495 - mean_eps: 0.355 - ale.lives: 3.318\n",
      "\n",
      "Interval 1434 (716500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.109 - mean_q: 1.499 - mean_eps: 0.355 - ale.lives: 2.366\n",
      "\n",
      "Interval 1435 (717000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.114 - mean_q: 1.507 - mean_eps: 0.354 - ale.lives: 2.288\n",
      "\n",
      "Interval 1436 (717500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.108 - mean_q: 1.498 - mean_eps: 0.354 - ale.lives: 2.810\n",
      "\n",
      "Interval 1437 (718000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.110 - mean_q: 1.500 - mean_eps: 0.354 - ale.lives: 3.430\n",
      "\n",
      "Interval 1438 (718500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1439 (719000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 10.000 [7.000, 13.000] - loss: 0.002 - mae: 1.117 - mean_q: 1.507 - mean_eps: 0.353 - ale.lives: 2.798\n",
      "\n",
      "Interval 1440 (719500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.104 - mean_q: 1.491 - mean_eps: 0.352 - ale.lives: 3.058\n",
      "\n",
      "Interval 1441 (720000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.136 - mean_q: 1.530 - mean_eps: 0.352 - ale.lives: 2.942\n",
      "\n",
      "Interval 1442 (720500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.132 - mean_q: 1.528 - mean_eps: 0.351 - ale.lives: 2.588\n",
      "\n",
      "Interval 1443 (721000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.134 - mean_q: 1.531 - mean_eps: 0.351 - ale.lives: 3.546\n",
      "\n",
      "Interval 1444 (721500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.126 - mean_q: 1.521 - mean_eps: 0.350 - ale.lives: 2.830\n",
      "\n",
      "Interval 1445 (722000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.129 - mean_q: 1.524 - mean_eps: 0.350 - ale.lives: 3.946\n",
      "\n",
      "Interval 1446 (722500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1447 (723000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.131 - mean_q: 1.524 - mean_eps: 0.349 - ale.lives: 1.934\n",
      "\n",
      "Interval 1448 (723500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.139 - mean_q: 1.536 - mean_eps: 0.349 - ale.lives: 3.754\n",
      "\n",
      "Interval 1449 (724000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 9.500 [6.000, 13.000] - loss: 0.002 - mae: 1.134 - mean_q: 1.529 - mean_eps: 0.348 - ale.lives: 3.136\n",
      "\n",
      "Interval 1450 (724500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.131 - mean_q: 1.526 - mean_eps: 0.348 - ale.lives: 3.738\n",
      "\n",
      "Interval 1451 (725000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.123 - mean_q: 1.518 - mean_eps: 0.347 - ale.lives: 2.406\n",
      "\n",
      "Interval 1452 (725500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.124 - mean_q: 1.518 - mean_eps: 0.347 - ale.lives: 2.158\n",
      "\n",
      "Interval 1453 (726000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.001 - mae: 1.125 - mean_q: 1.522 - mean_eps: 0.346 - ale.lives: 3.448\n",
      "\n",
      "Interval 1454 (726500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 8.500 [6.000, 11.000] - loss: 0.001 - mae: 1.132 - mean_q: 1.530 - mean_eps: 0.346 - ale.lives: 3.298\n",
      "\n",
      "Interval 1455 (727000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.136 - mean_q: 1.534 - mean_eps: 0.345 - ale.lives: 2.860\n",
      "\n",
      "Interval 1456 (727500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.127 - mean_q: 1.522 - mean_eps: 0.345 - ale.lives: 3.314\n",
      "\n",
      "Interval 1457 (728000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.133 - mean_q: 1.527 - mean_eps: 0.345 - ale.lives: 2.792\n",
      "\n",
      "Interval 1458 (728500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 6.500 [6.000, 7.000] - loss: 0.002 - mae: 1.137 - mean_q: 1.536 - mean_eps: 0.344 - ale.lives: 3.144\n",
      "\n",
      "Interval 1459 (729000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.131 - mean_q: 1.526 - mean_eps: 0.344 - ale.lives: 3.670\n",
      "\n",
      "Interval 1460 (729500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.137 - mean_q: 1.536 - mean_eps: 0.343 - ale.lives: 3.650\n",
      "\n",
      "Interval 1461 (730000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.130 - mean_q: 1.525 - mean_eps: 0.343 - ale.lives: 3.464\n",
      "\n",
      "Interval 1462 (730500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.134 - mean_q: 1.533 - mean_eps: 0.342 - ale.lives: 3.458\n",
      "\n",
      "Interval 1463 (731000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.142 - mean_q: 1.545 - mean_eps: 0.342 - ale.lives: 2.794\n",
      "\n",
      "Interval 1464 (731500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.140 - mean_q: 1.542 - mean_eps: 0.341 - ale.lives: 2.926\n",
      "\n",
      "Interval 1465 (732000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.132 - mean_q: 1.532 - mean_eps: 0.341 - ale.lives: 3.632\n",
      "\n",
      "Interval 1466 (732500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.143 - mean_q: 1.546 - mean_eps: 0.341 - ale.lives: 3.530\n",
      "\n",
      "Interval 1467 (733000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.136 - mean_q: 1.537 - mean_eps: 0.340 - ale.lives: 2.814\n",
      "\n",
      "Interval 1468 (733500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 7.000 [6.000, 8.000] - loss: 0.002 - mae: 1.131 - mean_q: 1.530 - mean_eps: 0.340 - ale.lives: 3.356\n",
      "\n",
      "Interval 1469 (734000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.134 - mean_q: 1.534 - mean_eps: 0.339 - ale.lives: 2.930\n",
      "\n",
      "Interval 1470 (734500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 4.000 [4.000, 4.000] - loss: 0.002 - mae: 1.133 - mean_q: 1.534 - mean_eps: 0.339 - ale.lives: 3.516\n",
      "\n",
      "Interval 1471 (735000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.136 - mean_q: 1.539 - mean_eps: 0.338 - ale.lives: 2.902\n",
      "\n",
      "Interval 1472 (735500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.136 - mean_q: 1.539 - mean_eps: 0.338 - ale.lives: 2.976\n",
      "\n",
      "Interval 1473 (736000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.135 - mean_q: 1.539 - mean_eps: 0.337 - ale.lives: 2.938\n",
      "\n",
      "Interval 1474 (736500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.141 - mean_q: 1.542 - mean_eps: 0.337 - ale.lives: 2.852\n",
      "\n",
      "Interval 1475 (737000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.140 - mean_q: 1.543 - mean_eps: 0.336 - ale.lives: 2.514\n",
      "\n",
      "Interval 1476 (737500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.136 - mean_q: 1.538 - mean_eps: 0.336 - ale.lives: 3.324\n",
      "\n",
      "Interval 1477 (738000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.142 - mean_q: 1.543 - mean_eps: 0.336 - ale.lives: 2.660\n",
      "\n",
      "Interval 1478 (738500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.137 - mean_q: 1.539 - mean_eps: 0.335 - ale.lives: 2.950\n",
      "\n",
      "Interval 1479 (739000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.001 - mae: 1.142 - mean_q: 1.547 - mean_eps: 0.335 - ale.lives: 3.276\n",
      "\n",
      "Interval 1480 (739500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.134 - mean_q: 1.535 - mean_eps: 0.334 - ale.lives: 2.468\n",
      "\n",
      "Interval 1481 (740000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.156 - mean_q: 1.562 - mean_eps: 0.334 - ale.lives: 3.764\n",
      "\n",
      "Interval 1482 (740500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.146 - mean_q: 1.551 - mean_eps: 0.333 - ale.lives: 3.748\n",
      "\n",
      "Interval 1483 (741000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.150 - mean_q: 1.555 - mean_eps: 0.333 - ale.lives: 2.566\n",
      "\n",
      "Interval 1484 (741500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.154 - mean_q: 1.559 - mean_eps: 0.332 - ale.lives: 3.254\n",
      "\n",
      "Interval 1485 (742000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1486 (742500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.146 - mean_q: 1.549 - mean_eps: 0.332 - ale.lives: 3.354\n",
      "\n",
      "Interval 1487 (743000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 10.000 [8.000, 12.000] - loss: 0.002 - mae: 1.153 - mean_q: 1.558 - mean_eps: 0.331 - ale.lives: 2.782\n",
      "\n",
      "Interval 1488 (743500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.154 - mean_q: 1.560 - mean_eps: 0.331 - ale.lives: 2.804\n",
      "\n",
      "Interval 1489 (744000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.154 - mean_q: 1.560 - mean_eps: 0.330 - ale.lives: 3.308\n",
      "\n",
      "Interval 1490 (744500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "Interval 1491 (745000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.154 - mean_q: 1.561 - mean_eps: 0.329 - ale.lives: 3.070\n",
      "\n",
      "Interval 1492 (745500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.148 - mean_q: 1.553 - mean_eps: 0.329 - ale.lives: 2.758\n",
      "\n",
      "Interval 1493 (746000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.153 - mean_q: 1.562 - mean_eps: 0.328 - ale.lives: 3.154\n",
      "\n",
      "Interval 1494 (746500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.150 - mean_q: 1.556 - mean_eps: 0.328 - ale.lives: 2.960\n",
      "\n",
      "Interval 1495 (747000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.151 - mean_q: 1.558 - mean_eps: 0.327 - ale.lives: 3.266\n",
      "\n",
      "Interval 1496 (747500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "Interval 1497 (748000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 11.500 [8.000, 15.000] - loss: 0.002 - mae: 1.145 - mean_q: 1.550 - mean_eps: 0.327 - ale.lives: 3.194\n",
      "\n",
      "Interval 1498 (748500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.151 - mean_q: 1.556 - mean_eps: 0.326 - ale.lives: 3.948\n",
      "\n",
      "Interval 1499 (749000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.159 - mean_q: 1.567 - mean_eps: 0.326 - ale.lives: 2.664\n",
      "\n",
      "Interval 1500 (749500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.150 - mean_q: 1.555 - mean_eps: 0.325 - ale.lives: 3.302\n",
      "\n",
      "Interval 1501 (750000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1502 (750500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.168 - mean_q: 1.578 - mean_eps: 0.324 - ale.lives: 3.140\n",
      "\n",
      "Interval 1503 (751000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.162 - mean_q: 1.570 - mean_eps: 0.324 - ale.lives: 3.448\n",
      "\n",
      "Interval 1504 (751500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.165 - mean_q: 1.576 - mean_eps: 0.323 - ale.lives: 3.782\n",
      "\n",
      "Interval 1505 (752000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.157 - mean_q: 1.566 - mean_eps: 0.323 - ale.lives: 2.972\n",
      "\n",
      "Interval 1506 (752500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.165 - mean_q: 1.575 - mean_eps: 0.323 - ale.lives: 3.360\n",
      "\n",
      "Interval 1507 (753000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.160 - mean_q: 1.571 - mean_eps: 0.322 - ale.lives: 2.968\n",
      "\n",
      "Interval 1508 (753500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.164 - mean_q: 1.573 - mean_eps: 0.322 - ale.lives: 2.706\n",
      "\n",
      "Interval 1509 (754000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.154 - mean_q: 1.561 - mean_eps: 0.321 - ale.lives: 3.656\n",
      "\n",
      "Interval 1510 (754500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 3.500 [2.000, 5.000] - loss: 0.002 - mae: 1.158 - mean_q: 1.566 - mean_eps: 0.321 - ale.lives: 3.450\n",
      "\n",
      "Interval 1511 (755000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.159 - mean_q: 1.565 - mean_eps: 0.320 - ale.lives: 3.220\n",
      "\n",
      "Interval 1512 (755500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.166 - mean_q: 1.577 - mean_eps: 0.320 - ale.lives: 2.822\n",
      "\n",
      "Interval 1513 (756000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.175 - mean_q: 1.589 - mean_eps: 0.319 - ale.lives: 3.420\n",
      "\n",
      "Interval 1514 (756500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.160 - mean_q: 1.567 - mean_eps: 0.319 - ale.lives: 3.172\n",
      "\n",
      "Interval 1515 (757000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.160 - mean_q: 1.570 - mean_eps: 0.318 - ale.lives: 2.956\n",
      "\n",
      "Interval 1516 (757500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 6.500 [4.000, 9.000] - loss: 0.002 - mae: 1.164 - mean_q: 1.573 - mean_eps: 0.318 - ale.lives: 2.774\n",
      "\n",
      "Interval 1517 (758000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.164 - mean_q: 1.574 - mean_eps: 0.318 - ale.lives: 3.044\n",
      "\n",
      "Interval 1518 (758500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.157 - mean_q: 1.562 - mean_eps: 0.317 - ale.lives: 3.636\n",
      "\n",
      "Interval 1519 (759000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.156 - mean_q: 1.563 - mean_eps: 0.317 - ale.lives: 2.836\n",
      "\n",
      "Interval 1520 (759500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.171 - mean_q: 1.581 - mean_eps: 0.316 - ale.lives: 2.818\n",
      "\n",
      "Interval 1521 (760000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1522 (760500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.177 - mean_q: 1.592 - mean_eps: 0.315 - ale.lives: 3.562\n",
      "\n",
      "Interval 1523 (761000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.186 - mean_q: 1.604 - mean_eps: 0.315 - ale.lives: 3.374\n",
      "\n",
      "Interval 1524 (761500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.180 - mean_q: 1.597 - mean_eps: 0.314 - ale.lives: 3.304\n",
      "\n",
      "Interval 1525 (762000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1526 (762500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.182 - mean_q: 1.598 - mean_eps: 0.314 - ale.lives: 3.592\n",
      "\n",
      "Interval 1527 (763000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.173 - mean_q: 1.585 - mean_eps: 0.313 - ale.lives: 3.220\n",
      "\n",
      "Interval 1528 (763500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.173 - mean_q: 1.586 - mean_eps: 0.313 - ale.lives: 2.930\n",
      "\n",
      "Interval 1529 (764000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 6.000 [4.000, 8.000] - loss: 0.002 - mae: 1.181 - mean_q: 1.599 - mean_eps: 0.312 - ale.lives: 3.094\n",
      "\n",
      "Interval 1530 (764500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.179 - mean_q: 1.592 - mean_eps: 0.312 - ale.lives: 3.212\n",
      "\n",
      "Interval 1531 (765000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.175 - mean_q: 1.586 - mean_eps: 0.311 - ale.lives: 3.240\n",
      "\n",
      "Interval 1532 (765500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "Interval 1533 (766000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.182 - mean_q: 1.598 - mean_eps: 0.310 - ale.lives: 3.506\n",
      "\n",
      "Interval 1534 (766500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.176 - mean_q: 1.592 - mean_eps: 0.310 - ale.lives: 2.922\n",
      "\n",
      "Interval 1535 (767000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "Interval 1536 (767500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.175 - mean_q: 1.589 - mean_eps: 0.309 - ale.lives: 3.540\n",
      "\n",
      "Interval 1537 (768000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.176 - mean_q: 1.592 - mean_eps: 0.309 - ale.lives: 3.384\n",
      "\n",
      "Interval 1538 (768500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.175 - mean_q: 1.589 - mean_eps: 0.308 - ale.lives: 3.154\n",
      "\n",
      "Interval 1539 (769000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.180 - mean_q: 1.596 - mean_eps: 0.308 - ale.lives: 2.876\n",
      "\n",
      "Interval 1540 (769500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.170 - mean_q: 1.583 - mean_eps: 0.307 - ale.lives: 3.174\n",
      "\n",
      "Interval 1541 (770000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "Interval 1542 (770500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.191 - mean_q: 1.609 - mean_eps: 0.306 - ale.lives: 2.872\n",
      "\n",
      "Interval 1543 (771000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.188 - mean_q: 1.606 - mean_eps: 0.306 - ale.lives: 3.514\n",
      "\n",
      "Interval 1544 (771500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 8.000 [4.000, 12.000] - loss: 0.002 - mae: 1.186 - mean_q: 1.604 - mean_eps: 0.305 - ale.lives: 3.272\n",
      "\n",
      "Interval 1545 (772000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.191 - mean_q: 1.610 - mean_eps: 0.305 - ale.lives: 3.132\n",
      "\n",
      "Interval 1546 (772500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.190 - mean_q: 1.611 - mean_eps: 0.305 - ale.lives: 3.970\n",
      "\n",
      "Interval 1547 (773000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "Interval 1548 (773500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.002 - mae: 1.189 - mean_q: 1.607 - mean_eps: 0.304 - ale.lives: 2.474\n",
      "\n",
      "Interval 1549 (774000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.188 - mean_q: 1.607 - mean_eps: 0.303 - ale.lives: 3.004\n",
      "\n",
      "Interval 1550 (774500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0160\n",
      "2 episodes - episode_reward: 9.000 [7.000, 11.000] - loss: 0.002 - mae: 1.190 - mean_q: 1.611 - mean_eps: 0.303 - ale.lives: 2.874\n",
      "\n",
      "Interval 1551 (775000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.189 - mean_q: 1.608 - mean_eps: 0.302 - ale.lives: 2.394\n",
      "\n",
      "Interval 1552 (775500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.182 - mean_q: 1.601 - mean_eps: 0.302 - ale.lives: 3.490\n",
      "\n",
      "Interval 1553 (776000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.190 - mean_q: 1.610 - mean_eps: 0.301 - ale.lives: 3.434\n",
      "\n",
      "Interval 1554 (776500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.193 - mean_q: 1.615 - mean_eps: 0.301 - ale.lives: 3.108\n",
      "\n",
      "Interval 1555 (777000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.188 - mean_q: 1.608 - mean_eps: 0.300 - ale.lives: 2.826\n",
      "\n",
      "Interval 1556 (777500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.193 - mean_q: 1.615 - mean_eps: 0.300 - ale.lives: 2.948\n",
      "\n",
      "Interval 1557 (778000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.178 - mean_q: 1.595 - mean_eps: 0.300 - ale.lives: 2.850\n",
      "\n",
      "Interval 1558 (778500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.185 - mean_q: 1.603 - mean_eps: 0.299 - ale.lives: 2.546\n",
      "\n",
      "Interval 1559 (779000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.188 - mean_q: 1.609 - mean_eps: 0.299 - ale.lives: 3.354\n",
      "\n",
      "Interval 1560 (779500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.190 - mean_q: 1.612 - mean_eps: 0.298 - ale.lives: 2.554\n",
      "\n",
      "Interval 1561 (780000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.193 - mean_q: 1.612 - mean_eps: 0.298 - ale.lives: 2.562\n",
      "\n",
      "Interval 1562 (780500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "Interval 1563 (781000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.196 - mean_q: 1.618 - mean_eps: 0.297 - ale.lives: 3.416\n",
      "\n",
      "Interval 1564 (781500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.189 - mean_q: 1.610 - mean_eps: 0.296 - ale.lives: 2.470\n",
      "\n",
      "Interval 1565 (782000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.197 - mean_q: 1.621 - mean_eps: 0.296 - ale.lives: 3.220\n",
      "\n",
      "Interval 1566 (782500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.191 - mean_q: 1.614 - mean_eps: 0.296 - ale.lives: 3.324\n",
      "\n",
      "Interval 1567 (783000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 10.000 [9.000, 11.000] - loss: 0.002 - mae: 1.194 - mean_q: 1.618 - mean_eps: 0.295 - ale.lives: 2.782\n",
      "\n",
      "Interval 1568 (783500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1569 (784000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 10.500 [10.000, 11.000] - loss: 0.002 - mae: 1.194 - mean_q: 1.618 - mean_eps: 0.294 - ale.lives: 3.480\n",
      "\n",
      "Interval 1570 (784500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "Interval 1571 (785000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.179 - mean_q: 1.595 - mean_eps: 0.293 - ale.lives: 2.808\n",
      "\n",
      "Interval 1572 (785500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 7.500 [7.000, 8.000] - loss: 0.002 - mae: 1.183 - mean_q: 1.603 - mean_eps: 0.293 - ale.lives: 3.658\n",
      "\n",
      "Interval 1573 (786000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.002 - mae: 1.190 - mean_q: 1.615 - mean_eps: 0.292 - ale.lives: 3.746\n",
      "\n",
      "Interval 1574 (786500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.191 - mean_q: 1.614 - mean_eps: 0.292 - ale.lives: 3.092\n",
      "\n",
      "Interval 1575 (787000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.186 - mean_q: 1.606 - mean_eps: 0.291 - ale.lives: 3.094\n",
      "\n",
      "Interval 1576 (787500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.194 - mean_q: 1.620 - mean_eps: 0.291 - ale.lives: 1.866\n",
      "\n",
      "Interval 1577 (788000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 5.000 [5.000, 5.000] - loss: 0.002 - mae: 1.188 - mean_q: 1.611 - mean_eps: 0.291 - ale.lives: 3.188\n",
      "\n",
      "Interval 1578 (788500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.002 - mae: 1.192 - mean_q: 1.615 - mean_eps: 0.290 - ale.lives: 3.534\n",
      "\n",
      "Interval 1579 (789000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.186 - mean_q: 1.608 - mean_eps: 0.290 - ale.lives: 2.530\n",
      "\n",
      "Interval 1580 (789500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.185 - mean_q: 1.605 - mean_eps: 0.289 - ale.lives: 3.266\n",
      "\n",
      "Interval 1581 (790000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.210 - mean_q: 1.640 - mean_eps: 0.289 - ale.lives: 3.560\n",
      "\n",
      "Interval 1582 (790500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.218 - mean_q: 1.653 - mean_eps: 0.288 - ale.lives: 2.494\n",
      "\n",
      "Interval 1583 (791000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1584 (791500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.003 - mae: 1.217 - mean_q: 1.653 - mean_eps: 0.287 - ale.lives: 2.994\n",
      "\n",
      "Interval 1585 (792000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 8.000 [6.000, 10.000] - loss: 0.002 - mae: 1.206 - mean_q: 1.637 - mean_eps: 0.287 - ale.lives: 3.284\n",
      "\n",
      "Interval 1586 (792500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 1.215 - mean_q: 1.648 - mean_eps: 0.287 - ale.lives: 3.710\n",
      "\n",
      "Interval 1587 (793000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.220 - mean_q: 1.657 - mean_eps: 0.286 - ale.lives: 2.946\n",
      "\n",
      "Interval 1588 (793500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.206 - mean_q: 1.639 - mean_eps: 0.286 - ale.lives: 3.024\n",
      "\n",
      "Interval 1589 (794000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.206 - mean_q: 1.640 - mean_eps: 0.285 - ale.lives: 3.322\n",
      "\n",
      "Interval 1590 (794500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 1.200 - mean_q: 1.633 - mean_eps: 0.285 - ale.lives: 3.252\n",
      "\n",
      "Interval 1591 (795000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.212 - mean_q: 1.650 - mean_eps: 0.284 - ale.lives: 3.504\n",
      "\n",
      "Interval 1592 (795500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.206 - mean_q: 1.643 - mean_eps: 0.284 - ale.lives: 3.044\n",
      "\n",
      "Interval 1593 (796000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.209 - mean_q: 1.645 - mean_eps: 0.283 - ale.lives: 2.728\n",
      "\n",
      "Interval 1594 (796500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "Interval 1595 (797000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.216 - mean_q: 1.652 - mean_eps: 0.282 - ale.lives: 2.484\n",
      "\n",
      "Interval 1596 (797500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 8.500 [7.000, 10.000] - loss: 0.002 - mae: 1.209 - mean_q: 1.643 - mean_eps: 0.282 - ale.lives: 2.738\n",
      "\n",
      "Interval 1597 (798000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "Interval 1598 (798500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "2 episodes - episode_reward: 10.000 [6.000, 14.000] - loss: 0.002 - mae: 1.208 - mean_q: 1.639 - mean_eps: 0.281 - ale.lives: 3.302\n",
      "\n",
      "Interval 1599 (799000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1600 (799500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 10.000 [6.000, 14.000] - loss: 0.002 - mae: 1.206 - mean_q: 1.640 - mean_eps: 0.280 - ale.lives: 3.434\n",
      "\n",
      "Interval 1601 (800000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.004 - mae: 1.235 - mean_q: 1.677 - mean_eps: 0.280 - ale.lives: 3.374\n",
      "\n",
      "Interval 1602 (800500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.242 - mean_q: 1.686 - mean_eps: 0.279 - ale.lives: 2.506\n",
      "\n",
      "Interval 1603 (801000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.003 - mae: 1.229 - mean_q: 1.672 - mean_eps: 0.279 - ale.lives: 3.146\n",
      "\n",
      "Interval 1604 (801500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.236 - mean_q: 1.678 - mean_eps: 0.278 - ale.lives: 2.782\n",
      "\n",
      "Interval 1605 (802000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "Interval 1606 (802500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0220\n",
      "2 episodes - episode_reward: 9.000 [5.000, 13.000] - loss: 0.003 - mae: 1.239 - mean_q: 1.682 - mean_eps: 0.278 - ale.lives: 3.822\n",
      "\n",
      "Interval 1607 (803000 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0220\n",
      "Interval 1608 (803500 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.004 - mae: 1.234 - mean_q: 1.674 - mean_eps: 0.277 - ale.lives: 3.382\n",
      "\n",
      "Interval 1609 (804000 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.229 - mean_q: 1.673 - mean_eps: 0.276 - ale.lives: 2.952\n",
      "\n",
      "Interval 1610 (804500 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.240 - mean_q: 1.687 - mean_eps: 0.276 - ale.lives: 3.524\n",
      "\n",
      "Interval 1611 (805000 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0240\n",
      "Interval 1612 (805500 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.225 - mean_q: 1.663 - mean_eps: 0.275 - ale.lives: 3.286\n",
      "\n",
      "Interval 1613 (806000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.003 - mae: 1.233 - mean_q: 1.677 - mean_eps: 0.274 - ale.lives: 3.690\n",
      "\n",
      "Interval 1614 (806500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.234 - mean_q: 1.676 - mean_eps: 0.274 - ale.lives: 2.982\n",
      "\n",
      "Interval 1615 (807000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.223 - mean_q: 1.664 - mean_eps: 0.273 - ale.lives: 2.184\n",
      "\n",
      "Interval 1616 (807500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.226 - mean_q: 1.668 - mean_eps: 0.273 - ale.lives: 3.560\n",
      "\n",
      "Interval 1617 (808000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.227 - mean_q: 1.670 - mean_eps: 0.273 - ale.lives: 3.964\n",
      "\n",
      "Interval 1618 (808500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.236 - mean_q: 1.682 - mean_eps: 0.272 - ale.lives: 2.294\n",
      "\n",
      "Interval 1619 (809000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.224 - mean_q: 1.668 - mean_eps: 0.272 - ale.lives: 2.858\n",
      "\n",
      "Interval 1620 (809500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "Interval 1621 (810000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.004 - mae: 1.261 - mean_q: 1.709 - mean_eps: 0.271 - ale.lives: 2.978\n",
      "\n",
      "Interval 1622 (810500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.253 - mean_q: 1.695 - mean_eps: 0.270 - ale.lives: 2.938\n",
      "\n",
      "Interval 1623 (811000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.004 - mae: 1.253 - mean_q: 1.696 - mean_eps: 0.270 - ale.lives: 2.880\n",
      "\n",
      "Interval 1624 (811500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 6.000 [6.000, 6.000] - loss: 0.003 - mae: 1.250 - mean_q: 1.694 - mean_eps: 0.269 - ale.lives: 2.808\n",
      "\n",
      "Interval 1625 (812000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.257 - mean_q: 1.703 - mean_eps: 0.269 - ale.lives: 3.620\n",
      "\n",
      "Interval 1626 (812500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.252 - mean_q: 1.696 - mean_eps: 0.269 - ale.lives: 2.414\n",
      "\n",
      "Interval 1627 (813000 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0240\n",
      "Interval 1628 (813500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.247 - mean_q: 1.689 - mean_eps: 0.268 - ale.lives: 3.574\n",
      "\n",
      "Interval 1629 (814000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.251 - mean_q: 1.695 - mean_eps: 0.267 - ale.lives: 3.862\n",
      "\n",
      "Interval 1630 (814500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.265 - mean_q: 1.713 - mean_eps: 0.267 - ale.lives: 2.818\n",
      "\n",
      "Interval 1631 (815000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "Interval 1632 (815500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.256 - mean_q: 1.704 - mean_eps: 0.266 - ale.lives: 2.422\n",
      "\n",
      "Interval 1633 (816000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.242 - mean_q: 1.686 - mean_eps: 0.265 - ale.lives: 3.022\n",
      "\n",
      "Interval 1634 (816500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.257 - mean_q: 1.701 - mean_eps: 0.265 - ale.lives: 2.902\n",
      "\n",
      "Interval 1635 (817000 steps performed)\n",
      "500/500 [==============================] - 27s 55ms/step - reward: 0.0240\n",
      "Interval 1636 (817500 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.251 - mean_q: 1.695 - mean_eps: 0.264 - ale.lives: 4.022\n",
      "\n",
      "Interval 1637 (818000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.257 - mean_q: 1.703 - mean_eps: 0.264 - ale.lives: 2.564\n",
      "\n",
      "Interval 1638 (818500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "Interval 1639 (819000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.260 - mean_q: 1.707 - mean_eps: 0.263 - ale.lives: 3.558\n",
      "\n",
      "Interval 1640 (819500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.250 - mean_q: 1.693 - mean_eps: 0.262 - ale.lives: 3.052\n",
      "\n",
      "Interval 1641 (820000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.273 - mean_q: 1.721 - mean_eps: 0.262 - ale.lives: 3.072\n",
      "\n",
      "Interval 1642 (820500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0220\n",
      "Interval 1643 (821000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.273 - mean_q: 1.723 - mean_eps: 0.261 - ale.lives: 3.858\n",
      "\n",
      "Interval 1644 (821500 steps performed)\n",
      "500/500 [==============================] - 28s 55ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.266 - mean_q: 1.713 - mean_eps: 0.260 - ale.lives: 3.052\n",
      "\n",
      "Interval 1645 (822000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "Interval 1646 (822500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0200\n",
      "2 episodes - episode_reward: 12.500 [9.000, 16.000] - loss: 0.002 - mae: 1.284 - mean_q: 1.736 - mean_eps: 0.260 - ale.lives: 3.728\n",
      "\n",
      "Interval 1647 (823000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1648 (823500 steps performed)\n",
      "500/500 [==============================] - 24s 48ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.263 - mean_q: 1.709 - mean_eps: 0.259 - ale.lives: 4.392\n",
      "\n",
      "Interval 1649 (824000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.270 - mean_q: 1.718 - mean_eps: 0.258 - ale.lives: 3.290\n",
      "\n",
      "Interval 1650 (824500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.266 - mean_q: 1.714 - mean_eps: 0.258 - ale.lives: 3.002\n",
      "\n",
      "Interval 1651 (825000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 7.000 [7.000, 7.000] - loss: 0.003 - mae: 1.274 - mean_q: 1.724 - mean_eps: 0.257 - ale.lives: 3.306\n",
      "\n",
      "Interval 1652 (825500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.280 - mean_q: 1.730 - mean_eps: 0.257 - ale.lives: 3.366\n",
      "\n",
      "Interval 1653 (826000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1654 (826500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.275 - mean_q: 1.728 - mean_eps: 0.256 - ale.lives: 2.976\n",
      "\n",
      "Interval 1655 (827000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "2 episodes - episode_reward: 9.000 [7.000, 11.000] - loss: 0.003 - mae: 1.275 - mean_q: 1.727 - mean_eps: 0.255 - ale.lives: 2.572\n",
      "\n",
      "Interval 1656 (827500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "Interval 1657 (828000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.268 - mean_q: 1.716 - mean_eps: 0.255 - ale.lives: 4.042\n",
      "\n",
      "Interval 1658 (828500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.279 - mean_q: 1.729 - mean_eps: 0.254 - ale.lives: 3.336\n",
      "\n",
      "Interval 1659 (829000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.268 - mean_q: 1.716 - mean_eps: 0.254 - ale.lives: 3.212\n",
      "\n",
      "Interval 1660 (829500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.270 - mean_q: 1.721 - mean_eps: 0.253 - ale.lives: 3.330\n",
      "\n",
      "Interval 1661 (830000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "Interval 1662 (830500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.003 - mae: 1.283 - mean_q: 1.738 - mean_eps: 0.252 - ale.lives: 3.250\n",
      "\n",
      "Interval 1663 (831000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.289 - mean_q: 1.747 - mean_eps: 0.252 - ale.lives: 3.048\n",
      "\n",
      "Interval 1664 (831500 steps performed)\n",
      "500/500 [==============================] - 24s 49ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.289 - mean_q: 1.747 - mean_eps: 0.251 - ale.lives: 2.716\n",
      "\n",
      "Interval 1665 (832000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1666 (832500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.289 - mean_q: 1.748 - mean_eps: 0.251 - ale.lives: 3.516\n",
      "\n",
      "Interval 1667 (833000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.292 - mean_q: 1.748 - mean_eps: 0.250 - ale.lives: 3.156\n",
      "\n",
      "Interval 1668 (833500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.277 - mean_q: 1.729 - mean_eps: 0.250 - ale.lives: 1.828\n",
      "\n",
      "Interval 1669 (834000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1670 (834500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.285 - mean_q: 1.741 - mean_eps: 0.249 - ale.lives: 3.894\n",
      "\n",
      "Interval 1671 (835000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0180\n",
      "Interval 1672 (835500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.002 - mae: 1.288 - mean_q: 1.743 - mean_eps: 0.248 - ale.lives: 3.532\n",
      "\n",
      "Interval 1673 (836000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.288 - mean_q: 1.741 - mean_eps: 0.247 - ale.lives: 2.246\n",
      "\n",
      "Interval 1674 (836500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0220\n",
      "Interval 1675 (837000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.274 - mean_q: 1.727 - mean_eps: 0.246 - ale.lives: 3.992\n",
      "\n",
      "Interval 1676 (837500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.003 - mae: 1.296 - mean_q: 1.756 - mean_eps: 0.246 - ale.lives: 3.060\n",
      "\n",
      "Interval 1677 (838000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1678 (838500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.290 - mean_q: 1.748 - mean_eps: 0.245 - ale.lives: 4.004\n",
      "\n",
      "Interval 1679 (839000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.298 - mean_q: 1.756 - mean_eps: 0.245 - ale.lives: 3.212\n",
      "\n",
      "Interval 1680 (839500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.285 - mean_q: 1.740 - mean_eps: 0.244 - ale.lives: 3.220\n",
      "\n",
      "Interval 1681 (840000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.003 - mae: 1.297 - mean_q: 1.757 - mean_eps: 0.244 - ale.lives: 2.564\n",
      "\n",
      "Interval 1682 (840500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "Interval 1683 (841000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.002 - mae: 1.303 - mean_q: 1.768 - mean_eps: 0.243 - ale.lives: 3.018\n",
      "\n",
      "Interval 1684 (841500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.302 - mean_q: 1.767 - mean_eps: 0.242 - ale.lives: 2.600\n",
      "\n",
      "Interval 1685 (842000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.300 - mean_q: 1.760 - mean_eps: 0.242 - ale.lives: 2.372\n",
      "\n",
      "Interval 1686 (842500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.299 - mean_q: 1.760 - mean_eps: 0.242 - ale.lives: 2.828\n",
      "\n",
      "Interval 1687 (843000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.304 - mean_q: 1.765 - mean_eps: 0.241 - ale.lives: 2.588\n",
      "\n",
      "Interval 1688 (843500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0300\n",
      "Interval 1689 (844000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.002 - mae: 1.294 - mean_q: 1.756 - mean_eps: 0.240 - ale.lives: 2.734\n",
      "\n",
      "Interval 1690 (844500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.301 - mean_q: 1.763 - mean_eps: 0.240 - ale.lives: 3.130\n",
      "\n",
      "Interval 1691 (845000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1692 (845500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.002 - mae: 1.303 - mean_q: 1.766 - mean_eps: 0.239 - ale.lives: 2.862\n",
      "\n",
      "Interval 1693 (846000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.304 - mean_q: 1.768 - mean_eps: 0.238 - ale.lives: 2.708\n",
      "\n",
      "Interval 1694 (846500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.295 - mean_q: 1.755 - mean_eps: 0.238 - ale.lives: 3.006\n",
      "\n",
      "Interval 1695 (847000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0160\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.302 - mean_q: 1.765 - mean_eps: 0.237 - ale.lives: 3.262\n",
      "\n",
      "Interval 1696 (847500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.003 - mae: 1.302 - mean_q: 1.765 - mean_eps: 0.237 - ale.lives: 2.930\n",
      "\n",
      "Interval 1697 (848000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.304 - mean_q: 1.768 - mean_eps: 0.237 - ale.lives: 3.200\n",
      "\n",
      "Interval 1698 (848500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.296 - mean_q: 1.758 - mean_eps: 0.236 - ale.lives: 2.546\n",
      "\n",
      "Interval 1699 (849000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.296 - mean_q: 1.759 - mean_eps: 0.236 - ale.lives: 3.420\n",
      "\n",
      "Interval 1700 (849500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0240\n",
      "Interval 1701 (850000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.314 - mean_q: 1.778 - mean_eps: 0.235 - ale.lives: 3.084\n",
      "\n",
      "Interval 1702 (850500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.312 - mean_q: 1.776 - mean_eps: 0.234 - ale.lives: 2.476\n",
      "\n",
      "Interval 1703 (851000 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0260\n",
      "Interval 1704 (851500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.002 - mae: 1.312 - mean_q: 1.780 - mean_eps: 0.233 - ale.lives: 2.908\n",
      "\n",
      "Interval 1705 (852000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1706 (852500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.311 - mean_q: 1.776 - mean_eps: 0.233 - ale.lives: 3.106\n",
      "\n",
      "Interval 1707 (853000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.315 - mean_q: 1.780 - mean_eps: 0.232 - ale.lives: 3.294\n",
      "\n",
      "Interval 1708 (853500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.310 - mean_q: 1.772 - mean_eps: 0.232 - ale.lives: 3.246\n",
      "\n",
      "Interval 1709 (854000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.296 - mean_q: 1.755 - mean_eps: 0.231 - ale.lives: 2.066\n",
      "\n",
      "Interval 1710 (854500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "Interval 1711 (855000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.309 - mean_q: 1.772 - mean_eps: 0.230 - ale.lives: 3.448\n",
      "\n",
      "Interval 1712 (855500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.313 - mean_q: 1.777 - mean_eps: 0.230 - ale.lives: 3.412\n",
      "\n",
      "Interval 1713 (856000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1714 (856500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.316 - mean_q: 1.782 - mean_eps: 0.229 - ale.lives: 2.724\n",
      "\n",
      "Interval 1715 (857000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.316 - mean_q: 1.781 - mean_eps: 0.228 - ale.lives: 3.772\n",
      "\n",
      "Interval 1716 (857500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0260\n",
      "Interval 1717 (858000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.002 - mae: 1.312 - mean_q: 1.778 - mean_eps: 0.228 - ale.lives: 3.698\n",
      "\n",
      "Interval 1718 (858500 steps performed)\n",
      "500/500 [==============================] - 25s 49ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.297 - mean_q: 1.760 - mean_eps: 0.227 - ale.lives: 3.122\n",
      "\n",
      "Interval 1719 (859000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.316 - mean_q: 1.780 - mean_eps: 0.227 - ale.lives: 3.292\n",
      "\n",
      "Interval 1720 (859500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1721 (860000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.003 - mae: 1.322 - mean_q: 1.789 - mean_eps: 0.226 - ale.lives: 3.164\n",
      "\n",
      "Interval 1722 (860500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.327 - mean_q: 1.795 - mean_eps: 0.225 - ale.lives: 3.216\n",
      "\n",
      "Interval 1723 (861000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "Interval 1724 (861500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.320 - mean_q: 1.789 - mean_eps: 0.224 - ale.lives: 2.836\n",
      "\n",
      "Interval 1725 (862000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.323 - mean_q: 1.793 - mean_eps: 0.224 - ale.lives: 2.610\n",
      "\n",
      "Interval 1726 (862500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.328 - mean_q: 1.796 - mean_eps: 0.224 - ale.lives: 3.300\n",
      "\n",
      "Interval 1727 (863000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "Interval 1728 (863500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.332 - mean_q: 1.804 - mean_eps: 0.223 - ale.lives: 3.626\n",
      "\n",
      "Interval 1729 (864000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.327 - mean_q: 1.795 - mean_eps: 0.222 - ale.lives: 3.328\n",
      "\n",
      "Interval 1730 (864500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.324 - mean_q: 1.793 - mean_eps: 0.222 - ale.lives: 2.852\n",
      "\n",
      "Interval 1731 (865000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.318 - mean_q: 1.784 - mean_eps: 0.221 - ale.lives: 3.036\n",
      "\n",
      "Interval 1732 (865500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.324 - mean_q: 1.794 - mean_eps: 0.221 - ale.lives: 3.282\n",
      "\n",
      "Interval 1733 (866000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "Interval 1734 (866500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.325 - mean_q: 1.795 - mean_eps: 0.220 - ale.lives: 2.228\n",
      "\n",
      "Interval 1735 (867000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.321 - mean_q: 1.787 - mean_eps: 0.219 - ale.lives: 2.262\n",
      "\n",
      "Interval 1736 (867500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1737 (868000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.321 - mean_q: 1.789 - mean_eps: 0.219 - ale.lives: 3.800\n",
      "\n",
      "Interval 1738 (868500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.327 - mean_q: 1.795 - mean_eps: 0.218 - ale.lives: 2.914\n",
      "\n",
      "Interval 1739 (869000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.327 - mean_q: 1.798 - mean_eps: 0.218 - ale.lives: 2.904\n",
      "\n",
      "Interval 1740 (869500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1741 (870000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.332 - mean_q: 1.806 - mean_eps: 0.217 - ale.lives: 2.902\n",
      "\n",
      "Interval 1742 (870500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.003 - mae: 1.334 - mean_q: 1.805 - mean_eps: 0.216 - ale.lives: 3.110\n",
      "\n",
      "Interval 1743 (871000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.330 - mean_q: 1.802 - mean_eps: 0.216 - ale.lives: 2.748\n",
      "\n",
      "Interval 1744 (871500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.340 - mean_q: 1.814 - mean_eps: 0.215 - ale.lives: 2.900\n",
      "\n",
      "Interval 1745 (872000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0260\n",
      "Interval 1746 (872500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.331 - mean_q: 1.804 - mean_eps: 0.215 - ale.lives: 3.562\n",
      "\n",
      "Interval 1747 (873000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.343 - mean_q: 1.822 - mean_eps: 0.214 - ale.lives: 2.308\n",
      "\n",
      "Interval 1748 (873500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.342 - mean_q: 1.820 - mean_eps: 0.214 - ale.lives: 2.820\n",
      "\n",
      "Interval 1749 (874000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1750 (874500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.338 - mean_q: 1.818 - mean_eps: 0.213 - ale.lives: 3.618\n",
      "\n",
      "Interval 1751 (875000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.342 - mean_q: 1.819 - mean_eps: 0.212 - ale.lives: 2.816\n",
      "\n",
      "Interval 1752 (875500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.332 - mean_q: 1.809 - mean_eps: 0.212 - ale.lives: 3.058\n",
      "\n",
      "Interval 1753 (876000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1754 (876500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.333 - mean_q: 1.809 - mean_eps: 0.211 - ale.lives: 3.220\n",
      "\n",
      "Interval 1755 (877000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.332 - mean_q: 1.805 - mean_eps: 0.210 - ale.lives: 2.830\n",
      "\n",
      "Interval 1756 (877500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.002 - mae: 1.332 - mean_q: 1.807 - mean_eps: 0.210 - ale.lives: 3.698\n",
      "\n",
      "Interval 1757 (878000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.330 - mean_q: 1.806 - mean_eps: 0.210 - ale.lives: 3.184\n",
      "\n",
      "Interval 1758 (878500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 9.000 [9.000, 9.000] - loss: 0.003 - mae: 1.329 - mean_q: 1.805 - mean_eps: 0.209 - ale.lives: 3.094\n",
      "\n",
      "Interval 1759 (879000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 8.000 [8.000, 8.000] - loss: 0.002 - mae: 1.328 - mean_q: 1.801 - mean_eps: 0.209 - ale.lives: 3.454\n",
      "\n",
      "Interval 1760 (879500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.337 - mean_q: 1.815 - mean_eps: 0.208 - ale.lives: 3.184\n",
      "\n",
      "Interval 1761 (880000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.004 - mae: 1.349 - mean_q: 1.826 - mean_eps: 0.208 - ale.lives: 3.026\n",
      "\n",
      "Interval 1762 (880500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.363 - mean_q: 1.847 - mean_eps: 0.207 - ale.lives: 3.744\n",
      "\n",
      "Interval 1763 (881000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.355 - mean_q: 1.832 - mean_eps: 0.207 - ale.lives: 2.166\n",
      "\n",
      "Interval 1764 (881500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "Interval 1765 (882000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.357 - mean_q: 1.835 - mean_eps: 0.206 - ale.lives: 3.414\n",
      "\n",
      "Interval 1766 (882500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.353 - mean_q: 1.831 - mean_eps: 0.206 - ale.lives: 3.036\n",
      "\n",
      "Interval 1767 (883000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0280\n",
      "Interval 1768 (883500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.348 - mean_q: 1.823 - mean_eps: 0.205 - ale.lives: 3.516\n",
      "\n",
      "Interval 1769 (884000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.345 - mean_q: 1.822 - mean_eps: 0.204 - ale.lives: 2.974\n",
      "\n",
      "Interval 1770 (884500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0200\n",
      "Interval 1771 (885000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.355 - mean_q: 1.835 - mean_eps: 0.203 - ale.lives: 3.986\n",
      "\n",
      "Interval 1772 (885500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.004 - mae: 1.352 - mean_q: 1.831 - mean_eps: 0.203 - ale.lives: 3.274\n",
      "\n",
      "Interval 1773 (886000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.346 - mean_q: 1.823 - mean_eps: 0.202 - ale.lives: 2.436\n",
      "\n",
      "Interval 1774 (886500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.360 - mean_q: 1.840 - mean_eps: 0.202 - ale.lives: 3.010\n",
      "\n",
      "Interval 1775 (887000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.347 - mean_q: 1.825 - mean_eps: 0.201 - ale.lives: 2.722\n",
      "\n",
      "Interval 1776 (887500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "Interval 1777 (888000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.354 - mean_q: 1.833 - mean_eps: 0.201 - ale.lives: 3.538\n",
      "\n",
      "Interval 1778 (888500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.355 - mean_q: 1.834 - mean_eps: 0.200 - ale.lives: 3.434\n",
      "\n",
      "Interval 1779 (889000 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1780 (889500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.002 - mae: 1.355 - mean_q: 1.835 - mean_eps: 0.199 - ale.lives: 3.256\n",
      "\n",
      "Interval 1781 (890000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.370 - mean_q: 1.850 - mean_eps: 0.199 - ale.lives: 2.884\n",
      "\n",
      "Interval 1782 (890500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.382 - mean_q: 1.866 - mean_eps: 0.198 - ale.lives: 2.910\n",
      "\n",
      "Interval 1783 (891000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.366 - mean_q: 1.846 - mean_eps: 0.198 - ale.lives: 3.192\n",
      "\n",
      "Interval 1784 (891500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1785 (892000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.375 - mean_q: 1.854 - mean_eps: 0.197 - ale.lives: 2.844\n",
      "\n",
      "Interval 1786 (892500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.367 - mean_q: 1.845 - mean_eps: 0.197 - ale.lives: 3.264\n",
      "\n",
      "Interval 1787 (893000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.371 - mean_q: 1.851 - mean_eps: 0.196 - ale.lives: 3.168\n",
      "\n",
      "Interval 1788 (893500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.368 - mean_q: 1.848 - mean_eps: 0.196 - ale.lives: 2.998\n",
      "\n",
      "Interval 1789 (894000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "Interval 1790 (894500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.376 - mean_q: 1.857 - mean_eps: 0.195 - ale.lives: 3.908\n",
      "\n",
      "Interval 1791 (895000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.003 - mae: 1.373 - mean_q: 1.853 - mean_eps: 0.194 - ale.lives: 2.966\n",
      "\n",
      "Interval 1792 (895500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1793 (896000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.371 - mean_q: 1.853 - mean_eps: 0.193 - ale.lives: 3.332\n",
      "\n",
      "Interval 1794 (896500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.366 - mean_q: 1.849 - mean_eps: 0.193 - ale.lives: 3.224\n",
      "\n",
      "Interval 1795 (897000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.371 - mean_q: 1.851 - mean_eps: 0.192 - ale.lives: 2.734\n",
      "\n",
      "Interval 1796 (897500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.370 - mean_q: 1.854 - mean_eps: 0.192 - ale.lives: 3.010\n",
      "\n",
      "Interval 1797 (898000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.373 - mean_q: 1.856 - mean_eps: 0.192 - ale.lives: 3.554\n",
      "\n",
      "Interval 1798 (898500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1799 (899000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.004 - mae: 1.371 - mean_q: 1.851 - mean_eps: 0.191 - ale.lives: 3.092\n",
      "\n",
      "Interval 1800 (899500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.365 - mean_q: 1.844 - mean_eps: 0.190 - ale.lives: 2.910\n",
      "\n",
      "Interval 1801 (900000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.378 - mean_q: 1.863 - mean_eps: 0.190 - ale.lives: 3.114\n",
      "\n",
      "Interval 1802 (900500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1803 (901000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.381 - mean_q: 1.863 - mean_eps: 0.189 - ale.lives: 2.632\n",
      "\n",
      "Interval 1804 (901500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.003 - mae: 1.389 - mean_q: 1.873 - mean_eps: 0.188 - ale.lives: 2.202\n",
      "\n",
      "Interval 1805 (902000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1806 (902500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.371 - mean_q: 1.852 - mean_eps: 0.188 - ale.lives: 3.320\n",
      "\n",
      "Interval 1807 (903000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.376 - mean_q: 1.857 - mean_eps: 0.187 - ale.lives: 2.774\n",
      "\n",
      "Interval 1808 (903500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.002 - mae: 1.386 - mean_q: 1.871 - mean_eps: 0.187 - ale.lives: 3.672\n",
      "\n",
      "Interval 1809 (904000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.382 - mean_q: 1.866 - mean_eps: 0.186 - ale.lives: 3.272\n",
      "\n",
      "Interval 1810 (904500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "Interval 1811 (905000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.004 - mae: 1.374 - mean_q: 1.854 - mean_eps: 0.185 - ale.lives: 3.000\n",
      "\n",
      "Interval 1812 (905500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.003 - mae: 1.381 - mean_q: 1.864 - mean_eps: 0.185 - ale.lives: 2.808\n",
      "\n",
      "Interval 1813 (906000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1814 (906500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.387 - mean_q: 1.871 - mean_eps: 0.184 - ale.lives: 3.472\n",
      "\n",
      "Interval 1815 (907000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.381 - mean_q: 1.864 - mean_eps: 0.183 - ale.lives: 3.060\n",
      "\n",
      "Interval 1816 (907500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1817 (908000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 0.002 - mae: 1.383 - mean_q: 1.868 - mean_eps: 0.183 - ale.lives: 2.840\n",
      "\n",
      "Interval 1818 (908500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.386 - mean_q: 1.872 - mean_eps: 0.182 - ale.lives: 2.678\n",
      "\n",
      "Interval 1819 (909000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "Interval 1820 (909500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.377 - mean_q: 1.860 - mean_eps: 0.181 - ale.lives: 3.822\n",
      "\n",
      "Interval 1821 (910000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.388 - mean_q: 1.871 - mean_eps: 0.181 - ale.lives: 3.394\n",
      "\n",
      "Interval 1822 (910500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0280\n",
      "Interval 1823 (911000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 0.003 - mae: 1.388 - mean_q: 1.871 - mean_eps: 0.180 - ale.lives: 3.364\n",
      "\n",
      "Interval 1824 (911500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.388 - mean_q: 1.874 - mean_eps: 0.179 - ale.lives: 3.278\n",
      "\n",
      "Interval 1825 (912000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.003 - mae: 1.382 - mean_q: 1.865 - mean_eps: 0.179 - ale.lives: 2.816\n",
      "\n",
      "Interval 1826 (912500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "Interval 1827 (913000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.380 - mean_q: 1.860 - mean_eps: 0.178 - ale.lives: 2.984\n",
      "\n",
      "Interval 1828 (913500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.003 - mae: 1.380 - mean_q: 1.864 - mean_eps: 0.178 - ale.lives: 3.456\n",
      "\n",
      "Interval 1829 (914000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "Interval 1830 (914500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.390 - mean_q: 1.875 - mean_eps: 0.177 - ale.lives: 3.428\n",
      "\n",
      "Interval 1831 (915000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.002 - mae: 1.385 - mean_q: 1.868 - mean_eps: 0.176 - ale.lives: 3.020\n",
      "\n",
      "Interval 1832 (915500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.401 - mean_q: 1.888 - mean_eps: 0.176 - ale.lives: 3.374\n",
      "\n",
      "Interval 1833 (916000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.390 - mean_q: 1.874 - mean_eps: 0.175 - ale.lives: 2.848\n",
      "\n",
      "Interval 1834 (916500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1835 (917000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.393 - mean_q: 1.880 - mean_eps: 0.174 - ale.lives: 2.496\n",
      "\n",
      "Interval 1836 (917500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1837 (918000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.002 - mae: 1.385 - mean_q: 1.869 - mean_eps: 0.174 - ale.lives: 2.514\n",
      "\n",
      "Interval 1838 (918500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.386 - mean_q: 1.870 - mean_eps: 0.173 - ale.lives: 3.132\n",
      "\n",
      "Interval 1839 (919000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "Interval 1840 (919500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.003 - mae: 1.397 - mean_q: 1.882 - mean_eps: 0.172 - ale.lives: 3.100\n",
      "\n",
      "Interval 1841 (920000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.389 - mean_q: 1.872 - mean_eps: 0.172 - ale.lives: 4.328\n",
      "\n",
      "Interval 1842 (920500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.003 - mae: 1.388 - mean_q: 1.877 - mean_eps: 0.171 - ale.lives: 3.380\n",
      "\n",
      "Interval 1843 (921000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1844 (921500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.383 - mean_q: 1.866 - mean_eps: 0.170 - ale.lives: 3.016\n",
      "\n",
      "Interval 1845 (922000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.395 - mean_q: 1.881 - mean_eps: 0.170 - ale.lives: 1.562\n",
      "\n",
      "Interval 1846 (922500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1847 (923000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.382 - mean_q: 1.864 - mean_eps: 0.169 - ale.lives: 2.810\n",
      "\n",
      "Interval 1848 (923500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1849 (924000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.387 - mean_q: 1.871 - mean_eps: 0.168 - ale.lives: 3.152\n",
      "\n",
      "Interval 1850 (924500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.393 - mean_q: 1.879 - mean_eps: 0.168 - ale.lives: 3.126\n",
      "\n",
      "Interval 1851 (925000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1852 (925500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.396 - mean_q: 1.883 - mean_eps: 0.167 - ale.lives: 4.044\n",
      "\n",
      "Interval 1853 (926000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1854 (926500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 29.000 [29.000, 29.000] - loss: 0.002 - mae: 1.396 - mean_q: 1.884 - mean_eps: 0.166 - ale.lives: 3.374\n",
      "\n",
      "Interval 1855 (927000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1856 (927500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.389 - mean_q: 1.875 - mean_eps: 0.165 - ale.lives: 3.390\n",
      "\n",
      "Interval 1857 (928000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.392 - mean_q: 1.881 - mean_eps: 0.165 - ale.lives: 3.584\n",
      "\n",
      "Interval 1858 (928500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.398 - mean_q: 1.886 - mean_eps: 0.164 - ale.lives: 2.390\n",
      "\n",
      "Interval 1859 (929000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "Interval 1860 (929500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.389 - mean_q: 1.873 - mean_eps: 0.163 - ale.lives: 3.876\n",
      "\n",
      "Interval 1861 (930000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.003 - mae: 1.403 - mean_q: 1.892 - mean_eps: 0.163 - ale.lives: 2.770\n",
      "\n",
      "Interval 1862 (930500 steps performed)\n",
      "500/500 [==============================] - 25s 50ms/step - reward: 0.0240\n",
      "Interval 1863 (931000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.409 - mean_q: 1.898 - mean_eps: 0.162 - ale.lives: 3.306\n",
      "\n",
      "Interval 1864 (931500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1865 (932000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.407 - mean_q: 1.895 - mean_eps: 0.161 - ale.lives: 3.914\n",
      "\n",
      "Interval 1866 (932500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.401 - mean_q: 1.890 - mean_eps: 0.161 - ale.lives: 2.818\n",
      "\n",
      "Interval 1867 (933000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.002 - mae: 1.410 - mean_q: 1.898 - mean_eps: 0.160 - ale.lives: 3.164\n",
      "\n",
      "Interval 1868 (933500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.404 - mean_q: 1.892 - mean_eps: 0.160 - ale.lives: 3.204\n",
      "\n",
      "Interval 1869 (934000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1870 (934500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1871 (935000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "2 episodes - episode_reward: 18.500 [11.000, 26.000] - loss: 0.002 - mae: 1.402 - mean_q: 1.890 - mean_eps: 0.158 - ale.lives: 3.458\n",
      "\n",
      "Interval 1872 (935500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1873 (936000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.002 - mae: 1.406 - mean_q: 1.897 - mean_eps: 0.157 - ale.lives: 2.666\n",
      "\n",
      "Interval 1874 (936500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1875 (937000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.404 - mean_q: 1.893 - mean_eps: 0.156 - ale.lives: 3.060\n",
      "\n",
      "Interval 1876 (937500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.404 - mean_q: 1.892 - mean_eps: 0.156 - ale.lives: 3.156\n",
      "\n",
      "Interval 1877 (938000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.396 - mean_q: 1.884 - mean_eps: 0.156 - ale.lives: 2.736\n",
      "\n",
      "Interval 1878 (938500 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "Interval 1879 (939000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.402 - mean_q: 1.888 - mean_eps: 0.155 - ale.lives: 4.384\n",
      "\n",
      "Interval 1880 (939500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.004 - mae: 1.404 - mean_q: 1.892 - mean_eps: 0.154 - ale.lives: 3.058\n",
      "\n",
      "Interval 1881 (940000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.408 - mean_q: 1.897 - mean_eps: 0.154 - ale.lives: 2.954\n",
      "\n",
      "Interval 1882 (940500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1883 (941000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.409 - mean_q: 1.897 - mean_eps: 0.153 - ale.lives: 3.832\n",
      "\n",
      "Interval 1884 (941500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0180\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.417 - mean_q: 1.911 - mean_eps: 0.152 - ale.lives: 2.742\n",
      "\n",
      "Interval 1885 (942000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1886 (942500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.416 - mean_q: 1.911 - mean_eps: 0.152 - ale.lives: 2.920\n",
      "\n",
      "Interval 1887 (943000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.405 - mean_q: 1.893 - mean_eps: 0.151 - ale.lives: 3.370\n",
      "\n",
      "Interval 1888 (943500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.400 - mean_q: 1.888 - mean_eps: 0.151 - ale.lives: 2.822\n",
      "\n",
      "Interval 1889 (944000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1890 (944500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.002 - mae: 1.415 - mean_q: 1.909 - mean_eps: 0.150 - ale.lives: 2.016\n",
      "\n",
      "Interval 1891 (945000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1892 (945500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.405 - mean_q: 1.892 - mean_eps: 0.149 - ale.lives: 3.552\n",
      "\n",
      "Interval 1893 (946000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.400 - mean_q: 1.887 - mean_eps: 0.148 - ale.lives: 3.440\n",
      "\n",
      "Interval 1894 (946500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1895 (947000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.403 - mean_q: 1.891 - mean_eps: 0.147 - ale.lives: 4.444\n",
      "\n",
      "Interval 1896 (947500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1897 (948000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 0.002 - mae: 1.407 - mean_q: 1.895 - mean_eps: 0.147 - ale.lives: 3.942\n",
      "\n",
      "Interval 1898 (948500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.401 - mean_q: 1.888 - mean_eps: 0.146 - ale.lives: 2.650\n",
      "\n",
      "Interval 1899 (949000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0300\n",
      "Interval 1900 (949500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 0.003 - mae: 1.406 - mean_q: 1.895 - mean_eps: 0.145 - ale.lives: 2.704\n",
      "\n",
      "Interval 1901 (950000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1902 (950500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.416 - mean_q: 1.908 - mean_eps: 0.144 - ale.lives: 2.810\n",
      "\n",
      "Interval 1903 (951000 steps performed)\n",
      "500/500 [==============================] - 25s 51ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.410 - mean_q: 1.901 - mean_eps: 0.144 - ale.lives: 2.636\n",
      "\n",
      "Interval 1904 (951500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 10.000 [10.000, 10.000] - loss: 0.003 - mae: 1.409 - mean_q: 1.898 - mean_eps: 0.143 - ale.lives: 3.396\n",
      "\n",
      "Interval 1905 (952000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "Interval 1906 (952500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.411 - mean_q: 1.903 - mean_eps: 0.143 - ale.lives: 3.620\n",
      "\n",
      "Interval 1907 (953000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1908 (953500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.002 - mae: 1.425 - mean_q: 1.922 - mean_eps: 0.142 - ale.lives: 3.944\n",
      "\n",
      "Interval 1909 (954000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.413 - mean_q: 1.904 - mean_eps: 0.141 - ale.lives: 2.986\n",
      "\n",
      "Interval 1910 (954500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.414 - mean_q: 1.907 - mean_eps: 0.141 - ale.lives: 3.084\n",
      "\n",
      "Interval 1911 (955000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "Interval 1912 (955500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.003 - mae: 1.414 - mean_q: 1.904 - mean_eps: 0.140 - ale.lives: 3.368\n",
      "\n",
      "Interval 1913 (956000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.409 - mean_q: 1.902 - mean_eps: 0.139 - ale.lives: 2.864\n",
      "\n",
      "Interval 1914 (956500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1915 (957000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.418 - mean_q: 1.912 - mean_eps: 0.138 - ale.lives: 3.046\n",
      "\n",
      "Interval 1916 (957500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.416 - mean_q: 1.907 - mean_eps: 0.138 - ale.lives: 1.998\n",
      "\n",
      "Interval 1917 (958000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "Interval 1918 (958500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.421 - mean_q: 1.916 - mean_eps: 0.137 - ale.lives: 3.664\n",
      "\n",
      "Interval 1919 (959000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.002 - mae: 1.418 - mean_q: 1.912 - mean_eps: 0.137 - ale.lives: 2.628\n",
      "\n",
      "Interval 1920 (959500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0220\n",
      "Interval 1921 (960000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.426 - mean_q: 1.921 - mean_eps: 0.136 - ale.lives: 3.166\n",
      "\n",
      "Interval 1922 (960500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.420 - mean_q: 1.914 - mean_eps: 0.135 - ale.lives: 3.290\n",
      "\n",
      "Interval 1923 (961000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1924 (961500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.002 - mae: 1.424 - mean_q: 1.920 - mean_eps: 0.134 - ale.lives: 3.750\n",
      "\n",
      "Interval 1925 (962000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.002 - mae: 1.421 - mean_q: 1.915 - mean_eps: 0.134 - ale.lives: 3.476\n",
      "\n",
      "Interval 1926 (962500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 17.000 [17.000, 17.000] - loss: 0.003 - mae: 1.423 - mean_q: 1.918 - mean_eps: 0.134 - ale.lives: 2.706\n",
      "\n",
      "Interval 1927 (963000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0220\n",
      "Interval 1928 (963500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.427 - mean_q: 1.925 - mean_eps: 0.133 - ale.lives: 3.240\n",
      "\n",
      "Interval 1929 (964000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1930 (964500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 27.000 [27.000, 27.000] - loss: 0.002 - mae: 1.419 - mean_q: 1.913 - mean_eps: 0.132 - ale.lives: 2.942\n",
      "\n",
      "Interval 1931 (965000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "Interval 1932 (965500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.429 - mean_q: 1.927 - mean_eps: 0.131 - ale.lives: 4.010\n",
      "\n",
      "Interval 1933 (966000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1934 (966500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 28.000 [28.000, 28.000] - loss: 0.003 - mae: 1.429 - mean_q: 1.928 - mean_eps: 0.130 - ale.lives: 2.444\n",
      "\n",
      "Interval 1935 (967000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.432 - mean_q: 1.931 - mean_eps: 0.129 - ale.lives: 2.906\n",
      "\n",
      "Interval 1936 (967500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.428 - mean_q: 1.925 - mean_eps: 0.129 - ale.lives: 3.312\n",
      "\n",
      "Interval 1937 (968000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.424 - mean_q: 1.921 - mean_eps: 0.129 - ale.lives: 3.760\n",
      "\n",
      "Interval 1938 (968500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "Interval 1939 (969000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 30.000 [30.000, 30.000] - loss: 0.003 - mae: 1.419 - mean_q: 1.915 - mean_eps: 0.128 - ale.lives: 2.892\n",
      "\n",
      "Interval 1940 (969500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0280\n",
      "Interval 1941 (970000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 0.003 - mae: 1.433 - mean_q: 1.933 - mean_eps: 0.127 - ale.lives: 3.152\n",
      "\n",
      "Interval 1942 (970500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.004 - mae: 1.433 - mean_q: 1.932 - mean_eps: 0.126 - ale.lives: 2.478\n",
      "\n",
      "Interval 1943 (971000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0280\n",
      "Interval 1944 (971500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.003 - mae: 1.442 - mean_q: 1.945 - mean_eps: 0.125 - ale.lives: 3.414\n",
      "\n",
      "Interval 1945 (972000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.003 - mae: 1.442 - mean_q: 1.946 - mean_eps: 0.125 - ale.lives: 2.346\n",
      "\n",
      "Interval 1946 (972500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1947 (973000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.432 - mean_q: 1.931 - mean_eps: 0.124 - ale.lives: 3.622\n",
      "\n",
      "Interval 1948 (973500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.437 - mean_q: 1.941 - mean_eps: 0.124 - ale.lives: 2.422\n",
      "\n",
      "Interval 1949 (974000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1950 (974500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.438 - mean_q: 1.941 - mean_eps: 0.123 - ale.lives: 3.654\n",
      "\n",
      "Interval 1951 (975000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.434 - mean_q: 1.934 - mean_eps: 0.122 - ale.lives: 3.004\n",
      "\n",
      "Interval 1952 (975500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "Interval 1953 (976000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.436 - mean_q: 1.939 - mean_eps: 0.121 - ale.lives: 3.698\n",
      "\n",
      "Interval 1954 (976500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.436 - mean_q: 1.938 - mean_eps: 0.121 - ale.lives: 3.546\n",
      "\n",
      "Interval 1955 (977000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.437 - mean_q: 1.939 - mean_eps: 0.120 - ale.lives: 3.080\n",
      "\n",
      "Interval 1956 (977500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "Interval 1957 (978000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.003 - mae: 1.431 - mean_q: 1.932 - mean_eps: 0.120 - ale.lives: 2.740\n",
      "\n",
      "Interval 1958 (978500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "Interval 1959 (979000 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 22.000 [22.000, 22.000] - loss: 0.002 - mae: 1.427 - mean_q: 1.927 - mean_eps: 0.119 - ale.lives: 3.554\n",
      "\n",
      "Interval 1960 (979500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.439 - mean_q: 1.942 - mean_eps: 0.118 - ale.lives: 2.922\n",
      "\n",
      "Interval 1961 (980000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.437 - mean_q: 1.940 - mean_eps: 0.118 - ale.lives: 3.634\n",
      "\n",
      "Interval 1962 (980500 steps performed)\n",
      "500/500 [==============================] - 27s 54ms/step - reward: 0.0240\n",
      "Interval 1963 (981000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.003 - mae: 1.445 - mean_q: 1.948 - mean_eps: 0.117 - ale.lives: 2.980\n",
      "\n",
      "Interval 1964 (981500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0260\n",
      "Interval 1965 (982000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0300\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.440 - mean_q: 1.941 - mean_eps: 0.116 - ale.lives: 4.432\n",
      "\n",
      "Interval 1966 (982500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.003 - mae: 1.437 - mean_q: 1.939 - mean_eps: 0.116 - ale.lives: 3.246\n",
      "\n",
      "Interval 1967 (983000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "Interval 1968 (983500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.002 - mae: 1.434 - mean_q: 1.937 - mean_eps: 0.115 - ale.lives: 3.464\n",
      "\n",
      "Interval 1969 (984000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.442 - mean_q: 1.947 - mean_eps: 0.114 - ale.lives: 2.904\n",
      "\n",
      "Interval 1970 (984500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "Interval 1971 (985000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 0.002 - mae: 1.442 - mean_q: 1.945 - mean_eps: 0.113 - ale.lives: 2.924\n",
      "\n",
      "Interval 1972 (985500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.003 - mae: 1.437 - mean_q: 1.938 - mean_eps: 0.113 - ale.lives: 2.920\n",
      "\n",
      "Interval 1973 (986000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.003 - mae: 1.437 - mean_q: 1.938 - mean_eps: 0.112 - ale.lives: 3.174\n",
      "\n",
      "Interval 1974 (986500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "Interval 1975 (987000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.003 - mae: 1.445 - mean_q: 1.947 - mean_eps: 0.111 - ale.lives: 4.406\n",
      "\n",
      "Interval 1976 (987500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "Interval 1977 (988000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 0.003 - mae: 1.441 - mean_q: 1.946 - mean_eps: 0.111 - ale.lives: 3.516\n",
      "\n",
      "Interval 1978 (988500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.443 - mean_q: 1.947 - mean_eps: 0.110 - ale.lives: 3.560\n",
      "\n",
      "Interval 1979 (989000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.002 - mae: 1.439 - mean_q: 1.945 - mean_eps: 0.110 - ale.lives: 2.224\n",
      "\n",
      "Interval 1980 (989500 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 12.000 [12.000, 12.000] - loss: 0.003 - mae: 1.441 - mean_q: 1.943 - mean_eps: 0.109 - ale.lives: 2.250\n",
      "\n",
      "Interval 1981 (990000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0300\n",
      "Interval 1982 (990500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.003 - mae: 1.443 - mean_q: 1.945 - mean_eps: 0.108 - ale.lives: 2.642\n",
      "\n",
      "Interval 1983 (991000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 0.002 - mae: 1.453 - mean_q: 1.962 - mean_eps: 0.108 - ale.lives: 2.544\n",
      "\n",
      "Interval 1984 (991500 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0280\n",
      "Interval 1985 (992000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.002 - mae: 1.451 - mean_q: 1.956 - mean_eps: 0.107 - ale.lives: 3.538\n",
      "\n",
      "Interval 1986 (992500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.445 - mean_q: 1.949 - mean_eps: 0.107 - ale.lives: 3.222\n",
      "\n",
      "Interval 1987 (993000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0240\n",
      "Interval 1988 (993500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 0.003 - mae: 1.445 - mean_q: 1.946 - mean_eps: 0.106 - ale.lives: 3.382\n",
      "\n",
      "Interval 1989 (994000 steps performed)\n",
      "500/500 [==============================] - 26s 51ms/step - reward: 0.0260\n",
      "Interval 1990 (994500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 0.003 - mae: 1.453 - mean_q: 1.959 - mean_eps: 0.105 - ale.lives: 3.376\n",
      "\n",
      "Interval 1991 (995000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.002 - mae: 1.454 - mean_q: 1.961 - mean_eps: 0.104 - ale.lives: 3.380\n",
      "\n",
      "Interval 1992 (995500 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0280\n",
      "Interval 1993 (996000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 26.000 [26.000, 26.000] - loss: 0.002 - mae: 1.447 - mean_q: 1.950 - mean_eps: 0.103 - ale.lives: 3.410\n",
      "\n",
      "Interval 1994 (996500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 14.000 [14.000, 14.000] - loss: 0.003 - mae: 1.451 - mean_q: 1.954 - mean_eps: 0.103 - ale.lives: 3.332\n",
      "\n",
      "Interval 1995 (997000 steps performed)\n",
      "500/500 [==============================] - 26s 53ms/step - reward: 0.0200\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.003 - mae: 1.447 - mean_q: 1.949 - mean_eps: 0.102 - ale.lives: 2.440\n",
      "\n",
      "Interval 1996 (997500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0220\n",
      "1 episodes - episode_reward: 11.000 [11.000, 11.000] - loss: 0.002 - mae: 1.457 - mean_q: 1.962 - mean_eps: 0.102 - ale.lives: 2.994\n",
      "\n",
      "Interval 1997 (998000 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0240\n",
      "Interval 1998 (998500 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0240\n",
      "1 episodes - episode_reward: 13.000 [13.000, 13.000] - loss: 0.002 - mae: 1.452 - mean_q: 1.956 - mean_eps: 0.101 - ale.lives: 3.622\n",
      "\n",
      "Interval 1999 (999000 steps performed)\n",
      "500/500 [==============================] - 26s 52ms/step - reward: 0.0260\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 0.003 - mae: 1.449 - mean_q: 1.954 - mean_eps: 0.101 - ale.lives: 2.942\n",
      "\n",
      "Interval 2000 (999500 steps performed)\n",
      "500/500 [==============================] - 27s 53ms/step - reward: 0.0300\n",
      "done, took 46971.923 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27a6e6b6d88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=1_000_000, callbacks=[checkpoint_callback],\n",
    "        log_interval=500, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.test(env, nb_episodes=1, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b01d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0200\n",
      "Interval 2 (500 steps performed)\n",
      "500/500 [==============================] - 4s 8ms/step - reward: 0.0200\n",
      "done, took 8.292 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bd4e39e508>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case you want to train from an expecific checkpoint\n",
    "model.load_weights(\"dqn_checkpoint.h5f\")\n",
    "# Start the value_max in 0.2 because you don't \n",
    "# need to make further exploration as in the begging of the training\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(0.1),\n",
    "                              attr=\"eps\",\n",
    "                              value_max=0.2,\n",
    "                              value_min=0.1,\n",
    "                              value_test=0.05,\n",
    "                              nb_steps=1_000)\n",
    "dqn = DQNAgent(model=model,\n",
    "               nb_actions=nb_actions,\n",
    "               policy=policy,\n",
    "               memory=memory,\n",
    "               processor=processor,\n",
    "               nb_steps_warmup=50_000,\n",
    "               gamma=0.99,\n",
    "               target_model_update=10_000,\n",
    "               train_interval=4,\n",
    "               delta_clip=1)\n",
    "dqn.compile(Adam(learning_rate=0.00025), metrics=[\"mae\"])\n",
    "dqn.fit(env, nb_steps=1000, log_interval=500, visualize=False)\n",
    "dqn.test(env, nb_episodes=1, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
